defmodule Floki.HTML.Generated.Tokenizer.NamedentitiesPart35Test do
  use ExUnit.Case, async: true

  # NOTE: This file was generated by "mix generate_tokenizer_tests namedEntities.test".
  # html5lib-tests rev: e52ff68cc7113a6ef3687747fa82691079bf9cc5

  alias Floki.HTML.Tokenizer

  test "tokenize/1 Named entity: measuredangle; with a semi-colon" do
    input = "&measuredangle;"
    output = [["Character", "âˆ¡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: mfr; with a semi-colon" do
    input = "&mfr;"
    output = [["Character", "ð”ª"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: mho; with a semi-colon" do
    input = "&mho;"
    output = [["Character", "â„§"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: micro without a semi-colon" do
    input = "&micro"
    output = [["Character", "Âµ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: micro; with a semi-colon" do
    input = "&micro;"
    output = [["Character", "Âµ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: mid; with a semi-colon" do
    input = "&mid;"
    output = [["Character", "âˆ£"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: midast; with a semi-colon" do
    input = "&midast;"
    output = [["Character", "*"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: midcir; with a semi-colon" do
    input = "&midcir;"
    output = [["Character", "â«°"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: middot without a semi-colon" do
    input = "&middot"
    output = [["Character", "Â·"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: middot; with a semi-colon" do
    input = "&middot;"
    output = [["Character", "Â·"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: minus; with a semi-colon" do
    input = "&minus;"
    output = [["Character", "âˆ’"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: minusb; with a semi-colon" do
    input = "&minusb;"
    output = [["Character", "âŠŸ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: minusd; with a semi-colon" do
    input = "&minusd;"
    output = [["Character", "âˆ¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: minusdu; with a semi-colon" do
    input = "&minusdu;"
    output = [["Character", "â¨ª"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: mlcp; with a semi-colon" do
    input = "&mlcp;"
    output = [["Character", "â«›"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: mldr; with a semi-colon" do
    input = "&mldr;"
    output = [["Character", "â€¦"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: mnplus; with a semi-colon" do
    input = "&mnplus;"
    output = [["Character", "âˆ“"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: models; with a semi-colon" do
    input = "&models;"
    output = [["Character", "âŠ§"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: mopf; with a semi-colon" do
    input = "&mopf;"
    output = [["Character", "ð•ž"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: mp; with a semi-colon" do
    input = "&mp;"
    output = [["Character", "âˆ“"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: mscr; with a semi-colon" do
    input = "&mscr;"
    output = [["Character", "ð“‚"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: mstpos; with a semi-colon" do
    input = "&mstpos;"
    output = [["Character", "âˆ¾"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: mu; with a semi-colon" do
    input = "&mu;"
    output = [["Character", "Î¼"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: multimap; with a semi-colon" do
    input = "&multimap;"
    output = [["Character", "âŠ¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: mumap; with a semi-colon" do
    input = "&mumap;"
    output = [["Character", "âŠ¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nGg; with a semi-colon" do
    input = "&nGg;"
    output = [["Character", "â‹™Ì¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nGt; with a semi-colon" do
    input = "&nGt;"
    output = [["Character", "â‰«âƒ’"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nGtv; with a semi-colon" do
    input = "&nGtv;"
    output = [["Character", "â‰«Ì¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nLeftarrow; with a semi-colon" do
    input = "&nLeftarrow;"
    output = [["Character", "â‡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nLeftrightarrow; with a semi-colon" do
    input = "&nLeftrightarrow;"
    output = [["Character", "â‡Ž"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nLl; with a semi-colon" do
    input = "&nLl;"
    output = [["Character", "â‹˜Ì¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nLt; with a semi-colon" do
    input = "&nLt;"
    output = [["Character", "â‰ªâƒ’"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nLtv; with a semi-colon" do
    input = "&nLtv;"
    output = [["Character", "â‰ªÌ¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nRightarrow; with a semi-colon" do
    input = "&nRightarrow;"
    output = [["Character", "â‡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nVDash; with a semi-colon" do
    input = "&nVDash;"
    output = [["Character", "âŠ¯"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nVdash; with a semi-colon" do
    input = "&nVdash;"
    output = [["Character", "âŠ®"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nabla; with a semi-colon" do
    input = "&nabla;"
    output = [["Character", "âˆ‡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nacute; with a semi-colon" do
    input = "&nacute;"
    output = [["Character", "Å„"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nang; with a semi-colon" do
    input = "&nang;"
    output = [["Character", "âˆ âƒ’"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nap; with a semi-colon" do
    input = "&nap;"
    output = [["Character", "â‰‰"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: napE; with a semi-colon" do
    input = "&napE;"
    output = [["Character", "â©°Ì¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: napid; with a semi-colon" do
    input = "&napid;"
    output = [["Character", "â‰‹Ì¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: napos; with a semi-colon" do
    input = "&napos;"
    output = [["Character", "Å‰"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: napprox; with a semi-colon" do
    input = "&napprox;"
    output = [["Character", "â‰‰"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: natur; with a semi-colon" do
    input = "&natur;"
    output = [["Character", "â™®"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: natural; with a semi-colon" do
    input = "&natural;"
    output = [["Character", "â™®"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: naturals; with a semi-colon" do
    input = "&naturals;"
    output = [["Character", "â„•"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nbsp without a semi-colon" do
    input = "&nbsp"
    output = [["Character", "Â "]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nbsp; with a semi-colon" do
    input = "&nbsp;"
    output = [["Character", "Â "]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nbump; with a semi-colon" do
    input = "&nbump;"
    output = [["Character", "â‰ŽÌ¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nbumpe; with a semi-colon" do
    input = "&nbumpe;"
    output = [["Character", "â‰Ì¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ncap; with a semi-colon" do
    input = "&ncap;"
    output = [["Character", "â©ƒ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ncaron; with a semi-colon" do
    input = "&ncaron;"
    output = [["Character", "Åˆ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ncedil; with a semi-colon" do
    input = "&ncedil;"
    output = [["Character", "Å†"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ncong; with a semi-colon" do
    input = "&ncong;"
    output = [["Character", "â‰‡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ncongdot; with a semi-colon" do
    input = "&ncongdot;"
    output = [["Character", "â©­Ì¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ncup; with a semi-colon" do
    input = "&ncup;"
    output = [["Character", "â©‚"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ncy; with a semi-colon" do
    input = "&ncy;"
    output = [["Character", "Ð½"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ndash; with a semi-colon" do
    input = "&ndash;"
    output = [["Character", "â€“"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ne; with a semi-colon" do
    input = "&ne;"
    output = [["Character", "â‰ "]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: neArr; with a semi-colon" do
    input = "&neArr;"
    output = [["Character", "â‡—"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nearhk; with a semi-colon" do
    input = "&nearhk;"
    output = [["Character", "â¤¤"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nearr; with a semi-colon" do
    input = "&nearr;"
    output = [["Character", "â†—"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nearrow; with a semi-colon" do
    input = "&nearrow;"
    output = [["Character", "â†—"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nedot; with a semi-colon" do
    input = "&nedot;"
    output = [["Character", "â‰Ì¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nequiv; with a semi-colon" do
    input = "&nequiv;"
    output = [["Character", "â‰¢"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nesear; with a semi-colon" do
    input = "&nesear;"
    output = [["Character", "â¤¨"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nesim; with a semi-colon" do
    input = "&nesim;"
    output = [["Character", "â‰‚Ì¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nexist; with a semi-colon" do
    input = "&nexist;"
    output = [["Character", "âˆ„"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nexists; with a semi-colon" do
    input = "&nexists;"
    output = [["Character", "âˆ„"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nfr; with a semi-colon" do
    input = "&nfr;"
    output = [["Character", "ð”«"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ngE; with a semi-colon" do
    input = "&ngE;"
    output = [["Character", "â‰§Ì¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nge; with a semi-colon" do
    input = "&nge;"
    output = [["Character", "â‰±"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ngeq; with a semi-colon" do
    input = "&ngeq;"
    output = [["Character", "â‰±"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ngeqq; with a semi-colon" do
    input = "&ngeqq;"
    output = [["Character", "â‰§Ì¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ngeqslant; with a semi-colon" do
    input = "&ngeqslant;"
    output = [["Character", "â©¾Ì¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nges; with a semi-colon" do
    input = "&nges;"
    output = [["Character", "â©¾Ì¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ngsim; with a semi-colon" do
    input = "&ngsim;"
    output = [["Character", "â‰µ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ngt; with a semi-colon" do
    input = "&ngt;"
    output = [["Character", "â‰¯"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ngtr; with a semi-colon" do
    input = "&ngtr;"
    output = [["Character", "â‰¯"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nhArr; with a semi-colon" do
    input = "&nhArr;"
    output = [["Character", "â‡Ž"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nharr; with a semi-colon" do
    input = "&nharr;"
    output = [["Character", "â†®"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nhpar; with a semi-colon" do
    input = "&nhpar;"
    output = [["Character", "â«²"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ni; with a semi-colon" do
    input = "&ni;"
    output = [["Character", "âˆ‹"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nis; with a semi-colon" do
    input = "&nis;"
    output = [["Character", "â‹¼"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nisd; with a semi-colon" do
    input = "&nisd;"
    output = [["Character", "â‹º"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: niv; with a semi-colon" do
    input = "&niv;"
    output = [["Character", "âˆ‹"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: njcy; with a semi-colon" do
    input = "&njcy;"
    output = [["Character", "Ñš"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nlArr; with a semi-colon" do
    input = "&nlArr;"
    output = [["Character", "â‡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nlE; with a semi-colon" do
    input = "&nlE;"
    output = [["Character", "â‰¦Ì¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nlarr; with a semi-colon" do
    input = "&nlarr;"
    output = [["Character", "â†š"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nldr; with a semi-colon" do
    input = "&nldr;"
    output = [["Character", "â€¥"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nle; with a semi-colon" do
    input = "&nle;"
    output = [["Character", "â‰°"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nleftarrow; with a semi-colon" do
    input = "&nleftarrow;"
    output = [["Character", "â†š"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nleftrightarrow; with a semi-colon" do
    input = "&nleftrightarrow;"
    output = [["Character", "â†®"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nleq; with a semi-colon" do
    input = "&nleq;"
    output = [["Character", "â‰°"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nleqq; with a semi-colon" do
    input = "&nleqq;"
    output = [["Character", "â‰¦Ì¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nleqslant; with a semi-colon" do
    input = "&nleqslant;"
    output = [["Character", "â©½Ì¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nles; with a semi-colon" do
    input = "&nles;"
    output = [["Character", "â©½Ì¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nless; with a semi-colon" do
    input = "&nless;"
    output = [["Character", "â‰®"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end
end