defmodule Floki.HTML.Generated.Tokenizer.NamedentitiesPart35Test do
  use ExUnit.Case, async: true

  # NOTE: This file was generated by "mix generate_tokenizer_tests namedEntities.test".
  # html5lib-tests rev: e52ff68cc7113a6ef3687747fa82691079bf9cc5

  alias Floki.HTML.Tokenizer

  test "tokenize/1 Named entity: measuredangle; with a semi-colon" do
    input = "&measuredangle;"
    output = [["Character", "∡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: mfr; with a semi-colon" do
    input = "&mfr;"
    output = [["Character", "𝔪"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: mho; with a semi-colon" do
    input = "&mho;"
    output = [["Character", "℧"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: micro without a semi-colon" do
    input = "&micro"
    output = [["Character", "µ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: micro; with a semi-colon" do
    input = "&micro;"
    output = [["Character", "µ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: mid; with a semi-colon" do
    input = "&mid;"
    output = [["Character", "∣"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: midast; with a semi-colon" do
    input = "&midast;"
    output = [["Character", "*"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: midcir; with a semi-colon" do
    input = "&midcir;"
    output = [["Character", "⫰"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: middot without a semi-colon" do
    input = "&middot"
    output = [["Character", "·"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: middot; with a semi-colon" do
    input = "&middot;"
    output = [["Character", "·"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: minus; with a semi-colon" do
    input = "&minus;"
    output = [["Character", "−"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: minusb; with a semi-colon" do
    input = "&minusb;"
    output = [["Character", "⊟"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: minusd; with a semi-colon" do
    input = "&minusd;"
    output = [["Character", "∸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: minusdu; with a semi-colon" do
    input = "&minusdu;"
    output = [["Character", "⨪"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: mlcp; with a semi-colon" do
    input = "&mlcp;"
    output = [["Character", "⫛"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: mldr; with a semi-colon" do
    input = "&mldr;"
    output = [["Character", "…"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: mnplus; with a semi-colon" do
    input = "&mnplus;"
    output = [["Character", "∓"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: models; with a semi-colon" do
    input = "&models;"
    output = [["Character", "⊧"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: mopf; with a semi-colon" do
    input = "&mopf;"
    output = [["Character", "𝕞"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: mp; with a semi-colon" do
    input = "&mp;"
    output = [["Character", "∓"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: mscr; with a semi-colon" do
    input = "&mscr;"
    output = [["Character", "𝓂"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: mstpos; with a semi-colon" do
    input = "&mstpos;"
    output = [["Character", "∾"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: mu; with a semi-colon" do
    input = "&mu;"
    output = [["Character", "μ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: multimap; with a semi-colon" do
    input = "&multimap;"
    output = [["Character", "⊸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: mumap; with a semi-colon" do
    input = "&mumap;"
    output = [["Character", "⊸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nGg; with a semi-colon" do
    input = "&nGg;"
    output = [["Character", "⋙̸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nGt; with a semi-colon" do
    input = "&nGt;"
    output = [["Character", "≫⃒"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nGtv; with a semi-colon" do
    input = "&nGtv;"
    output = [["Character", "≫̸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nLeftarrow; with a semi-colon" do
    input = "&nLeftarrow;"
    output = [["Character", "⇍"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nLeftrightarrow; with a semi-colon" do
    input = "&nLeftrightarrow;"
    output = [["Character", "⇎"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nLl; with a semi-colon" do
    input = "&nLl;"
    output = [["Character", "⋘̸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nLt; with a semi-colon" do
    input = "&nLt;"
    output = [["Character", "≪⃒"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nLtv; with a semi-colon" do
    input = "&nLtv;"
    output = [["Character", "≪̸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nRightarrow; with a semi-colon" do
    input = "&nRightarrow;"
    output = [["Character", "⇏"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nVDash; with a semi-colon" do
    input = "&nVDash;"
    output = [["Character", "⊯"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nVdash; with a semi-colon" do
    input = "&nVdash;"
    output = [["Character", "⊮"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nabla; with a semi-colon" do
    input = "&nabla;"
    output = [["Character", "∇"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nacute; with a semi-colon" do
    input = "&nacute;"
    output = [["Character", "ń"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nang; with a semi-colon" do
    input = "&nang;"
    output = [["Character", "∠⃒"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nap; with a semi-colon" do
    input = "&nap;"
    output = [["Character", "≉"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: napE; with a semi-colon" do
    input = "&napE;"
    output = [["Character", "⩰̸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: napid; with a semi-colon" do
    input = "&napid;"
    output = [["Character", "≋̸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: napos; with a semi-colon" do
    input = "&napos;"
    output = [["Character", "ŉ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: napprox; with a semi-colon" do
    input = "&napprox;"
    output = [["Character", "≉"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: natur; with a semi-colon" do
    input = "&natur;"
    output = [["Character", "♮"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: natural; with a semi-colon" do
    input = "&natural;"
    output = [["Character", "♮"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: naturals; with a semi-colon" do
    input = "&naturals;"
    output = [["Character", "ℕ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nbsp without a semi-colon" do
    input = "&nbsp"
    output = [["Character", " "]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nbsp; with a semi-colon" do
    input = "&nbsp;"
    output = [["Character", " "]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nbump; with a semi-colon" do
    input = "&nbump;"
    output = [["Character", "≎̸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nbumpe; with a semi-colon" do
    input = "&nbumpe;"
    output = [["Character", "≏̸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ncap; with a semi-colon" do
    input = "&ncap;"
    output = [["Character", "⩃"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ncaron; with a semi-colon" do
    input = "&ncaron;"
    output = [["Character", "ň"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ncedil; with a semi-colon" do
    input = "&ncedil;"
    output = [["Character", "ņ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ncong; with a semi-colon" do
    input = "&ncong;"
    output = [["Character", "≇"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ncongdot; with a semi-colon" do
    input = "&ncongdot;"
    output = [["Character", "⩭̸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ncup; with a semi-colon" do
    input = "&ncup;"
    output = [["Character", "⩂"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ncy; with a semi-colon" do
    input = "&ncy;"
    output = [["Character", "н"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ndash; with a semi-colon" do
    input = "&ndash;"
    output = [["Character", "–"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ne; with a semi-colon" do
    input = "&ne;"
    output = [["Character", "≠"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: neArr; with a semi-colon" do
    input = "&neArr;"
    output = [["Character", "⇗"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nearhk; with a semi-colon" do
    input = "&nearhk;"
    output = [["Character", "⤤"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nearr; with a semi-colon" do
    input = "&nearr;"
    output = [["Character", "↗"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nearrow; with a semi-colon" do
    input = "&nearrow;"
    output = [["Character", "↗"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nedot; with a semi-colon" do
    input = "&nedot;"
    output = [["Character", "≐̸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nequiv; with a semi-colon" do
    input = "&nequiv;"
    output = [["Character", "≢"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nesear; with a semi-colon" do
    input = "&nesear;"
    output = [["Character", "⤨"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nesim; with a semi-colon" do
    input = "&nesim;"
    output = [["Character", "≂̸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nexist; with a semi-colon" do
    input = "&nexist;"
    output = [["Character", "∄"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nexists; with a semi-colon" do
    input = "&nexists;"
    output = [["Character", "∄"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nfr; with a semi-colon" do
    input = "&nfr;"
    output = [["Character", "𝔫"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ngE; with a semi-colon" do
    input = "&ngE;"
    output = [["Character", "≧̸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nge; with a semi-colon" do
    input = "&nge;"
    output = [["Character", "≱"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ngeq; with a semi-colon" do
    input = "&ngeq;"
    output = [["Character", "≱"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ngeqq; with a semi-colon" do
    input = "&ngeqq;"
    output = [["Character", "≧̸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ngeqslant; with a semi-colon" do
    input = "&ngeqslant;"
    output = [["Character", "⩾̸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nges; with a semi-colon" do
    input = "&nges;"
    output = [["Character", "⩾̸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ngsim; with a semi-colon" do
    input = "&ngsim;"
    output = [["Character", "≵"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ngt; with a semi-colon" do
    input = "&ngt;"
    output = [["Character", "≯"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ngtr; with a semi-colon" do
    input = "&ngtr;"
    output = [["Character", "≯"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nhArr; with a semi-colon" do
    input = "&nhArr;"
    output = [["Character", "⇎"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nharr; with a semi-colon" do
    input = "&nharr;"
    output = [["Character", "↮"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nhpar; with a semi-colon" do
    input = "&nhpar;"
    output = [["Character", "⫲"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ni; with a semi-colon" do
    input = "&ni;"
    output = [["Character", "∋"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nis; with a semi-colon" do
    input = "&nis;"
    output = [["Character", "⋼"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nisd; with a semi-colon" do
    input = "&nisd;"
    output = [["Character", "⋺"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: niv; with a semi-colon" do
    input = "&niv;"
    output = [["Character", "∋"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: njcy; with a semi-colon" do
    input = "&njcy;"
    output = [["Character", "њ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nlArr; with a semi-colon" do
    input = "&nlArr;"
    output = [["Character", "⇍"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nlE; with a semi-colon" do
    input = "&nlE;"
    output = [["Character", "≦̸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nlarr; with a semi-colon" do
    input = "&nlarr;"
    output = [["Character", "↚"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nldr; with a semi-colon" do
    input = "&nldr;"
    output = [["Character", "‥"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nle; with a semi-colon" do
    input = "&nle;"
    output = [["Character", "≰"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nleftarrow; with a semi-colon" do
    input = "&nleftarrow;"
    output = [["Character", "↚"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nleftrightarrow; with a semi-colon" do
    input = "&nleftrightarrow;"
    output = [["Character", "↮"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nleq; with a semi-colon" do
    input = "&nleq;"
    output = [["Character", "≰"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nleqq; with a semi-colon" do
    input = "&nleqq;"
    output = [["Character", "≦̸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nleqslant; with a semi-colon" do
    input = "&nleqslant;"
    output = [["Character", "⩽̸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nles; with a semi-colon" do
    input = "&nles;"
    output = [["Character", "⩽̸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nless; with a semi-colon" do
    input = "&nless;"
    output = [["Character", "≮"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end
end