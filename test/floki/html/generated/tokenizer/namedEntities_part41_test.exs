defmodule Floki.HTML.Generated.Tokenizer.NamedentitiesPart41Test do
  use ExUnit.Case, async: true

  # NOTE: This file was generated by "mix generate_tokenizer_tests namedEntities.test".
  # html5lib-tests rev: e52ff68cc7113a6ef3687747fa82691079bf9cc5

  alias Floki.HTML.Tokenizer

  test "tokenize/1 Named entity: tcedil; with a semi-colon" do
    input = "&tcedil;"
    output = [["Character", "ţ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: tcy; with a semi-colon" do
    input = "&tcy;"
    output = [["Character", "т"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: tdot; with a semi-colon" do
    input = "&tdot;"
    output = [["Character", "⃛"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: telrec; with a semi-colon" do
    input = "&telrec;"
    output = [["Character", "⌕"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: tfr; with a semi-colon" do
    input = "&tfr;"
    output = [["Character", "𝔱"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: there4; with a semi-colon" do
    input = "&there4;"
    output = [["Character", "∴"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: therefore; with a semi-colon" do
    input = "&therefore;"
    output = [["Character", "∴"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: theta; with a semi-colon" do
    input = "&theta;"
    output = [["Character", "θ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: thetasym; with a semi-colon" do
    input = "&thetasym;"
    output = [["Character", "ϑ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: thetav; with a semi-colon" do
    input = "&thetav;"
    output = [["Character", "ϑ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: thickapprox; with a semi-colon" do
    input = "&thickapprox;"
    output = [["Character", "≈"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: thicksim; with a semi-colon" do
    input = "&thicksim;"
    output = [["Character", "∼"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: thinsp; with a semi-colon" do
    input = "&thinsp;"
    output = [["Character", " "]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: thkap; with a semi-colon" do
    input = "&thkap;"
    output = [["Character", "≈"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: thksim; with a semi-colon" do
    input = "&thksim;"
    output = [["Character", "∼"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: thorn without a semi-colon" do
    input = "&thorn"
    output = [["Character", "þ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: thorn; with a semi-colon" do
    input = "&thorn;"
    output = [["Character", "þ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: tilde; with a semi-colon" do
    input = "&tilde;"
    output = [["Character", "˜"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: times without a semi-colon" do
    input = "&times"
    output = [["Character", "×"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: times; with a semi-colon" do
    input = "&times;"
    output = [["Character", "×"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: timesb; with a semi-colon" do
    input = "&timesb;"
    output = [["Character", "⊠"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: timesbar; with a semi-colon" do
    input = "&timesbar;"
    output = [["Character", "⨱"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: timesd; with a semi-colon" do
    input = "&timesd;"
    output = [["Character", "⨰"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: tint; with a semi-colon" do
    input = "&tint;"
    output = [["Character", "∭"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: toea; with a semi-colon" do
    input = "&toea;"
    output = [["Character", "⤨"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: top; with a semi-colon" do
    input = "&top;"
    output = [["Character", "⊤"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: topbot; with a semi-colon" do
    input = "&topbot;"
    output = [["Character", "⌶"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: topcir; with a semi-colon" do
    input = "&topcir;"
    output = [["Character", "⫱"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: topf; with a semi-colon" do
    input = "&topf;"
    output = [["Character", "𝕥"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: topfork; with a semi-colon" do
    input = "&topfork;"
    output = [["Character", "⫚"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: tosa; with a semi-colon" do
    input = "&tosa;"
    output = [["Character", "⤩"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: tprime; with a semi-colon" do
    input = "&tprime;"
    output = [["Character", "‴"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: trade; with a semi-colon" do
    input = "&trade;"
    output = [["Character", "™"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: triangle; with a semi-colon" do
    input = "&triangle;"
    output = [["Character", "▵"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: triangledown; with a semi-colon" do
    input = "&triangledown;"
    output = [["Character", "▿"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: triangleleft; with a semi-colon" do
    input = "&triangleleft;"
    output = [["Character", "◃"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: trianglelefteq; with a semi-colon" do
    input = "&trianglelefteq;"
    output = [["Character", "⊴"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: triangleq; with a semi-colon" do
    input = "&triangleq;"
    output = [["Character", "≜"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: triangleright; with a semi-colon" do
    input = "&triangleright;"
    output = [["Character", "▹"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: trianglerighteq; with a semi-colon" do
    input = "&trianglerighteq;"
    output = [["Character", "⊵"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: tridot; with a semi-colon" do
    input = "&tridot;"
    output = [["Character", "◬"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: trie; with a semi-colon" do
    input = "&trie;"
    output = [["Character", "≜"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: triminus; with a semi-colon" do
    input = "&triminus;"
    output = [["Character", "⨺"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: triplus; with a semi-colon" do
    input = "&triplus;"
    output = [["Character", "⨹"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: trisb; with a semi-colon" do
    input = "&trisb;"
    output = [["Character", "⧍"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: tritime; with a semi-colon" do
    input = "&tritime;"
    output = [["Character", "⨻"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: trpezium; with a semi-colon" do
    input = "&trpezium;"
    output = [["Character", "⏢"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: tscr; with a semi-colon" do
    input = "&tscr;"
    output = [["Character", "𝓉"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: tscy; with a semi-colon" do
    input = "&tscy;"
    output = [["Character", "ц"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: tshcy; with a semi-colon" do
    input = "&tshcy;"
    output = [["Character", "ћ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: tstrok; with a semi-colon" do
    input = "&tstrok;"
    output = [["Character", "ŧ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: twixt; with a semi-colon" do
    input = "&twixt;"
    output = [["Character", "≬"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: twoheadleftarrow; with a semi-colon" do
    input = "&twoheadleftarrow;"
    output = [["Character", "↞"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: twoheadrightarrow; with a semi-colon" do
    input = "&twoheadrightarrow;"
    output = [["Character", "↠"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: uArr; with a semi-colon" do
    input = "&uArr;"
    output = [["Character", "⇑"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: uHar; with a semi-colon" do
    input = "&uHar;"
    output = [["Character", "⥣"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: uacute without a semi-colon" do
    input = "&uacute"
    output = [["Character", "ú"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: uacute; with a semi-colon" do
    input = "&uacute;"
    output = [["Character", "ú"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: uarr; with a semi-colon" do
    input = "&uarr;"
    output = [["Character", "↑"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ubrcy; with a semi-colon" do
    input = "&ubrcy;"
    output = [["Character", "ў"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ubreve; with a semi-colon" do
    input = "&ubreve;"
    output = [["Character", "ŭ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ucirc without a semi-colon" do
    input = "&ucirc"
    output = [["Character", "û"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ucirc; with a semi-colon" do
    input = "&ucirc;"
    output = [["Character", "û"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ucy; with a semi-colon" do
    input = "&ucy;"
    output = [["Character", "у"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: udarr; with a semi-colon" do
    input = "&udarr;"
    output = [["Character", "⇅"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: udblac; with a semi-colon" do
    input = "&udblac;"
    output = [["Character", "ű"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: udhar; with a semi-colon" do
    input = "&udhar;"
    output = [["Character", "⥮"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ufisht; with a semi-colon" do
    input = "&ufisht;"
    output = [["Character", "⥾"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ufr; with a semi-colon" do
    input = "&ufr;"
    output = [["Character", "𝔲"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ugrave without a semi-colon" do
    input = "&ugrave"
    output = [["Character", "ù"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ugrave; with a semi-colon" do
    input = "&ugrave;"
    output = [["Character", "ù"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: uharl; with a semi-colon" do
    input = "&uharl;"
    output = [["Character", "↿"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: uharr; with a semi-colon" do
    input = "&uharr;"
    output = [["Character", "↾"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: uhblk; with a semi-colon" do
    input = "&uhblk;"
    output = [["Character", "▀"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ulcorn; with a semi-colon" do
    input = "&ulcorn;"
    output = [["Character", "⌜"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ulcorner; with a semi-colon" do
    input = "&ulcorner;"
    output = [["Character", "⌜"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ulcrop; with a semi-colon" do
    input = "&ulcrop;"
    output = [["Character", "⌏"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ultri; with a semi-colon" do
    input = "&ultri;"
    output = [["Character", "◸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: umacr; with a semi-colon" do
    input = "&umacr;"
    output = [["Character", "ū"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: uml without a semi-colon" do
    input = "&uml"
    output = [["Character", "¨"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: uml; with a semi-colon" do
    input = "&uml;"
    output = [["Character", "¨"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: uogon; with a semi-colon" do
    input = "&uogon;"
    output = [["Character", "ų"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: uopf; with a semi-colon" do
    input = "&uopf;"
    output = [["Character", "𝕦"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: uparrow; with a semi-colon" do
    input = "&uparrow;"
    output = [["Character", "↑"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: updownarrow; with a semi-colon" do
    input = "&updownarrow;"
    output = [["Character", "↕"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: upharpoonleft; with a semi-colon" do
    input = "&upharpoonleft;"
    output = [["Character", "↿"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: upharpoonright; with a semi-colon" do
    input = "&upharpoonright;"
    output = [["Character", "↾"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: uplus; with a semi-colon" do
    input = "&uplus;"
    output = [["Character", "⊎"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: upsi; with a semi-colon" do
    input = "&upsi;"
    output = [["Character", "υ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: upsih; with a semi-colon" do
    input = "&upsih;"
    output = [["Character", "ϒ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: upsilon; with a semi-colon" do
    input = "&upsilon;"
    output = [["Character", "υ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: upuparrows; with a semi-colon" do
    input = "&upuparrows;"
    output = [["Character", "⇈"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: urcorn; with a semi-colon" do
    input = "&urcorn;"
    output = [["Character", "⌝"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: urcorner; with a semi-colon" do
    input = "&urcorner;"
    output = [["Character", "⌝"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: urcrop; with a semi-colon" do
    input = "&urcrop;"
    output = [["Character", "⌎"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: uring; with a semi-colon" do
    input = "&uring;"
    output = [["Character", "ů"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: urtri; with a semi-colon" do
    input = "&urtri;"
    output = [["Character", "◹"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: uscr; with a semi-colon" do
    input = "&uscr;"
    output = [["Character", "𝓊"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: utdot; with a semi-colon" do
    input = "&utdot;"
    output = [["Character", "⋰"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: utilde; with a semi-colon" do
    input = "&utilde;"
    output = [["Character", "ũ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end
end