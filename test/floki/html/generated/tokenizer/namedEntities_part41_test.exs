defmodule Floki.HTML.Generated.Tokenizer.NamedentitiesPart41Test do
  use ExUnit.Case, async: true

  # NOTE: This file was generated by "mix generate_tokenizer_tests namedEntities.test".
  # html5lib-tests rev: e52ff68cc7113a6ef3687747fa82691079bf9cc5

  alias Floki.HTML.Tokenizer

  test "tokenize/1 Named entity: tcedil; with a semi-colon" do
    input = "&tcedil;"
    output = [["Character", "Å£"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: tcy; with a semi-colon" do
    input = "&tcy;"
    output = [["Character", "Ñ‚"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: tdot; with a semi-colon" do
    input = "&tdot;"
    output = [["Character", "âƒ›"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: telrec; with a semi-colon" do
    input = "&telrec;"
    output = [["Character", "âŒ•"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: tfr; with a semi-colon" do
    input = "&tfr;"
    output = [["Character", "ð”±"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: there4; with a semi-colon" do
    input = "&there4;"
    output = [["Character", "âˆ´"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: therefore; with a semi-colon" do
    input = "&therefore;"
    output = [["Character", "âˆ´"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: theta; with a semi-colon" do
    input = "&theta;"
    output = [["Character", "Î¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: thetasym; with a semi-colon" do
    input = "&thetasym;"
    output = [["Character", "Ï‘"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: thetav; with a semi-colon" do
    input = "&thetav;"
    output = [["Character", "Ï‘"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: thickapprox; with a semi-colon" do
    input = "&thickapprox;"
    output = [["Character", "â‰ˆ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: thicksim; with a semi-colon" do
    input = "&thicksim;"
    output = [["Character", "âˆ¼"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: thinsp; with a semi-colon" do
    input = "&thinsp;"
    output = [["Character", "â€‰"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: thkap; with a semi-colon" do
    input = "&thkap;"
    output = [["Character", "â‰ˆ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: thksim; with a semi-colon" do
    input = "&thksim;"
    output = [["Character", "âˆ¼"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: thorn without a semi-colon" do
    input = "&thorn"
    output = [["Character", "Ã¾"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: thorn; with a semi-colon" do
    input = "&thorn;"
    output = [["Character", "Ã¾"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: tilde; with a semi-colon" do
    input = "&tilde;"
    output = [["Character", "Ëœ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: times without a semi-colon" do
    input = "&times"
    output = [["Character", "Ã—"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: times; with a semi-colon" do
    input = "&times;"
    output = [["Character", "Ã—"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: timesb; with a semi-colon" do
    input = "&timesb;"
    output = [["Character", "âŠ "]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: timesbar; with a semi-colon" do
    input = "&timesbar;"
    output = [["Character", "â¨±"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: timesd; with a semi-colon" do
    input = "&timesd;"
    output = [["Character", "â¨°"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: tint; with a semi-colon" do
    input = "&tint;"
    output = [["Character", "âˆ­"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: toea; with a semi-colon" do
    input = "&toea;"
    output = [["Character", "â¤¨"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: top; with a semi-colon" do
    input = "&top;"
    output = [["Character", "âŠ¤"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: topbot; with a semi-colon" do
    input = "&topbot;"
    output = [["Character", "âŒ¶"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: topcir; with a semi-colon" do
    input = "&topcir;"
    output = [["Character", "â«±"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: topf; with a semi-colon" do
    input = "&topf;"
    output = [["Character", "ð•¥"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: topfork; with a semi-colon" do
    input = "&topfork;"
    output = [["Character", "â«š"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: tosa; with a semi-colon" do
    input = "&tosa;"
    output = [["Character", "â¤©"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: tprime; with a semi-colon" do
    input = "&tprime;"
    output = [["Character", "â€´"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: trade; with a semi-colon" do
    input = "&trade;"
    output = [["Character", "â„¢"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: triangle; with a semi-colon" do
    input = "&triangle;"
    output = [["Character", "â–µ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: triangledown; with a semi-colon" do
    input = "&triangledown;"
    output = [["Character", "â–¿"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: triangleleft; with a semi-colon" do
    input = "&triangleleft;"
    output = [["Character", "â—ƒ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: trianglelefteq; with a semi-colon" do
    input = "&trianglelefteq;"
    output = [["Character", "âŠ´"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: triangleq; with a semi-colon" do
    input = "&triangleq;"
    output = [["Character", "â‰œ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: triangleright; with a semi-colon" do
    input = "&triangleright;"
    output = [["Character", "â–¹"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: trianglerighteq; with a semi-colon" do
    input = "&trianglerighteq;"
    output = [["Character", "âŠµ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: tridot; with a semi-colon" do
    input = "&tridot;"
    output = [["Character", "â—¬"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: trie; with a semi-colon" do
    input = "&trie;"
    output = [["Character", "â‰œ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: triminus; with a semi-colon" do
    input = "&triminus;"
    output = [["Character", "â¨º"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: triplus; with a semi-colon" do
    input = "&triplus;"
    output = [["Character", "â¨¹"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: trisb; with a semi-colon" do
    input = "&trisb;"
    output = [["Character", "â§"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: tritime; with a semi-colon" do
    input = "&tritime;"
    output = [["Character", "â¨»"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: trpezium; with a semi-colon" do
    input = "&trpezium;"
    output = [["Character", "â¢"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: tscr; with a semi-colon" do
    input = "&tscr;"
    output = [["Character", "ð“‰"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: tscy; with a semi-colon" do
    input = "&tscy;"
    output = [["Character", "Ñ†"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: tshcy; with a semi-colon" do
    input = "&tshcy;"
    output = [["Character", "Ñ›"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: tstrok; with a semi-colon" do
    input = "&tstrok;"
    output = [["Character", "Å§"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: twixt; with a semi-colon" do
    input = "&twixt;"
    output = [["Character", "â‰¬"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: twoheadleftarrow; with a semi-colon" do
    input = "&twoheadleftarrow;"
    output = [["Character", "â†ž"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: twoheadrightarrow; with a semi-colon" do
    input = "&twoheadrightarrow;"
    output = [["Character", "â† "]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: uArr; with a semi-colon" do
    input = "&uArr;"
    output = [["Character", "â‡‘"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: uHar; with a semi-colon" do
    input = "&uHar;"
    output = [["Character", "â¥£"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: uacute without a semi-colon" do
    input = "&uacute"
    output = [["Character", "Ãº"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: uacute; with a semi-colon" do
    input = "&uacute;"
    output = [["Character", "Ãº"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: uarr; with a semi-colon" do
    input = "&uarr;"
    output = [["Character", "â†‘"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ubrcy; with a semi-colon" do
    input = "&ubrcy;"
    output = [["Character", "Ñž"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ubreve; with a semi-colon" do
    input = "&ubreve;"
    output = [["Character", "Å­"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ucirc without a semi-colon" do
    input = "&ucirc"
    output = [["Character", "Ã»"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ucirc; with a semi-colon" do
    input = "&ucirc;"
    output = [["Character", "Ã»"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ucy; with a semi-colon" do
    input = "&ucy;"
    output = [["Character", "Ñƒ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: udarr; with a semi-colon" do
    input = "&udarr;"
    output = [["Character", "â‡…"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: udblac; with a semi-colon" do
    input = "&udblac;"
    output = [["Character", "Å±"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: udhar; with a semi-colon" do
    input = "&udhar;"
    output = [["Character", "â¥®"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ufisht; with a semi-colon" do
    input = "&ufisht;"
    output = [["Character", "â¥¾"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ufr; with a semi-colon" do
    input = "&ufr;"
    output = [["Character", "ð”²"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ugrave without a semi-colon" do
    input = "&ugrave"
    output = [["Character", "Ã¹"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ugrave; with a semi-colon" do
    input = "&ugrave;"
    output = [["Character", "Ã¹"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: uharl; with a semi-colon" do
    input = "&uharl;"
    output = [["Character", "â†¿"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: uharr; with a semi-colon" do
    input = "&uharr;"
    output = [["Character", "â†¾"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: uhblk; with a semi-colon" do
    input = "&uhblk;"
    output = [["Character", "â–€"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ulcorn; with a semi-colon" do
    input = "&ulcorn;"
    output = [["Character", "âŒœ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ulcorner; with a semi-colon" do
    input = "&ulcorner;"
    output = [["Character", "âŒœ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ulcrop; with a semi-colon" do
    input = "&ulcrop;"
    output = [["Character", "âŒ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ultri; with a semi-colon" do
    input = "&ultri;"
    output = [["Character", "â—¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: umacr; with a semi-colon" do
    input = "&umacr;"
    output = [["Character", "Å«"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: uml without a semi-colon" do
    input = "&uml"
    output = [["Character", "Â¨"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: uml; with a semi-colon" do
    input = "&uml;"
    output = [["Character", "Â¨"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: uogon; with a semi-colon" do
    input = "&uogon;"
    output = [["Character", "Å³"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: uopf; with a semi-colon" do
    input = "&uopf;"
    output = [["Character", "ð•¦"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: uparrow; with a semi-colon" do
    input = "&uparrow;"
    output = [["Character", "â†‘"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: updownarrow; with a semi-colon" do
    input = "&updownarrow;"
    output = [["Character", "â†•"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: upharpoonleft; with a semi-colon" do
    input = "&upharpoonleft;"
    output = [["Character", "â†¿"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: upharpoonright; with a semi-colon" do
    input = "&upharpoonright;"
    output = [["Character", "â†¾"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: uplus; with a semi-colon" do
    input = "&uplus;"
    output = [["Character", "âŠŽ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: upsi; with a semi-colon" do
    input = "&upsi;"
    output = [["Character", "Ï…"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: upsih; with a semi-colon" do
    input = "&upsih;"
    output = [["Character", "Ï’"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: upsilon; with a semi-colon" do
    input = "&upsilon;"
    output = [["Character", "Ï…"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: upuparrows; with a semi-colon" do
    input = "&upuparrows;"
    output = [["Character", "â‡ˆ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: urcorn; with a semi-colon" do
    input = "&urcorn;"
    output = [["Character", "âŒ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: urcorner; with a semi-colon" do
    input = "&urcorner;"
    output = [["Character", "âŒ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: urcrop; with a semi-colon" do
    input = "&urcrop;"
    output = [["Character", "âŒŽ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: uring; with a semi-colon" do
    input = "&uring;"
    output = [["Character", "Å¯"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: urtri; with a semi-colon" do
    input = "&urtri;"
    output = [["Character", "â—¹"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: uscr; with a semi-colon" do
    input = "&uscr;"
    output = [["Character", "ð“Š"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: utdot; with a semi-colon" do
    input = "&utdot;"
    output = [["Character", "â‹°"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: utilde; with a semi-colon" do
    input = "&utilde;"
    output = [["Character", "Å©"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end
end