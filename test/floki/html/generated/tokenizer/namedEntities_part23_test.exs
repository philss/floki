defmodule Floki.HTML.Generated.Tokenizer.NamedentitiesPart23Test do
  use ExUnit.Case, async: true

  # NOTE: This file was generated by "mix generate_tokenizer_tests namedEntities.test".
  # html5lib-tests rev: e52ff68cc7113a6ef3687747fa82691079bf9cc5

  alias Floki.HTML.Tokenizer

  test "tokenize/1 Named entity: InvisibleTimes; with a semi-colon" do
    input = "&InvisibleTimes;"
    output = [["Character", "â¢"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Iogon; with a semi-colon" do
    input = "&Iogon;"
    output = [["Character", "Ä®"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Iopf; with a semi-colon" do
    input = "&Iopf;"
    output = [["Character", "ð•€"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Iota; with a semi-colon" do
    input = "&Iota;"
    output = [["Character", "Î™"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Iscr; with a semi-colon" do
    input = "&Iscr;"
    output = [["Character", "â„"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Itilde; with a semi-colon" do
    input = "&Itilde;"
    output = [["Character", "Ä¨"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Iukcy; with a semi-colon" do
    input = "&Iukcy;"
    output = [["Character", "Ð†"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Iuml without a semi-colon" do
    input = "&Iuml"
    output = [["Character", "Ã"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Iuml; with a semi-colon" do
    input = "&Iuml;"
    output = [["Character", "Ã"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Jcirc; with a semi-colon" do
    input = "&Jcirc;"
    output = [["Character", "Ä´"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Jcy; with a semi-colon" do
    input = "&Jcy;"
    output = [["Character", "Ð™"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Jfr; with a semi-colon" do
    input = "&Jfr;"
    output = [["Character", "ð”"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Jopf; with a semi-colon" do
    input = "&Jopf;"
    output = [["Character", "ð•"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Jscr; with a semi-colon" do
    input = "&Jscr;"
    output = [["Character", "ð’¥"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Jsercy; with a semi-colon" do
    input = "&Jsercy;"
    output = [["Character", "Ðˆ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Jukcy; with a semi-colon" do
    input = "&Jukcy;"
    output = [["Character", "Ð„"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: KHcy; with a semi-colon" do
    input = "&KHcy;"
    output = [["Character", "Ð¥"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: KJcy; with a semi-colon" do
    input = "&KJcy;"
    output = [["Character", "ÐŒ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Kappa; with a semi-colon" do
    input = "&Kappa;"
    output = [["Character", "Îš"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Kcedil; with a semi-colon" do
    input = "&Kcedil;"
    output = [["Character", "Ä¶"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Kcy; with a semi-colon" do
    input = "&Kcy;"
    output = [["Character", "Ðš"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Kfr; with a semi-colon" do
    input = "&Kfr;"
    output = [["Character", "ð”Ž"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Kopf; with a semi-colon" do
    input = "&Kopf;"
    output = [["Character", "ð•‚"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Kscr; with a semi-colon" do
    input = "&Kscr;"
    output = [["Character", "ð’¦"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LJcy; with a semi-colon" do
    input = "&LJcy;"
    output = [["Character", "Ð‰"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LT without a semi-colon" do
    input = "&LT"
    output = [["Character", "<"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LT; with a semi-colon" do
    input = "&LT;"
    output = [["Character", "<"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Lacute; with a semi-colon" do
    input = "&Lacute;"
    output = [["Character", "Ä¹"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Lambda; with a semi-colon" do
    input = "&Lambda;"
    output = [["Character", "Î›"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Lang; with a semi-colon" do
    input = "&Lang;"
    output = [["Character", "âŸª"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Laplacetrf; with a semi-colon" do
    input = "&Laplacetrf;"
    output = [["Character", "â„’"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Larr; with a semi-colon" do
    input = "&Larr;"
    output = [["Character", "â†ž"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Lcaron; with a semi-colon" do
    input = "&Lcaron;"
    output = [["Character", "Ä½"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Lcedil; with a semi-colon" do
    input = "&Lcedil;"
    output = [["Character", "Ä»"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Lcy; with a semi-colon" do
    input = "&Lcy;"
    output = [["Character", "Ð›"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftAngleBracket; with a semi-colon" do
    input = "&LeftAngleBracket;"
    output = [["Character", "âŸ¨"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftArrow; with a semi-colon" do
    input = "&LeftArrow;"
    output = [["Character", "â†"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftArrowBar; with a semi-colon" do
    input = "&LeftArrowBar;"
    output = [["Character", "â‡¤"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftArrowRightArrow; with a semi-colon" do
    input = "&LeftArrowRightArrow;"
    output = [["Character", "â‡†"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftCeiling; with a semi-colon" do
    input = "&LeftCeiling;"
    output = [["Character", "âŒˆ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftDoubleBracket; with a semi-colon" do
    input = "&LeftDoubleBracket;"
    output = [["Character", "âŸ¦"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftDownTeeVector; with a semi-colon" do
    input = "&LeftDownTeeVector;"
    output = [["Character", "â¥¡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftDownVector; with a semi-colon" do
    input = "&LeftDownVector;"
    output = [["Character", "â‡ƒ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftDownVectorBar; with a semi-colon" do
    input = "&LeftDownVectorBar;"
    output = [["Character", "â¥™"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftFloor; with a semi-colon" do
    input = "&LeftFloor;"
    output = [["Character", "âŒŠ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftRightArrow; with a semi-colon" do
    input = "&LeftRightArrow;"
    output = [["Character", "â†”"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftRightVector; with a semi-colon" do
    input = "&LeftRightVector;"
    output = [["Character", "â¥Ž"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftTee; with a semi-colon" do
    input = "&LeftTee;"
    output = [["Character", "âŠ£"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftTeeArrow; with a semi-colon" do
    input = "&LeftTeeArrow;"
    output = [["Character", "â†¤"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftTeeVector; with a semi-colon" do
    input = "&LeftTeeVector;"
    output = [["Character", "â¥š"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftTriangle; with a semi-colon" do
    input = "&LeftTriangle;"
    output = [["Character", "âŠ²"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftTriangleBar; with a semi-colon" do
    input = "&LeftTriangleBar;"
    output = [["Character", "â§"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftTriangleEqual; with a semi-colon" do
    input = "&LeftTriangleEqual;"
    output = [["Character", "âŠ´"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftUpDownVector; with a semi-colon" do
    input = "&LeftUpDownVector;"
    output = [["Character", "â¥‘"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftUpTeeVector; with a semi-colon" do
    input = "&LeftUpTeeVector;"
    output = [["Character", "â¥ "]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftUpVector; with a semi-colon" do
    input = "&LeftUpVector;"
    output = [["Character", "â†¿"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftUpVectorBar; with a semi-colon" do
    input = "&LeftUpVectorBar;"
    output = [["Character", "â¥˜"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftVector; with a semi-colon" do
    input = "&LeftVector;"
    output = [["Character", "â†¼"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftVectorBar; with a semi-colon" do
    input = "&LeftVectorBar;"
    output = [["Character", "â¥’"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Leftarrow; with a semi-colon" do
    input = "&Leftarrow;"
    output = [["Character", "â‡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Leftrightarrow; with a semi-colon" do
    input = "&Leftrightarrow;"
    output = [["Character", "â‡”"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LessEqualGreater; with a semi-colon" do
    input = "&LessEqualGreater;"
    output = [["Character", "â‹š"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LessFullEqual; with a semi-colon" do
    input = "&LessFullEqual;"
    output = [["Character", "â‰¦"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LessGreater; with a semi-colon" do
    input = "&LessGreater;"
    output = [["Character", "â‰¶"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LessLess; with a semi-colon" do
    input = "&LessLess;"
    output = [["Character", "âª¡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LessSlantEqual; with a semi-colon" do
    input = "&LessSlantEqual;"
    output = [["Character", "â©½"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LessTilde; with a semi-colon" do
    input = "&LessTilde;"
    output = [["Character", "â‰²"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Lfr; with a semi-colon" do
    input = "&Lfr;"
    output = [["Character", "ð”"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ll; with a semi-colon" do
    input = "&Ll;"
    output = [["Character", "â‹˜"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Lleftarrow; with a semi-colon" do
    input = "&Lleftarrow;"
    output = [["Character", "â‡š"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Lmidot; with a semi-colon" do
    input = "&Lmidot;"
    output = [["Character", "Ä¿"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LongLeftArrow; with a semi-colon" do
    input = "&LongLeftArrow;"
    output = [["Character", "âŸµ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LongLeftRightArrow; with a semi-colon" do
    input = "&LongLeftRightArrow;"
    output = [["Character", "âŸ·"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LongRightArrow; with a semi-colon" do
    input = "&LongRightArrow;"
    output = [["Character", "âŸ¶"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Longleftarrow; with a semi-colon" do
    input = "&Longleftarrow;"
    output = [["Character", "âŸ¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Longleftrightarrow; with a semi-colon" do
    input = "&Longleftrightarrow;"
    output = [["Character", "âŸº"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Longrightarrow; with a semi-colon" do
    input = "&Longrightarrow;"
    output = [["Character", "âŸ¹"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Lopf; with a semi-colon" do
    input = "&Lopf;"
    output = [["Character", "ð•ƒ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LowerLeftArrow; with a semi-colon" do
    input = "&LowerLeftArrow;"
    output = [["Character", "â†™"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LowerRightArrow; with a semi-colon" do
    input = "&LowerRightArrow;"
    output = [["Character", "â†˜"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Lscr; with a semi-colon" do
    input = "&Lscr;"
    output = [["Character", "â„’"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Lsh; with a semi-colon" do
    input = "&Lsh;"
    output = [["Character", "â†°"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Lstrok; with a semi-colon" do
    input = "&Lstrok;"
    output = [["Character", "Å"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Lt; with a semi-colon" do
    input = "&Lt;"
    output = [["Character", "â‰ª"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Map; with a semi-colon" do
    input = "&Map;"
    output = [["Character", "â¤…"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Mcy; with a semi-colon" do
    input = "&Mcy;"
    output = [["Character", "Ðœ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: MediumSpace; with a semi-colon" do
    input = "&MediumSpace;"
    output = [["Character", "âŸ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Mellintrf; with a semi-colon" do
    input = "&Mellintrf;"
    output = [["Character", "â„³"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Mfr; with a semi-colon" do
    input = "&Mfr;"
    output = [["Character", "ð”"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: MinusPlus; with a semi-colon" do
    input = "&MinusPlus;"
    output = [["Character", "âˆ“"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Mopf; with a semi-colon" do
    input = "&Mopf;"
    output = [["Character", "ð•„"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Mscr; with a semi-colon" do
    input = "&Mscr;"
    output = [["Character", "â„³"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Mu; with a semi-colon" do
    input = "&Mu;"
    output = [["Character", "Îœ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NJcy; with a semi-colon" do
    input = "&NJcy;"
    output = [["Character", "ÐŠ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Nacute; with a semi-colon" do
    input = "&Nacute;"
    output = [["Character", "Åƒ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ncaron; with a semi-colon" do
    input = "&Ncaron;"
    output = [["Character", "Å‡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ncedil; with a semi-colon" do
    input = "&Ncedil;"
    output = [["Character", "Å…"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ncy; with a semi-colon" do
    input = "&Ncy;"
    output = [["Character", "Ð"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NegativeMediumSpace; with a semi-colon" do
    input = "&NegativeMediumSpace;"
    output = [["Character", "â€‹"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NegativeThickSpace; with a semi-colon" do
    input = "&NegativeThickSpace;"
    output = [["Character", "â€‹"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end
end