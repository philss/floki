defmodule Floki.HTML.Generated.Tokenizer.NamedentitiesPart23Test do
  use ExUnit.Case, async: true

  # NOTE: This file was generated by "mix generate_tokenizer_tests namedEntities.test".
  # html5lib-tests rev: e52ff68cc7113a6ef3687747fa82691079bf9cc5

  alias Floki.HTML.Tokenizer

  test "tokenize/1 Named entity: InvisibleTimes; with a semi-colon" do
    input = "&InvisibleTimes;"
    output = [["Character", "⁢"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Iogon; with a semi-colon" do
    input = "&Iogon;"
    output = [["Character", "Į"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Iopf; with a semi-colon" do
    input = "&Iopf;"
    output = [["Character", "𝕀"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Iota; with a semi-colon" do
    input = "&Iota;"
    output = [["Character", "Ι"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Iscr; with a semi-colon" do
    input = "&Iscr;"
    output = [["Character", "ℐ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Itilde; with a semi-colon" do
    input = "&Itilde;"
    output = [["Character", "Ĩ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Iukcy; with a semi-colon" do
    input = "&Iukcy;"
    output = [["Character", "І"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Iuml without a semi-colon" do
    input = "&Iuml"
    output = [["Character", "Ï"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Iuml; with a semi-colon" do
    input = "&Iuml;"
    output = [["Character", "Ï"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Jcirc; with a semi-colon" do
    input = "&Jcirc;"
    output = [["Character", "Ĵ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Jcy; with a semi-colon" do
    input = "&Jcy;"
    output = [["Character", "Й"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Jfr; with a semi-colon" do
    input = "&Jfr;"
    output = [["Character", "𝔍"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Jopf; with a semi-colon" do
    input = "&Jopf;"
    output = [["Character", "𝕁"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Jscr; with a semi-colon" do
    input = "&Jscr;"
    output = [["Character", "𝒥"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Jsercy; with a semi-colon" do
    input = "&Jsercy;"
    output = [["Character", "Ј"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Jukcy; with a semi-colon" do
    input = "&Jukcy;"
    output = [["Character", "Є"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: KHcy; with a semi-colon" do
    input = "&KHcy;"
    output = [["Character", "Х"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: KJcy; with a semi-colon" do
    input = "&KJcy;"
    output = [["Character", "Ќ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Kappa; with a semi-colon" do
    input = "&Kappa;"
    output = [["Character", "Κ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Kcedil; with a semi-colon" do
    input = "&Kcedil;"
    output = [["Character", "Ķ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Kcy; with a semi-colon" do
    input = "&Kcy;"
    output = [["Character", "К"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Kfr; with a semi-colon" do
    input = "&Kfr;"
    output = [["Character", "𝔎"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Kopf; with a semi-colon" do
    input = "&Kopf;"
    output = [["Character", "𝕂"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Kscr; with a semi-colon" do
    input = "&Kscr;"
    output = [["Character", "𝒦"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LJcy; with a semi-colon" do
    input = "&LJcy;"
    output = [["Character", "Љ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LT without a semi-colon" do
    input = "&LT"
    output = [["Character", "<"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LT; with a semi-colon" do
    input = "&LT;"
    output = [["Character", "<"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Lacute; with a semi-colon" do
    input = "&Lacute;"
    output = [["Character", "Ĺ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Lambda; with a semi-colon" do
    input = "&Lambda;"
    output = [["Character", "Λ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Lang; with a semi-colon" do
    input = "&Lang;"
    output = [["Character", "⟪"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Laplacetrf; with a semi-colon" do
    input = "&Laplacetrf;"
    output = [["Character", "ℒ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Larr; with a semi-colon" do
    input = "&Larr;"
    output = [["Character", "↞"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Lcaron; with a semi-colon" do
    input = "&Lcaron;"
    output = [["Character", "Ľ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Lcedil; with a semi-colon" do
    input = "&Lcedil;"
    output = [["Character", "Ļ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Lcy; with a semi-colon" do
    input = "&Lcy;"
    output = [["Character", "Л"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftAngleBracket; with a semi-colon" do
    input = "&LeftAngleBracket;"
    output = [["Character", "⟨"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftArrow; with a semi-colon" do
    input = "&LeftArrow;"
    output = [["Character", "←"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftArrowBar; with a semi-colon" do
    input = "&LeftArrowBar;"
    output = [["Character", "⇤"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftArrowRightArrow; with a semi-colon" do
    input = "&LeftArrowRightArrow;"
    output = [["Character", "⇆"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftCeiling; with a semi-colon" do
    input = "&LeftCeiling;"
    output = [["Character", "⌈"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftDoubleBracket; with a semi-colon" do
    input = "&LeftDoubleBracket;"
    output = [["Character", "⟦"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftDownTeeVector; with a semi-colon" do
    input = "&LeftDownTeeVector;"
    output = [["Character", "⥡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftDownVector; with a semi-colon" do
    input = "&LeftDownVector;"
    output = [["Character", "⇃"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftDownVectorBar; with a semi-colon" do
    input = "&LeftDownVectorBar;"
    output = [["Character", "⥙"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftFloor; with a semi-colon" do
    input = "&LeftFloor;"
    output = [["Character", "⌊"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftRightArrow; with a semi-colon" do
    input = "&LeftRightArrow;"
    output = [["Character", "↔"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftRightVector; with a semi-colon" do
    input = "&LeftRightVector;"
    output = [["Character", "⥎"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftTee; with a semi-colon" do
    input = "&LeftTee;"
    output = [["Character", "⊣"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftTeeArrow; with a semi-colon" do
    input = "&LeftTeeArrow;"
    output = [["Character", "↤"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftTeeVector; with a semi-colon" do
    input = "&LeftTeeVector;"
    output = [["Character", "⥚"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftTriangle; with a semi-colon" do
    input = "&LeftTriangle;"
    output = [["Character", "⊲"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftTriangleBar; with a semi-colon" do
    input = "&LeftTriangleBar;"
    output = [["Character", "⧏"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftTriangleEqual; with a semi-colon" do
    input = "&LeftTriangleEqual;"
    output = [["Character", "⊴"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftUpDownVector; with a semi-colon" do
    input = "&LeftUpDownVector;"
    output = [["Character", "⥑"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftUpTeeVector; with a semi-colon" do
    input = "&LeftUpTeeVector;"
    output = [["Character", "⥠"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftUpVector; with a semi-colon" do
    input = "&LeftUpVector;"
    output = [["Character", "↿"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftUpVectorBar; with a semi-colon" do
    input = "&LeftUpVectorBar;"
    output = [["Character", "⥘"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftVector; with a semi-colon" do
    input = "&LeftVector;"
    output = [["Character", "↼"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LeftVectorBar; with a semi-colon" do
    input = "&LeftVectorBar;"
    output = [["Character", "⥒"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Leftarrow; with a semi-colon" do
    input = "&Leftarrow;"
    output = [["Character", "⇐"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Leftrightarrow; with a semi-colon" do
    input = "&Leftrightarrow;"
    output = [["Character", "⇔"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LessEqualGreater; with a semi-colon" do
    input = "&LessEqualGreater;"
    output = [["Character", "⋚"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LessFullEqual; with a semi-colon" do
    input = "&LessFullEqual;"
    output = [["Character", "≦"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LessGreater; with a semi-colon" do
    input = "&LessGreater;"
    output = [["Character", "≶"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LessLess; with a semi-colon" do
    input = "&LessLess;"
    output = [["Character", "⪡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LessSlantEqual; with a semi-colon" do
    input = "&LessSlantEqual;"
    output = [["Character", "⩽"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LessTilde; with a semi-colon" do
    input = "&LessTilde;"
    output = [["Character", "≲"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Lfr; with a semi-colon" do
    input = "&Lfr;"
    output = [["Character", "𝔏"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ll; with a semi-colon" do
    input = "&Ll;"
    output = [["Character", "⋘"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Lleftarrow; with a semi-colon" do
    input = "&Lleftarrow;"
    output = [["Character", "⇚"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Lmidot; with a semi-colon" do
    input = "&Lmidot;"
    output = [["Character", "Ŀ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LongLeftArrow; with a semi-colon" do
    input = "&LongLeftArrow;"
    output = [["Character", "⟵"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LongLeftRightArrow; with a semi-colon" do
    input = "&LongLeftRightArrow;"
    output = [["Character", "⟷"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LongRightArrow; with a semi-colon" do
    input = "&LongRightArrow;"
    output = [["Character", "⟶"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Longleftarrow; with a semi-colon" do
    input = "&Longleftarrow;"
    output = [["Character", "⟸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Longleftrightarrow; with a semi-colon" do
    input = "&Longleftrightarrow;"
    output = [["Character", "⟺"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Longrightarrow; with a semi-colon" do
    input = "&Longrightarrow;"
    output = [["Character", "⟹"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Lopf; with a semi-colon" do
    input = "&Lopf;"
    output = [["Character", "𝕃"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LowerLeftArrow; with a semi-colon" do
    input = "&LowerLeftArrow;"
    output = [["Character", "↙"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: LowerRightArrow; with a semi-colon" do
    input = "&LowerRightArrow;"
    output = [["Character", "↘"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Lscr; with a semi-colon" do
    input = "&Lscr;"
    output = [["Character", "ℒ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Lsh; with a semi-colon" do
    input = "&Lsh;"
    output = [["Character", "↰"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Lstrok; with a semi-colon" do
    input = "&Lstrok;"
    output = [["Character", "Ł"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Lt; with a semi-colon" do
    input = "&Lt;"
    output = [["Character", "≪"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Map; with a semi-colon" do
    input = "&Map;"
    output = [["Character", "⤅"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Mcy; with a semi-colon" do
    input = "&Mcy;"
    output = [["Character", "М"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: MediumSpace; with a semi-colon" do
    input = "&MediumSpace;"
    output = [["Character", " "]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Mellintrf; with a semi-colon" do
    input = "&Mellintrf;"
    output = [["Character", "ℳ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Mfr; with a semi-colon" do
    input = "&Mfr;"
    output = [["Character", "𝔐"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: MinusPlus; with a semi-colon" do
    input = "&MinusPlus;"
    output = [["Character", "∓"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Mopf; with a semi-colon" do
    input = "&Mopf;"
    output = [["Character", "𝕄"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Mscr; with a semi-colon" do
    input = "&Mscr;"
    output = [["Character", "ℳ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Mu; with a semi-colon" do
    input = "&Mu;"
    output = [["Character", "Μ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NJcy; with a semi-colon" do
    input = "&NJcy;"
    output = [["Character", "Њ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Nacute; with a semi-colon" do
    input = "&Nacute;"
    output = [["Character", "Ń"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ncaron; with a semi-colon" do
    input = "&Ncaron;"
    output = [["Character", "Ň"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ncedil; with a semi-colon" do
    input = "&Ncedil;"
    output = [["Character", "Ņ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ncy; with a semi-colon" do
    input = "&Ncy;"
    output = [["Character", "Н"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NegativeMediumSpace; with a semi-colon" do
    input = "&NegativeMediumSpace;"
    output = [["Character", "​"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NegativeThickSpace; with a semi-colon" do
    input = "&NegativeThickSpace;"
    output = [["Character", "​"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end
end