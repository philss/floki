defmodule Floki.HTML.Generated.Tokenizer.NamedentitiesPart15Test do
  use ExUnit.Case, async: true

  # NOTE: This file was generated by "mix generate_tokenizer_tests namedEntities.test".
  # html5lib-tests rev: e52ff68cc7113a6ef3687747fa82691079bf9cc5

  alias Floki.HTML.Tokenizer

  test "tokenize/1 Bad named entity: ntrianglelefteq without a semi-colon" do
    input = "&ntrianglelefteq"
    output = [["Character", "&ntrianglelefteq"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: ntriangleright without a semi-colon" do
    input = "&ntriangleright"
    output = [["Character", "&ntriangleright"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: ntrianglerighteq without a semi-colon" do
    input = "&ntrianglerighteq"
    output = [["Character", "&ntrianglerighteq"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: nu without a semi-colon" do
    input = "&nu"
    output = [["Character", "&nu"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: num without a semi-colon" do
    input = "&num"
    output = [["Character", "&num"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: numero without a semi-colon" do
    input = "&numero"
    output = [["Character", "&numero"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: numsp without a semi-colon" do
    input = "&numsp"
    output = [["Character", "&numsp"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: nvDash without a semi-colon" do
    input = "&nvDash"
    output = [["Character", "&nvDash"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: nvHarr without a semi-colon" do
    input = "&nvHarr"
    output = [["Character", "&nvHarr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: nvap without a semi-colon" do
    input = "&nvap"
    output = [["Character", "&nvap"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: nvdash without a semi-colon" do
    input = "&nvdash"
    output = [["Character", "&nvdash"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: nvge without a semi-colon" do
    input = "&nvge"
    output = [["Character", "&nvge"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: nvgt without a semi-colon" do
    input = "&nvgt"
    output = [["Character", "&nvgt"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: nvinfin without a semi-colon" do
    input = "&nvinfin"
    output = [["Character", "&nvinfin"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: nvlArr without a semi-colon" do
    input = "&nvlArr"
    output = [["Character", "&nvlArr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: nvle without a semi-colon" do
    input = "&nvle"
    output = [["Character", "&nvle"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: nvlt without a semi-colon" do
    input = "&nvlt"
    output = [["Character", "&nvlt"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: nvltrie without a semi-colon" do
    input = "&nvltrie"
    output = [["Character", "&nvltrie"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: nvrArr without a semi-colon" do
    input = "&nvrArr"
    output = [["Character", "&nvrArr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: nvrtrie without a semi-colon" do
    input = "&nvrtrie"
    output = [["Character", "&nvrtrie"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: nvsim without a semi-colon" do
    input = "&nvsim"
    output = [["Character", "&nvsim"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: nwArr without a semi-colon" do
    input = "&nwArr"
    output = [["Character", "&nwArr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: nwarhk without a semi-colon" do
    input = "&nwarhk"
    output = [["Character", "&nwarhk"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: nwarr without a semi-colon" do
    input = "&nwarr"
    output = [["Character", "&nwarr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: nwarrow without a semi-colon" do
    input = "&nwarrow"
    output = [["Character", "&nwarrow"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: nwnear without a semi-colon" do
    input = "&nwnear"
    output = [["Character", "&nwnear"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: oS without a semi-colon" do
    input = "&oS"
    output = [["Character", "&oS"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: oast without a semi-colon" do
    input = "&oast"
    output = [["Character", "&oast"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: ocir without a semi-colon" do
    input = "&ocir"
    output = [["Character", "&ocir"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: ocy without a semi-colon" do
    input = "&ocy"
    output = [["Character", "&ocy"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: odash without a semi-colon" do
    input = "&odash"
    output = [["Character", "&odash"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: odblac without a semi-colon" do
    input = "&odblac"
    output = [["Character", "&odblac"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: odiv without a semi-colon" do
    input = "&odiv"
    output = [["Character", "&odiv"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: odot without a semi-colon" do
    input = "&odot"
    output = [["Character", "&odot"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: odsold without a semi-colon" do
    input = "&odsold"
    output = [["Character", "&odsold"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: oelig without a semi-colon" do
    input = "&oelig"
    output = [["Character", "&oelig"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: ofcir without a semi-colon" do
    input = "&ofcir"
    output = [["Character", "&ofcir"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: ofr without a semi-colon" do
    input = "&ofr"
    output = [["Character", "&ofr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: ogon without a semi-colon" do
    input = "&ogon"
    output = [["Character", "&ogon"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: ogt without a semi-colon" do
    input = "&ogt"
    output = [["Character", "&ogt"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: ohbar without a semi-colon" do
    input = "&ohbar"
    output = [["Character", "&ohbar"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: ohm without a semi-colon" do
    input = "&ohm"
    output = [["Character", "&ohm"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: oint without a semi-colon" do
    input = "&oint"
    output = [["Character", "&oint"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: olarr without a semi-colon" do
    input = "&olarr"
    output = [["Character", "&olarr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: olcir without a semi-colon" do
    input = "&olcir"
    output = [["Character", "&olcir"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: olcross without a semi-colon" do
    input = "&olcross"
    output = [["Character", "&olcross"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: oline without a semi-colon" do
    input = "&oline"
    output = [["Character", "&oline"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: olt without a semi-colon" do
    input = "&olt"
    output = [["Character", "&olt"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: omacr without a semi-colon" do
    input = "&omacr"
    output = [["Character", "&omacr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: omega without a semi-colon" do
    input = "&omega"
    output = [["Character", "&omega"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: omicron without a semi-colon" do
    input = "&omicron"
    output = [["Character", "&omicron"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: omid without a semi-colon" do
    input = "&omid"
    output = [["Character", "&omid"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: ominus without a semi-colon" do
    input = "&ominus"
    output = [["Character", "&ominus"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: oopf without a semi-colon" do
    input = "&oopf"
    output = [["Character", "&oopf"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: opar without a semi-colon" do
    input = "&opar"
    output = [["Character", "&opar"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: operp without a semi-colon" do
    input = "&operp"
    output = [["Character", "&operp"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: oplus without a semi-colon" do
    input = "&oplus"
    output = [["Character", "&oplus"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: or without a semi-colon" do
    input = "&or"
    output = [["Character", "&or"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: orarr without a semi-colon" do
    input = "&orarr"
    output = [["Character", "&orarr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: ord without a semi-colon" do
    input = "&ord"
    output = [["Character", "&ord"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: order without a semi-colon" do
    input = "&order"
    output = [["Character", "&order"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: orderof without a semi-colon" do
    input = "&orderof"
    output = [["Character", "&orderof"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: origof without a semi-colon" do
    input = "&origof"
    output = [["Character", "&origof"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: oror without a semi-colon" do
    input = "&oror"
    output = [["Character", "&oror"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: orslope without a semi-colon" do
    input = "&orslope"
    output = [["Character", "&orslope"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: orv without a semi-colon" do
    input = "&orv"
    output = [["Character", "&orv"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: oscr without a semi-colon" do
    input = "&oscr"
    output = [["Character", "&oscr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: osol without a semi-colon" do
    input = "&osol"
    output = [["Character", "&osol"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: otimes without a semi-colon" do
    input = "&otimes"
    output = [["Character", "&otimes"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: otimesas without a semi-colon" do
    input = "&otimesas"
    output = [["Character", "&otimesas"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: ovbar without a semi-colon" do
    input = "&ovbar"
    output = [["Character", "&ovbar"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: par without a semi-colon" do
    input = "&par"
    output = [["Character", "&par"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: parsim without a semi-colon" do
    input = "&parsim"
    output = [["Character", "&parsim"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: parsl without a semi-colon" do
    input = "&parsl"
    output = [["Character", "&parsl"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: part without a semi-colon" do
    input = "&part"
    output = [["Character", "&part"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: pcy without a semi-colon" do
    input = "&pcy"
    output = [["Character", "&pcy"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: percnt without a semi-colon" do
    input = "&percnt"
    output = [["Character", "&percnt"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: period without a semi-colon" do
    input = "&period"
    output = [["Character", "&period"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: permil without a semi-colon" do
    input = "&permil"
    output = [["Character", "&permil"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: perp without a semi-colon" do
    input = "&perp"
    output = [["Character", "&perp"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: pertenk without a semi-colon" do
    input = "&pertenk"
    output = [["Character", "&pertenk"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: pfr without a semi-colon" do
    input = "&pfr"
    output = [["Character", "&pfr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: phi without a semi-colon" do
    input = "&phi"
    output = [["Character", "&phi"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: phiv without a semi-colon" do
    input = "&phiv"
    output = [["Character", "&phiv"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: phmmat without a semi-colon" do
    input = "&phmmat"
    output = [["Character", "&phmmat"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: phone without a semi-colon" do
    input = "&phone"
    output = [["Character", "&phone"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: pi without a semi-colon" do
    input = "&pi"
    output = [["Character", "&pi"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: pitchfork without a semi-colon" do
    input = "&pitchfork"
    output = [["Character", "&pitchfork"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: piv without a semi-colon" do
    input = "&piv"
    output = [["Character", "&piv"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: planck without a semi-colon" do
    input = "&planck"
    output = [["Character", "&planck"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: planckh without a semi-colon" do
    input = "&planckh"
    output = [["Character", "&planckh"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: plankv without a semi-colon" do
    input = "&plankv"
    output = [["Character", "&plankv"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: plus without a semi-colon" do
    input = "&plus"
    output = [["Character", "&plus"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: plusacir without a semi-colon" do
    input = "&plusacir"
    output = [["Character", "&plusacir"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: plusb without a semi-colon" do
    input = "&plusb"
    output = [["Character", "&plusb"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: pluscir without a semi-colon" do
    input = "&pluscir"
    output = [["Character", "&pluscir"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: plusdo without a semi-colon" do
    input = "&plusdo"
    output = [["Character", "&plusdo"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: plusdu without a semi-colon" do
    input = "&plusdu"
    output = [["Character", "&plusdu"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: pluse without a semi-colon" do
    input = "&pluse"
    output = [["Character", "&pluse"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: plussim without a semi-colon" do
    input = "&plussim"
    output = [["Character", "&plussim"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end
end
