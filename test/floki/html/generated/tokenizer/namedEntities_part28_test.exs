defmodule Floki.HTML.Generated.Tokenizer.NamedentitiesPart28Test do
  use ExUnit.Case, async: true

  # NOTE: This file was generated by "mix generate_tokenizer_tests namedEntities.test".
  # html5lib-tests rev: e52ff68cc7113a6ef3687747fa82691079bf9cc5

  alias Floki.HTML.Tokenizer

  test "tokenize/1 Named entity: bernou; with a semi-colon" do
    input = "&bernou;"
    output = [["Character", "â„¬"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: beta; with a semi-colon" do
    input = "&beta;"
    output = [["Character", "Î²"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: beth; with a semi-colon" do
    input = "&beth;"
    output = [["Character", "â„¶"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: between; with a semi-colon" do
    input = "&between;"
    output = [["Character", "â‰¬"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bfr; with a semi-colon" do
    input = "&bfr;"
    output = [["Character", "ð”Ÿ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bigcap; with a semi-colon" do
    input = "&bigcap;"
    output = [["Character", "â‹‚"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bigcirc; with a semi-colon" do
    input = "&bigcirc;"
    output = [["Character", "â—¯"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bigcup; with a semi-colon" do
    input = "&bigcup;"
    output = [["Character", "â‹ƒ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bigodot; with a semi-colon" do
    input = "&bigodot;"
    output = [["Character", "â¨€"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bigoplus; with a semi-colon" do
    input = "&bigoplus;"
    output = [["Character", "â¨"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bigotimes; with a semi-colon" do
    input = "&bigotimes;"
    output = [["Character", "â¨‚"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bigsqcup; with a semi-colon" do
    input = "&bigsqcup;"
    output = [["Character", "â¨†"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bigstar; with a semi-colon" do
    input = "&bigstar;"
    output = [["Character", "â˜…"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bigtriangledown; with a semi-colon" do
    input = "&bigtriangledown;"
    output = [["Character", "â–½"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bigtriangleup; with a semi-colon" do
    input = "&bigtriangleup;"
    output = [["Character", "â–³"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: biguplus; with a semi-colon" do
    input = "&biguplus;"
    output = [["Character", "â¨„"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bigvee; with a semi-colon" do
    input = "&bigvee;"
    output = [["Character", "â‹"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bigwedge; with a semi-colon" do
    input = "&bigwedge;"
    output = [["Character", "â‹€"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bkarow; with a semi-colon" do
    input = "&bkarow;"
    output = [["Character", "â¤"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: blacklozenge; with a semi-colon" do
    input = "&blacklozenge;"
    output = [["Character", "â§«"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: blacksquare; with a semi-colon" do
    input = "&blacksquare;"
    output = [["Character", "â–ª"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: blacktriangle; with a semi-colon" do
    input = "&blacktriangle;"
    output = [["Character", "â–´"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: blacktriangledown; with a semi-colon" do
    input = "&blacktriangledown;"
    output = [["Character", "â–¾"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: blacktriangleleft; with a semi-colon" do
    input = "&blacktriangleleft;"
    output = [["Character", "â—‚"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: blacktriangleright; with a semi-colon" do
    input = "&blacktriangleright;"
    output = [["Character", "â–¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: blank; with a semi-colon" do
    input = "&blank;"
    output = [["Character", "â£"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: blk12; with a semi-colon" do
    input = "&blk12;"
    output = [["Character", "â–’"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: blk14; with a semi-colon" do
    input = "&blk14;"
    output = [["Character", "â–‘"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: blk34; with a semi-colon" do
    input = "&blk34;"
    output = [["Character", "â–“"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: block; with a semi-colon" do
    input = "&block;"
    output = [["Character", "â–ˆ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bne; with a semi-colon" do
    input = "&bne;"
    output = [["Character", "=âƒ¥"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bnequiv; with a semi-colon" do
    input = "&bnequiv;"
    output = [["Character", "â‰¡âƒ¥"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bnot; with a semi-colon" do
    input = "&bnot;"
    output = [["Character", "âŒ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bopf; with a semi-colon" do
    input = "&bopf;"
    output = [["Character", "ð•“"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bot; with a semi-colon" do
    input = "&bot;"
    output = [["Character", "âŠ¥"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bottom; with a semi-colon" do
    input = "&bottom;"
    output = [["Character", "âŠ¥"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bowtie; with a semi-colon" do
    input = "&bowtie;"
    output = [["Character", "â‹ˆ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxDL; with a semi-colon" do
    input = "&boxDL;"
    output = [["Character", "â•—"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxDR; with a semi-colon" do
    input = "&boxDR;"
    output = [["Character", "â•”"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxDl; with a semi-colon" do
    input = "&boxDl;"
    output = [["Character", "â•–"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxDr; with a semi-colon" do
    input = "&boxDr;"
    output = [["Character", "â•“"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxH; with a semi-colon" do
    input = "&boxH;"
    output = [["Character", "â•"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxHD; with a semi-colon" do
    input = "&boxHD;"
    output = [["Character", "â•¦"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxHU; with a semi-colon" do
    input = "&boxHU;"
    output = [["Character", "â•©"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxHd; with a semi-colon" do
    input = "&boxHd;"
    output = [["Character", "â•¤"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxHu; with a semi-colon" do
    input = "&boxHu;"
    output = [["Character", "â•§"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxUL; with a semi-colon" do
    input = "&boxUL;"
    output = [["Character", "â•"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxUR; with a semi-colon" do
    input = "&boxUR;"
    output = [["Character", "â•š"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxUl; with a semi-colon" do
    input = "&boxUl;"
    output = [["Character", "â•œ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxUr; with a semi-colon" do
    input = "&boxUr;"
    output = [["Character", "â•™"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxV; with a semi-colon" do
    input = "&boxV;"
    output = [["Character", "â•‘"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxVH; with a semi-colon" do
    input = "&boxVH;"
    output = [["Character", "â•¬"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxVL; with a semi-colon" do
    input = "&boxVL;"
    output = [["Character", "â•£"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxVR; with a semi-colon" do
    input = "&boxVR;"
    output = [["Character", "â• "]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxVh; with a semi-colon" do
    input = "&boxVh;"
    output = [["Character", "â•«"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxVl; with a semi-colon" do
    input = "&boxVl;"
    output = [["Character", "â•¢"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxVr; with a semi-colon" do
    input = "&boxVr;"
    output = [["Character", "â•Ÿ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxbox; with a semi-colon" do
    input = "&boxbox;"
    output = [["Character", "â§‰"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxdL; with a semi-colon" do
    input = "&boxdL;"
    output = [["Character", "â••"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxdR; with a semi-colon" do
    input = "&boxdR;"
    output = [["Character", "â•’"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxdl; with a semi-colon" do
    input = "&boxdl;"
    output = [["Character", "â”"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxdr; with a semi-colon" do
    input = "&boxdr;"
    output = [["Character", "â”Œ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxh; with a semi-colon" do
    input = "&boxh;"
    output = [["Character", "â”€"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxhD; with a semi-colon" do
    input = "&boxhD;"
    output = [["Character", "â•¥"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxhU; with a semi-colon" do
    input = "&boxhU;"
    output = [["Character", "â•¨"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxhd; with a semi-colon" do
    input = "&boxhd;"
    output = [["Character", "â”¬"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxhu; with a semi-colon" do
    input = "&boxhu;"
    output = [["Character", "â”´"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxminus; with a semi-colon" do
    input = "&boxminus;"
    output = [["Character", "âŠŸ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxplus; with a semi-colon" do
    input = "&boxplus;"
    output = [["Character", "âŠž"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxtimes; with a semi-colon" do
    input = "&boxtimes;"
    output = [["Character", "âŠ "]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxuL; with a semi-colon" do
    input = "&boxuL;"
    output = [["Character", "â•›"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxuR; with a semi-colon" do
    input = "&boxuR;"
    output = [["Character", "â•˜"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxul; with a semi-colon" do
    input = "&boxul;"
    output = [["Character", "â”˜"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxur; with a semi-colon" do
    input = "&boxur;"
    output = [["Character", "â””"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxv; with a semi-colon" do
    input = "&boxv;"
    output = [["Character", "â”‚"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxvH; with a semi-colon" do
    input = "&boxvH;"
    output = [["Character", "â•ª"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxvL; with a semi-colon" do
    input = "&boxvL;"
    output = [["Character", "â•¡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxvR; with a semi-colon" do
    input = "&boxvR;"
    output = [["Character", "â•ž"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxvh; with a semi-colon" do
    input = "&boxvh;"
    output = [["Character", "â”¼"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxvl; with a semi-colon" do
    input = "&boxvl;"
    output = [["Character", "â”¤"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxvr; with a semi-colon" do
    input = "&boxvr;"
    output = [["Character", "â”œ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bprime; with a semi-colon" do
    input = "&bprime;"
    output = [["Character", "â€µ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: breve; with a semi-colon" do
    input = "&breve;"
    output = [["Character", "Ë˜"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: brvbar without a semi-colon" do
    input = "&brvbar"
    output = [["Character", "Â¦"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: brvbar; with a semi-colon" do
    input = "&brvbar;"
    output = [["Character", "Â¦"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bscr; with a semi-colon" do
    input = "&bscr;"
    output = [["Character", "ð’·"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bsemi; with a semi-colon" do
    input = "&bsemi;"
    output = [["Character", "â"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bsim; with a semi-colon" do
    input = "&bsim;"
    output = [["Character", "âˆ½"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bsime; with a semi-colon" do
    input = "&bsime;"
    output = [["Character", "â‹"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bsol; with a semi-colon" do
    input = "&bsol;"
    output = [["Character", "\\"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bsolb; with a semi-colon" do
    input = "&bsolb;"
    output = [["Character", "â§…"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bsolhsub; with a semi-colon" do
    input = "&bsolhsub;"
    output = [["Character", "âŸˆ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bull; with a semi-colon" do
    input = "&bull;"
    output = [["Character", "â€¢"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bullet; with a semi-colon" do
    input = "&bullet;"
    output = [["Character", "â€¢"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bump; with a semi-colon" do
    input = "&bump;"
    output = [["Character", "â‰Ž"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bumpE; with a semi-colon" do
    input = "&bumpE;"
    output = [["Character", "âª®"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bumpe; with a semi-colon" do
    input = "&bumpe;"
    output = [["Character", "â‰"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bumpeq; with a semi-colon" do
    input = "&bumpeq;"
    output = [["Character", "â‰"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: cacute; with a semi-colon" do
    input = "&cacute;"
    output = [["Character", "Ä‡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: cap; with a semi-colon" do
    input = "&cap;"
    output = [["Character", "âˆ©"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end
end
