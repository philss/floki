defmodule Floki.HTML.Generated.Tokenizer.NamedentitiesPart28Test do
  use ExUnit.Case, async: true

  # NOTE: This file was generated by "mix generate_tokenizer_tests namedEntities.test".
  # html5lib-tests rev: e52ff68cc7113a6ef3687747fa82691079bf9cc5

  alias Floki.HTML.Tokenizer

  test "tokenize/1 Named entity: bernou; with a semi-colon" do
    input = "&bernou;"
    output = [["Character", "ℬ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: beta; with a semi-colon" do
    input = "&beta;"
    output = [["Character", "β"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: beth; with a semi-colon" do
    input = "&beth;"
    output = [["Character", "ℶ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: between; with a semi-colon" do
    input = "&between;"
    output = [["Character", "≬"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bfr; with a semi-colon" do
    input = "&bfr;"
    output = [["Character", "𝔟"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bigcap; with a semi-colon" do
    input = "&bigcap;"
    output = [["Character", "⋂"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bigcirc; with a semi-colon" do
    input = "&bigcirc;"
    output = [["Character", "◯"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bigcup; with a semi-colon" do
    input = "&bigcup;"
    output = [["Character", "⋃"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bigodot; with a semi-colon" do
    input = "&bigodot;"
    output = [["Character", "⨀"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bigoplus; with a semi-colon" do
    input = "&bigoplus;"
    output = [["Character", "⨁"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bigotimes; with a semi-colon" do
    input = "&bigotimes;"
    output = [["Character", "⨂"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bigsqcup; with a semi-colon" do
    input = "&bigsqcup;"
    output = [["Character", "⨆"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bigstar; with a semi-colon" do
    input = "&bigstar;"
    output = [["Character", "★"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bigtriangledown; with a semi-colon" do
    input = "&bigtriangledown;"
    output = [["Character", "▽"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bigtriangleup; with a semi-colon" do
    input = "&bigtriangleup;"
    output = [["Character", "△"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: biguplus; with a semi-colon" do
    input = "&biguplus;"
    output = [["Character", "⨄"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bigvee; with a semi-colon" do
    input = "&bigvee;"
    output = [["Character", "⋁"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bigwedge; with a semi-colon" do
    input = "&bigwedge;"
    output = [["Character", "⋀"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bkarow; with a semi-colon" do
    input = "&bkarow;"
    output = [["Character", "⤍"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: blacklozenge; with a semi-colon" do
    input = "&blacklozenge;"
    output = [["Character", "⧫"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: blacksquare; with a semi-colon" do
    input = "&blacksquare;"
    output = [["Character", "▪"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: blacktriangle; with a semi-colon" do
    input = "&blacktriangle;"
    output = [["Character", "▴"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: blacktriangledown; with a semi-colon" do
    input = "&blacktriangledown;"
    output = [["Character", "▾"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: blacktriangleleft; with a semi-colon" do
    input = "&blacktriangleleft;"
    output = [["Character", "◂"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: blacktriangleright; with a semi-colon" do
    input = "&blacktriangleright;"
    output = [["Character", "▸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: blank; with a semi-colon" do
    input = "&blank;"
    output = [["Character", "␣"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: blk12; with a semi-colon" do
    input = "&blk12;"
    output = [["Character", "▒"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: blk14; with a semi-colon" do
    input = "&blk14;"
    output = [["Character", "░"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: blk34; with a semi-colon" do
    input = "&blk34;"
    output = [["Character", "▓"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: block; with a semi-colon" do
    input = "&block;"
    output = [["Character", "█"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bne; with a semi-colon" do
    input = "&bne;"
    output = [["Character", "=⃥"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bnequiv; with a semi-colon" do
    input = "&bnequiv;"
    output = [["Character", "≡⃥"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bnot; with a semi-colon" do
    input = "&bnot;"
    output = [["Character", "⌐"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bopf; with a semi-colon" do
    input = "&bopf;"
    output = [["Character", "𝕓"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bot; with a semi-colon" do
    input = "&bot;"
    output = [["Character", "⊥"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bottom; with a semi-colon" do
    input = "&bottom;"
    output = [["Character", "⊥"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bowtie; with a semi-colon" do
    input = "&bowtie;"
    output = [["Character", "⋈"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxDL; with a semi-colon" do
    input = "&boxDL;"
    output = [["Character", "╗"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxDR; with a semi-colon" do
    input = "&boxDR;"
    output = [["Character", "╔"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxDl; with a semi-colon" do
    input = "&boxDl;"
    output = [["Character", "╖"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxDr; with a semi-colon" do
    input = "&boxDr;"
    output = [["Character", "╓"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxH; with a semi-colon" do
    input = "&boxH;"
    output = [["Character", "═"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxHD; with a semi-colon" do
    input = "&boxHD;"
    output = [["Character", "╦"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxHU; with a semi-colon" do
    input = "&boxHU;"
    output = [["Character", "╩"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxHd; with a semi-colon" do
    input = "&boxHd;"
    output = [["Character", "╤"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxHu; with a semi-colon" do
    input = "&boxHu;"
    output = [["Character", "╧"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxUL; with a semi-colon" do
    input = "&boxUL;"
    output = [["Character", "╝"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxUR; with a semi-colon" do
    input = "&boxUR;"
    output = [["Character", "╚"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxUl; with a semi-colon" do
    input = "&boxUl;"
    output = [["Character", "╜"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxUr; with a semi-colon" do
    input = "&boxUr;"
    output = [["Character", "╙"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxV; with a semi-colon" do
    input = "&boxV;"
    output = [["Character", "║"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxVH; with a semi-colon" do
    input = "&boxVH;"
    output = [["Character", "╬"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxVL; with a semi-colon" do
    input = "&boxVL;"
    output = [["Character", "╣"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxVR; with a semi-colon" do
    input = "&boxVR;"
    output = [["Character", "╠"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxVh; with a semi-colon" do
    input = "&boxVh;"
    output = [["Character", "╫"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxVl; with a semi-colon" do
    input = "&boxVl;"
    output = [["Character", "╢"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxVr; with a semi-colon" do
    input = "&boxVr;"
    output = [["Character", "╟"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxbox; with a semi-colon" do
    input = "&boxbox;"
    output = [["Character", "⧉"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxdL; with a semi-colon" do
    input = "&boxdL;"
    output = [["Character", "╕"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxdR; with a semi-colon" do
    input = "&boxdR;"
    output = [["Character", "╒"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxdl; with a semi-colon" do
    input = "&boxdl;"
    output = [["Character", "┐"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxdr; with a semi-colon" do
    input = "&boxdr;"
    output = [["Character", "┌"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxh; with a semi-colon" do
    input = "&boxh;"
    output = [["Character", "─"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxhD; with a semi-colon" do
    input = "&boxhD;"
    output = [["Character", "╥"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxhU; with a semi-colon" do
    input = "&boxhU;"
    output = [["Character", "╨"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxhd; with a semi-colon" do
    input = "&boxhd;"
    output = [["Character", "┬"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxhu; with a semi-colon" do
    input = "&boxhu;"
    output = [["Character", "┴"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxminus; with a semi-colon" do
    input = "&boxminus;"
    output = [["Character", "⊟"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxplus; with a semi-colon" do
    input = "&boxplus;"
    output = [["Character", "⊞"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxtimes; with a semi-colon" do
    input = "&boxtimes;"
    output = [["Character", "⊠"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxuL; with a semi-colon" do
    input = "&boxuL;"
    output = [["Character", "╛"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxuR; with a semi-colon" do
    input = "&boxuR;"
    output = [["Character", "╘"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxul; with a semi-colon" do
    input = "&boxul;"
    output = [["Character", "┘"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxur; with a semi-colon" do
    input = "&boxur;"
    output = [["Character", "└"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxv; with a semi-colon" do
    input = "&boxv;"
    output = [["Character", "│"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxvH; with a semi-colon" do
    input = "&boxvH;"
    output = [["Character", "╪"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxvL; with a semi-colon" do
    input = "&boxvL;"
    output = [["Character", "╡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxvR; with a semi-colon" do
    input = "&boxvR;"
    output = [["Character", "╞"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxvh; with a semi-colon" do
    input = "&boxvh;"
    output = [["Character", "┼"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxvl; with a semi-colon" do
    input = "&boxvl;"
    output = [["Character", "┤"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: boxvr; with a semi-colon" do
    input = "&boxvr;"
    output = [["Character", "├"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bprime; with a semi-colon" do
    input = "&bprime;"
    output = [["Character", "‵"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: breve; with a semi-colon" do
    input = "&breve;"
    output = [["Character", "˘"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: brvbar without a semi-colon" do
    input = "&brvbar"
    output = [["Character", "¦"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: brvbar; with a semi-colon" do
    input = "&brvbar;"
    output = [["Character", "¦"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bscr; with a semi-colon" do
    input = "&bscr;"
    output = [["Character", "𝒷"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bsemi; with a semi-colon" do
    input = "&bsemi;"
    output = [["Character", "⁏"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bsim; with a semi-colon" do
    input = "&bsim;"
    output = [["Character", "∽"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bsime; with a semi-colon" do
    input = "&bsime;"
    output = [["Character", "⋍"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bsol; with a semi-colon" do
    input = "&bsol;"
    output = [["Character", "\\"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bsolb; with a semi-colon" do
    input = "&bsolb;"
    output = [["Character", "⧅"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bsolhsub; with a semi-colon" do
    input = "&bsolhsub;"
    output = [["Character", "⟈"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bull; with a semi-colon" do
    input = "&bull;"
    output = [["Character", "•"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bullet; with a semi-colon" do
    input = "&bullet;"
    output = [["Character", "•"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bump; with a semi-colon" do
    input = "&bump;"
    output = [["Character", "≎"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bumpE; with a semi-colon" do
    input = "&bumpE;"
    output = [["Character", "⪮"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bumpe; with a semi-colon" do
    input = "&bumpe;"
    output = [["Character", "≏"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bumpeq; with a semi-colon" do
    input = "&bumpeq;"
    output = [["Character", "≏"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: cacute; with a semi-colon" do
    input = "&cacute;"
    output = [["Character", "ć"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: cap; with a semi-colon" do
    input = "&cap;"
    output = [["Character", "∩"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end
end
