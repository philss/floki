defmodule Floki.HTML.Generated.Tokenizer.NamedentitiesPart4Test do
  use ExUnit.Case, async: true

  # NOTE: This file was generated by "mix generate_tokenizer_tests namedEntities.test".
  # html5lib-tests rev: e52ff68cc7113a6ef3687747fa82691079bf9cc5

  alias Floki.HTML.Tokenizer

  test "tokenize/1 Bad named entity: NotGreaterLess without a semi-colon" do
    input = "&NotGreaterLess"
    output = [["Character", "&NotGreaterLess"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: NotGreaterSlantEqual without a semi-colon" do
    input = "&NotGreaterSlantEqual"
    output = [["Character", "&NotGreaterSlantEqual"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: NotGreaterTilde without a semi-colon" do
    input = "&NotGreaterTilde"
    output = [["Character", "&NotGreaterTilde"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: NotHumpDownHump without a semi-colon" do
    input = "&NotHumpDownHump"
    output = [["Character", "&NotHumpDownHump"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: NotHumpEqual without a semi-colon" do
    input = "&NotHumpEqual"
    output = [["Character", "&NotHumpEqual"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: NotLeftTriangle without a semi-colon" do
    input = "&NotLeftTriangle"
    output = [["Character", "&NotLeftTriangle"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: NotLeftTriangleBar without a semi-colon" do
    input = "&NotLeftTriangleBar"
    output = [["Character", "&NotLeftTriangleBar"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: NotLeftTriangleEqual without a semi-colon" do
    input = "&NotLeftTriangleEqual"
    output = [["Character", "&NotLeftTriangleEqual"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: NotLess without a semi-colon" do
    input = "&NotLess"
    output = [["Character", "&NotLess"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: NotLessEqual without a semi-colon" do
    input = "&NotLessEqual"
    output = [["Character", "&NotLessEqual"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: NotLessGreater without a semi-colon" do
    input = "&NotLessGreater"
    output = [["Character", "&NotLessGreater"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: NotLessLess without a semi-colon" do
    input = "&NotLessLess"
    output = [["Character", "&NotLessLess"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: NotLessSlantEqual without a semi-colon" do
    input = "&NotLessSlantEqual"
    output = [["Character", "&NotLessSlantEqual"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: NotLessTilde without a semi-colon" do
    input = "&NotLessTilde"
    output = [["Character", "&NotLessTilde"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: NotNestedGreaterGreater without a semi-colon" do
    input = "&NotNestedGreaterGreater"
    output = [["Character", "&NotNestedGreaterGreater"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: NotNestedLessLess without a semi-colon" do
    input = "&NotNestedLessLess"
    output = [["Character", "&NotNestedLessLess"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: NotPrecedes without a semi-colon" do
    input = "&NotPrecedes"
    output = [["Character", "&NotPrecedes"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: NotPrecedesEqual without a semi-colon" do
    input = "&NotPrecedesEqual"
    output = [["Character", "&NotPrecedesEqual"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: NotPrecedesSlantEqual without a semi-colon" do
    input = "&NotPrecedesSlantEqual"
    output = [["Character", "&NotPrecedesSlantEqual"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: NotReverseElement without a semi-colon" do
    input = "&NotReverseElement"
    output = [["Character", "&NotReverseElement"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: NotRightTriangle without a semi-colon" do
    input = "&NotRightTriangle"
    output = [["Character", "&NotRightTriangle"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: NotRightTriangleBar without a semi-colon" do
    input = "&NotRightTriangleBar"
    output = [["Character", "&NotRightTriangleBar"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: NotRightTriangleEqual without a semi-colon" do
    input = "&NotRightTriangleEqual"
    output = [["Character", "&NotRightTriangleEqual"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: NotSquareSubset without a semi-colon" do
    input = "&NotSquareSubset"
    output = [["Character", "&NotSquareSubset"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: NotSquareSubsetEqual without a semi-colon" do
    input = "&NotSquareSubsetEqual"
    output = [["Character", "&NotSquareSubsetEqual"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: NotSquareSuperset without a semi-colon" do
    input = "&NotSquareSuperset"
    output = [["Character", "&NotSquareSuperset"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: NotSquareSupersetEqual without a semi-colon" do
    input = "&NotSquareSupersetEqual"
    output = [["Character", "&NotSquareSupersetEqual"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: NotSubset without a semi-colon" do
    input = "&NotSubset"
    output = [["Character", "&NotSubset"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: NotSubsetEqual without a semi-colon" do
    input = "&NotSubsetEqual"
    output = [["Character", "&NotSubsetEqual"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: NotSucceeds without a semi-colon" do
    input = "&NotSucceeds"
    output = [["Character", "&NotSucceeds"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: NotSucceedsEqual without a semi-colon" do
    input = "&NotSucceedsEqual"
    output = [["Character", "&NotSucceedsEqual"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: NotSucceedsSlantEqual without a semi-colon" do
    input = "&NotSucceedsSlantEqual"
    output = [["Character", "&NotSucceedsSlantEqual"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: NotSucceedsTilde without a semi-colon" do
    input = "&NotSucceedsTilde"
    output = [["Character", "&NotSucceedsTilde"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: NotSuperset without a semi-colon" do
    input = "&NotSuperset"
    output = [["Character", "&NotSuperset"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: NotSupersetEqual without a semi-colon" do
    input = "&NotSupersetEqual"
    output = [["Character", "&NotSupersetEqual"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: NotTilde without a semi-colon" do
    input = "&NotTilde"
    output = [["Character", "&NotTilde"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: NotTildeEqual without a semi-colon" do
    input = "&NotTildeEqual"
    output = [["Character", "&NotTildeEqual"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: NotTildeFullEqual without a semi-colon" do
    input = "&NotTildeFullEqual"
    output = [["Character", "&NotTildeFullEqual"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: NotTildeTilde without a semi-colon" do
    input = "&NotTildeTilde"
    output = [["Character", "&NotTildeTilde"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: NotVerticalBar without a semi-colon" do
    input = "&NotVerticalBar"
    output = [["Character", "&NotVerticalBar"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Nscr without a semi-colon" do
    input = "&Nscr"
    output = [["Character", "&Nscr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Nu without a semi-colon" do
    input = "&Nu"
    output = [["Character", "&Nu"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: OElig without a semi-colon" do
    input = "&OElig"
    output = [["Character", "&OElig"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Ocy without a semi-colon" do
    input = "&Ocy"
    output = [["Character", "&Ocy"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Odblac without a semi-colon" do
    input = "&Odblac"
    output = [["Character", "&Odblac"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Ofr without a semi-colon" do
    input = "&Ofr"
    output = [["Character", "&Ofr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Omacr without a semi-colon" do
    input = "&Omacr"
    output = [["Character", "&Omacr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Omega without a semi-colon" do
    input = "&Omega"
    output = [["Character", "&Omega"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Omicron without a semi-colon" do
    input = "&Omicron"
    output = [["Character", "&Omicron"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Oopf without a semi-colon" do
    input = "&Oopf"
    output = [["Character", "&Oopf"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: OpenCurlyDoubleQuote without a semi-colon" do
    input = "&OpenCurlyDoubleQuote"
    output = [["Character", "&OpenCurlyDoubleQuote"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: OpenCurlyQuote without a semi-colon" do
    input = "&OpenCurlyQuote"
    output = [["Character", "&OpenCurlyQuote"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Or without a semi-colon" do
    input = "&Or"
    output = [["Character", "&Or"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Oscr without a semi-colon" do
    input = "&Oscr"
    output = [["Character", "&Oscr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Otimes without a semi-colon" do
    input = "&Otimes"
    output = [["Character", "&Otimes"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: OverBar without a semi-colon" do
    input = "&OverBar"
    output = [["Character", "&OverBar"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: OverBrace without a semi-colon" do
    input = "&OverBrace"
    output = [["Character", "&OverBrace"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: OverBracket without a semi-colon" do
    input = "&OverBracket"
    output = [["Character", "&OverBracket"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: OverParenthesis without a semi-colon" do
    input = "&OverParenthesis"
    output = [["Character", "&OverParenthesis"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: PartialD without a semi-colon" do
    input = "&PartialD"
    output = [["Character", "&PartialD"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Pcy without a semi-colon" do
    input = "&Pcy"
    output = [["Character", "&Pcy"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Pfr without a semi-colon" do
    input = "&Pfr"
    output = [["Character", "&Pfr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Phi without a semi-colon" do
    input = "&Phi"
    output = [["Character", "&Phi"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Pi without a semi-colon" do
    input = "&Pi"
    output = [["Character", "&Pi"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: PlusMinus without a semi-colon" do
    input = "&PlusMinus"
    output = [["Character", "&PlusMinus"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Poincareplane without a semi-colon" do
    input = "&Poincareplane"
    output = [["Character", "&Poincareplane"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Popf without a semi-colon" do
    input = "&Popf"
    output = [["Character", "&Popf"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Pr without a semi-colon" do
    input = "&Pr"
    output = [["Character", "&Pr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Precedes without a semi-colon" do
    input = "&Precedes"
    output = [["Character", "&Precedes"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: PrecedesEqual without a semi-colon" do
    input = "&PrecedesEqual"
    output = [["Character", "&PrecedesEqual"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: PrecedesSlantEqual without a semi-colon" do
    input = "&PrecedesSlantEqual"
    output = [["Character", "&PrecedesSlantEqual"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: PrecedesTilde without a semi-colon" do
    input = "&PrecedesTilde"
    output = [["Character", "&PrecedesTilde"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Prime without a semi-colon" do
    input = "&Prime"
    output = [["Character", "&Prime"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Product without a semi-colon" do
    input = "&Product"
    output = [["Character", "&Product"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Proportion without a semi-colon" do
    input = "&Proportion"
    output = [["Character", "&Proportion"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Proportional without a semi-colon" do
    input = "&Proportional"
    output = [["Character", "&Proportional"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Pscr without a semi-colon" do
    input = "&Pscr"
    output = [["Character", "&Pscr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Psi without a semi-colon" do
    input = "&Psi"
    output = [["Character", "&Psi"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Qfr without a semi-colon" do
    input = "&Qfr"
    output = [["Character", "&Qfr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Qopf without a semi-colon" do
    input = "&Qopf"
    output = [["Character", "&Qopf"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Qscr without a semi-colon" do
    input = "&Qscr"
    output = [["Character", "&Qscr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: RBarr without a semi-colon" do
    input = "&RBarr"
    output = [["Character", "&RBarr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Racute without a semi-colon" do
    input = "&Racute"
    output = [["Character", "&Racute"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Rang without a semi-colon" do
    input = "&Rang"
    output = [["Character", "&Rang"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Rarr without a semi-colon" do
    input = "&Rarr"
    output = [["Character", "&Rarr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Rarrtl without a semi-colon" do
    input = "&Rarrtl"
    output = [["Character", "&Rarrtl"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Rcaron without a semi-colon" do
    input = "&Rcaron"
    output = [["Character", "&Rcaron"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Rcedil without a semi-colon" do
    input = "&Rcedil"
    output = [["Character", "&Rcedil"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Rcy without a semi-colon" do
    input = "&Rcy"
    output = [["Character", "&Rcy"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Re without a semi-colon" do
    input = "&Re"
    output = [["Character", "&Re"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: ReverseElement without a semi-colon" do
    input = "&ReverseElement"
    output = [["Character", "&ReverseElement"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: ReverseEquilibrium without a semi-colon" do
    input = "&ReverseEquilibrium"
    output = [["Character", "&ReverseEquilibrium"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: ReverseUpEquilibrium without a semi-colon" do
    input = "&ReverseUpEquilibrium"
    output = [["Character", "&ReverseUpEquilibrium"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Rfr without a semi-colon" do
    input = "&Rfr"
    output = [["Character", "&Rfr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Rho without a semi-colon" do
    input = "&Rho"
    output = [["Character", "&Rho"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: RightAngleBracket without a semi-colon" do
    input = "&RightAngleBracket"
    output = [["Character", "&RightAngleBracket"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: RightArrow without a semi-colon" do
    input = "&RightArrow"
    output = [["Character", "&RightArrow"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: RightArrowBar without a semi-colon" do
    input = "&RightArrowBar"
    output = [["Character", "&RightArrowBar"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: RightArrowLeftArrow without a semi-colon" do
    input = "&RightArrowLeftArrow"
    output = [["Character", "&RightArrowLeftArrow"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: RightCeiling without a semi-colon" do
    input = "&RightCeiling"
    output = [["Character", "&RightCeiling"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end
end
