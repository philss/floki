defmodule Floki.HTML.Generated.Tokenizer.NamedentitiesPart25Test do
  use ExUnit.Case, async: true

  # NOTE: This file was generated by "mix generate_tokenizer_tests namedEntities.test".
  # html5lib-tests rev: e52ff68cc7113a6ef3687747fa82691079bf9cc5

  alias Floki.HTML.Tokenizer

  test "tokenize/1 Named entity: Poincareplane; with a semi-colon" do
    input = "&Poincareplane;"
    output = [["Character", "â„Œ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Popf; with a semi-colon" do
    input = "&Popf;"
    output = [["Character", "â„™"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Pr; with a semi-colon" do
    input = "&Pr;"
    output = [["Character", "âª»"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Precedes; with a semi-colon" do
    input = "&Precedes;"
    output = [["Character", "â‰º"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: PrecedesEqual; with a semi-colon" do
    input = "&PrecedesEqual;"
    output = [["Character", "âª¯"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: PrecedesSlantEqual; with a semi-colon" do
    input = "&PrecedesSlantEqual;"
    output = [["Character", "â‰¼"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: PrecedesTilde; with a semi-colon" do
    input = "&PrecedesTilde;"
    output = [["Character", "â‰¾"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Prime; with a semi-colon" do
    input = "&Prime;"
    output = [["Character", "â€³"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Product; with a semi-colon" do
    input = "&Product;"
    output = [["Character", "âˆ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Proportion; with a semi-colon" do
    input = "&Proportion;"
    output = [["Character", "âˆ·"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Proportional; with a semi-colon" do
    input = "&Proportional;"
    output = [["Character", "âˆ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Pscr; with a semi-colon" do
    input = "&Pscr;"
    output = [["Character", "ð’«"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Psi; with a semi-colon" do
    input = "&Psi;"
    output = [["Character", "Î¨"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: QUOT without a semi-colon" do
    input = "&QUOT"
    output = [["Character", "\""]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: QUOT; with a semi-colon" do
    input = "&QUOT;"
    output = [["Character", "\""]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Qfr; with a semi-colon" do
    input = "&Qfr;"
    output = [["Character", "ð””"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Qopf; with a semi-colon" do
    input = "&Qopf;"
    output = [["Character", "â„š"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Qscr; with a semi-colon" do
    input = "&Qscr;"
    output = [["Character", "ð’¬"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RBarr; with a semi-colon" do
    input = "&RBarr;"
    output = [["Character", "â¤"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: REG without a semi-colon" do
    input = "&REG"
    output = [["Character", "Â®"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: REG; with a semi-colon" do
    input = "&REG;"
    output = [["Character", "Â®"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Racute; with a semi-colon" do
    input = "&Racute;"
    output = [["Character", "Å”"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Rang; with a semi-colon" do
    input = "&Rang;"
    output = [["Character", "âŸ«"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Rarr; with a semi-colon" do
    input = "&Rarr;"
    output = [["Character", "â† "]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Rarrtl; with a semi-colon" do
    input = "&Rarrtl;"
    output = [["Character", "â¤–"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Rcaron; with a semi-colon" do
    input = "&Rcaron;"
    output = [["Character", "Å˜"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Rcedil; with a semi-colon" do
    input = "&Rcedil;"
    output = [["Character", "Å–"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Rcy; with a semi-colon" do
    input = "&Rcy;"
    output = [["Character", "Ð "]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Re; with a semi-colon" do
    input = "&Re;"
    output = [["Character", "â„œ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ReverseElement; with a semi-colon" do
    input = "&ReverseElement;"
    output = [["Character", "âˆ‹"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ReverseEquilibrium; with a semi-colon" do
    input = "&ReverseEquilibrium;"
    output = [["Character", "â‡‹"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ReverseUpEquilibrium; with a semi-colon" do
    input = "&ReverseUpEquilibrium;"
    output = [["Character", "â¥¯"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Rfr; with a semi-colon" do
    input = "&Rfr;"
    output = [["Character", "â„œ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Rho; with a semi-colon" do
    input = "&Rho;"
    output = [["Character", "Î¡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RightAngleBracket; with a semi-colon" do
    input = "&RightAngleBracket;"
    output = [["Character", "âŸ©"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RightArrow; with a semi-colon" do
    input = "&RightArrow;"
    output = [["Character", "â†’"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RightArrowBar; with a semi-colon" do
    input = "&RightArrowBar;"
    output = [["Character", "â‡¥"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RightArrowLeftArrow; with a semi-colon" do
    input = "&RightArrowLeftArrow;"
    output = [["Character", "â‡„"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RightCeiling; with a semi-colon" do
    input = "&RightCeiling;"
    output = [["Character", "âŒ‰"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RightDoubleBracket; with a semi-colon" do
    input = "&RightDoubleBracket;"
    output = [["Character", "âŸ§"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RightDownTeeVector; with a semi-colon" do
    input = "&RightDownTeeVector;"
    output = [["Character", "â¥"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RightDownVector; with a semi-colon" do
    input = "&RightDownVector;"
    output = [["Character", "â‡‚"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RightDownVectorBar; with a semi-colon" do
    input = "&RightDownVectorBar;"
    output = [["Character", "â¥•"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RightFloor; with a semi-colon" do
    input = "&RightFloor;"
    output = [["Character", "âŒ‹"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RightTee; with a semi-colon" do
    input = "&RightTee;"
    output = [["Character", "âŠ¢"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RightTeeArrow; with a semi-colon" do
    input = "&RightTeeArrow;"
    output = [["Character", "â†¦"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RightTeeVector; with a semi-colon" do
    input = "&RightTeeVector;"
    output = [["Character", "â¥›"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RightTriangle; with a semi-colon" do
    input = "&RightTriangle;"
    output = [["Character", "âŠ³"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RightTriangleBar; with a semi-colon" do
    input = "&RightTriangleBar;"
    output = [["Character", "â§"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RightTriangleEqual; with a semi-colon" do
    input = "&RightTriangleEqual;"
    output = [["Character", "âŠµ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RightUpDownVector; with a semi-colon" do
    input = "&RightUpDownVector;"
    output = [["Character", "â¥"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RightUpTeeVector; with a semi-colon" do
    input = "&RightUpTeeVector;"
    output = [["Character", "â¥œ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RightUpVector; with a semi-colon" do
    input = "&RightUpVector;"
    output = [["Character", "â†¾"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RightUpVectorBar; with a semi-colon" do
    input = "&RightUpVectorBar;"
    output = [["Character", "â¥”"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RightVector; with a semi-colon" do
    input = "&RightVector;"
    output = [["Character", "â‡€"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RightVectorBar; with a semi-colon" do
    input = "&RightVectorBar;"
    output = [["Character", "â¥“"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Rightarrow; with a semi-colon" do
    input = "&Rightarrow;"
    output = [["Character", "â‡’"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ropf; with a semi-colon" do
    input = "&Ropf;"
    output = [["Character", "â„"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RoundImplies; with a semi-colon" do
    input = "&RoundImplies;"
    output = [["Character", "â¥°"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Rrightarrow; with a semi-colon" do
    input = "&Rrightarrow;"
    output = [["Character", "â‡›"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Rscr; with a semi-colon" do
    input = "&Rscr;"
    output = [["Character", "â„›"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Rsh; with a semi-colon" do
    input = "&Rsh;"
    output = [["Character", "â†±"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RuleDelayed; with a semi-colon" do
    input = "&RuleDelayed;"
    output = [["Character", "â§´"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: SHCHcy; with a semi-colon" do
    input = "&SHCHcy;"
    output = [["Character", "Ð©"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: SHcy; with a semi-colon" do
    input = "&SHcy;"
    output = [["Character", "Ð¨"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: SOFTcy; with a semi-colon" do
    input = "&SOFTcy;"
    output = [["Character", "Ð¬"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Sacute; with a semi-colon" do
    input = "&Sacute;"
    output = [["Character", "Åš"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Sc; with a semi-colon" do
    input = "&Sc;"
    output = [["Character", "âª¼"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Scaron; with a semi-colon" do
    input = "&Scaron;"
    output = [["Character", "Å "]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Scedil; with a semi-colon" do
    input = "&Scedil;"
    output = [["Character", "Åž"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Scirc; with a semi-colon" do
    input = "&Scirc;"
    output = [["Character", "Åœ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Scy; with a semi-colon" do
    input = "&Scy;"
    output = [["Character", "Ð¡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Sfr; with a semi-colon" do
    input = "&Sfr;"
    output = [["Character", "ð”–"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ShortDownArrow; with a semi-colon" do
    input = "&ShortDownArrow;"
    output = [["Character", "â†“"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ShortLeftArrow; with a semi-colon" do
    input = "&ShortLeftArrow;"
    output = [["Character", "â†"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ShortRightArrow; with a semi-colon" do
    input = "&ShortRightArrow;"
    output = [["Character", "â†’"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ShortUpArrow; with a semi-colon" do
    input = "&ShortUpArrow;"
    output = [["Character", "â†‘"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Sigma; with a semi-colon" do
    input = "&Sigma;"
    output = [["Character", "Î£"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: SmallCircle; with a semi-colon" do
    input = "&SmallCircle;"
    output = [["Character", "âˆ˜"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Sopf; with a semi-colon" do
    input = "&Sopf;"
    output = [["Character", "ð•Š"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Sqrt; with a semi-colon" do
    input = "&Sqrt;"
    output = [["Character", "âˆš"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Square; with a semi-colon" do
    input = "&Square;"
    output = [["Character", "â–¡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: SquareIntersection; with a semi-colon" do
    input = "&SquareIntersection;"
    output = [["Character", "âŠ“"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: SquareSubset; with a semi-colon" do
    input = "&SquareSubset;"
    output = [["Character", "âŠ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: SquareSubsetEqual; with a semi-colon" do
    input = "&SquareSubsetEqual;"
    output = [["Character", "âŠ‘"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: SquareSuperset; with a semi-colon" do
    input = "&SquareSuperset;"
    output = [["Character", "âŠ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: SquareSupersetEqual; with a semi-colon" do
    input = "&SquareSupersetEqual;"
    output = [["Character", "âŠ’"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: SquareUnion; with a semi-colon" do
    input = "&SquareUnion;"
    output = [["Character", "âŠ”"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Sscr; with a semi-colon" do
    input = "&Sscr;"
    output = [["Character", "ð’®"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Star; with a semi-colon" do
    input = "&Star;"
    output = [["Character", "â‹†"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Sub; with a semi-colon" do
    input = "&Sub;"
    output = [["Character", "â‹"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Subset; with a semi-colon" do
    input = "&Subset;"
    output = [["Character", "â‹"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: SubsetEqual; with a semi-colon" do
    input = "&SubsetEqual;"
    output = [["Character", "âŠ†"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Succeeds; with a semi-colon" do
    input = "&Succeeds;"
    output = [["Character", "â‰»"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: SucceedsEqual; with a semi-colon" do
    input = "&SucceedsEqual;"
    output = [["Character", "âª°"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: SucceedsSlantEqual; with a semi-colon" do
    input = "&SucceedsSlantEqual;"
    output = [["Character", "â‰½"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: SucceedsTilde; with a semi-colon" do
    input = "&SucceedsTilde;"
    output = [["Character", "â‰¿"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: SuchThat; with a semi-colon" do
    input = "&SuchThat;"
    output = [["Character", "âˆ‹"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Sum; with a semi-colon" do
    input = "&Sum;"
    output = [["Character", "âˆ‘"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Sup; with a semi-colon" do
    input = "&Sup;"
    output = [["Character", "â‹‘"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end
end