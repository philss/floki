defmodule Floki.HTML.Generated.Tokenizer.NamedentitiesPart25Test do
  use ExUnit.Case, async: true

  # NOTE: This file was generated by "mix generate_tokenizer_tests namedEntities.test".
  # html5lib-tests rev: e52ff68cc7113a6ef3687747fa82691079bf9cc5

  alias Floki.HTML.Tokenizer

  test "tokenize/1 Named entity: Poincareplane; with a semi-colon" do
    input = "&Poincareplane;"
    output = [["Character", "ℌ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Popf; with a semi-colon" do
    input = "&Popf;"
    output = [["Character", "ℙ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Pr; with a semi-colon" do
    input = "&Pr;"
    output = [["Character", "⪻"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Precedes; with a semi-colon" do
    input = "&Precedes;"
    output = [["Character", "≺"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: PrecedesEqual; with a semi-colon" do
    input = "&PrecedesEqual;"
    output = [["Character", "⪯"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: PrecedesSlantEqual; with a semi-colon" do
    input = "&PrecedesSlantEqual;"
    output = [["Character", "≼"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: PrecedesTilde; with a semi-colon" do
    input = "&PrecedesTilde;"
    output = [["Character", "≾"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Prime; with a semi-colon" do
    input = "&Prime;"
    output = [["Character", "″"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Product; with a semi-colon" do
    input = "&Product;"
    output = [["Character", "∏"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Proportion; with a semi-colon" do
    input = "&Proportion;"
    output = [["Character", "∷"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Proportional; with a semi-colon" do
    input = "&Proportional;"
    output = [["Character", "∝"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Pscr; with a semi-colon" do
    input = "&Pscr;"
    output = [["Character", "𝒫"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Psi; with a semi-colon" do
    input = "&Psi;"
    output = [["Character", "Ψ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: QUOT without a semi-colon" do
    input = "&QUOT"
    output = [["Character", "\""]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: QUOT; with a semi-colon" do
    input = "&QUOT;"
    output = [["Character", "\""]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Qfr; with a semi-colon" do
    input = "&Qfr;"
    output = [["Character", "𝔔"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Qopf; with a semi-colon" do
    input = "&Qopf;"
    output = [["Character", "ℚ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Qscr; with a semi-colon" do
    input = "&Qscr;"
    output = [["Character", "𝒬"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RBarr; with a semi-colon" do
    input = "&RBarr;"
    output = [["Character", "⤐"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: REG without a semi-colon" do
    input = "&REG"
    output = [["Character", "®"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: REG; with a semi-colon" do
    input = "&REG;"
    output = [["Character", "®"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Racute; with a semi-colon" do
    input = "&Racute;"
    output = [["Character", "Ŕ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Rang; with a semi-colon" do
    input = "&Rang;"
    output = [["Character", "⟫"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Rarr; with a semi-colon" do
    input = "&Rarr;"
    output = [["Character", "↠"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Rarrtl; with a semi-colon" do
    input = "&Rarrtl;"
    output = [["Character", "⤖"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Rcaron; with a semi-colon" do
    input = "&Rcaron;"
    output = [["Character", "Ř"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Rcedil; with a semi-colon" do
    input = "&Rcedil;"
    output = [["Character", "Ŗ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Rcy; with a semi-colon" do
    input = "&Rcy;"
    output = [["Character", "Р"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Re; with a semi-colon" do
    input = "&Re;"
    output = [["Character", "ℜ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ReverseElement; with a semi-colon" do
    input = "&ReverseElement;"
    output = [["Character", "∋"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ReverseEquilibrium; with a semi-colon" do
    input = "&ReverseEquilibrium;"
    output = [["Character", "⇋"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ReverseUpEquilibrium; with a semi-colon" do
    input = "&ReverseUpEquilibrium;"
    output = [["Character", "⥯"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Rfr; with a semi-colon" do
    input = "&Rfr;"
    output = [["Character", "ℜ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Rho; with a semi-colon" do
    input = "&Rho;"
    output = [["Character", "Ρ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RightAngleBracket; with a semi-colon" do
    input = "&RightAngleBracket;"
    output = [["Character", "⟩"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RightArrow; with a semi-colon" do
    input = "&RightArrow;"
    output = [["Character", "→"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RightArrowBar; with a semi-colon" do
    input = "&RightArrowBar;"
    output = [["Character", "⇥"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RightArrowLeftArrow; with a semi-colon" do
    input = "&RightArrowLeftArrow;"
    output = [["Character", "⇄"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RightCeiling; with a semi-colon" do
    input = "&RightCeiling;"
    output = [["Character", "⌉"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RightDoubleBracket; with a semi-colon" do
    input = "&RightDoubleBracket;"
    output = [["Character", "⟧"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RightDownTeeVector; with a semi-colon" do
    input = "&RightDownTeeVector;"
    output = [["Character", "⥝"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RightDownVector; with a semi-colon" do
    input = "&RightDownVector;"
    output = [["Character", "⇂"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RightDownVectorBar; with a semi-colon" do
    input = "&RightDownVectorBar;"
    output = [["Character", "⥕"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RightFloor; with a semi-colon" do
    input = "&RightFloor;"
    output = [["Character", "⌋"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RightTee; with a semi-colon" do
    input = "&RightTee;"
    output = [["Character", "⊢"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RightTeeArrow; with a semi-colon" do
    input = "&RightTeeArrow;"
    output = [["Character", "↦"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RightTeeVector; with a semi-colon" do
    input = "&RightTeeVector;"
    output = [["Character", "⥛"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RightTriangle; with a semi-colon" do
    input = "&RightTriangle;"
    output = [["Character", "⊳"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RightTriangleBar; with a semi-colon" do
    input = "&RightTriangleBar;"
    output = [["Character", "⧐"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RightTriangleEqual; with a semi-colon" do
    input = "&RightTriangleEqual;"
    output = [["Character", "⊵"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RightUpDownVector; with a semi-colon" do
    input = "&RightUpDownVector;"
    output = [["Character", "⥏"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RightUpTeeVector; with a semi-colon" do
    input = "&RightUpTeeVector;"
    output = [["Character", "⥜"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RightUpVector; with a semi-colon" do
    input = "&RightUpVector;"
    output = [["Character", "↾"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RightUpVectorBar; with a semi-colon" do
    input = "&RightUpVectorBar;"
    output = [["Character", "⥔"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RightVector; with a semi-colon" do
    input = "&RightVector;"
    output = [["Character", "⇀"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RightVectorBar; with a semi-colon" do
    input = "&RightVectorBar;"
    output = [["Character", "⥓"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Rightarrow; with a semi-colon" do
    input = "&Rightarrow;"
    output = [["Character", "⇒"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ropf; with a semi-colon" do
    input = "&Ropf;"
    output = [["Character", "ℝ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RoundImplies; with a semi-colon" do
    input = "&RoundImplies;"
    output = [["Character", "⥰"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Rrightarrow; with a semi-colon" do
    input = "&Rrightarrow;"
    output = [["Character", "⇛"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Rscr; with a semi-colon" do
    input = "&Rscr;"
    output = [["Character", "ℛ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Rsh; with a semi-colon" do
    input = "&Rsh;"
    output = [["Character", "↱"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: RuleDelayed; with a semi-colon" do
    input = "&RuleDelayed;"
    output = [["Character", "⧴"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: SHCHcy; with a semi-colon" do
    input = "&SHCHcy;"
    output = [["Character", "Щ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: SHcy; with a semi-colon" do
    input = "&SHcy;"
    output = [["Character", "Ш"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: SOFTcy; with a semi-colon" do
    input = "&SOFTcy;"
    output = [["Character", "Ь"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Sacute; with a semi-colon" do
    input = "&Sacute;"
    output = [["Character", "Ś"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Sc; with a semi-colon" do
    input = "&Sc;"
    output = [["Character", "⪼"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Scaron; with a semi-colon" do
    input = "&Scaron;"
    output = [["Character", "Š"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Scedil; with a semi-colon" do
    input = "&Scedil;"
    output = [["Character", "Ş"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Scirc; with a semi-colon" do
    input = "&Scirc;"
    output = [["Character", "Ŝ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Scy; with a semi-colon" do
    input = "&Scy;"
    output = [["Character", "С"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Sfr; with a semi-colon" do
    input = "&Sfr;"
    output = [["Character", "𝔖"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ShortDownArrow; with a semi-colon" do
    input = "&ShortDownArrow;"
    output = [["Character", "↓"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ShortLeftArrow; with a semi-colon" do
    input = "&ShortLeftArrow;"
    output = [["Character", "←"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ShortRightArrow; with a semi-colon" do
    input = "&ShortRightArrow;"
    output = [["Character", "→"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ShortUpArrow; with a semi-colon" do
    input = "&ShortUpArrow;"
    output = [["Character", "↑"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Sigma; with a semi-colon" do
    input = "&Sigma;"
    output = [["Character", "Σ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: SmallCircle; with a semi-colon" do
    input = "&SmallCircle;"
    output = [["Character", "∘"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Sopf; with a semi-colon" do
    input = "&Sopf;"
    output = [["Character", "𝕊"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Sqrt; with a semi-colon" do
    input = "&Sqrt;"
    output = [["Character", "√"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Square; with a semi-colon" do
    input = "&Square;"
    output = [["Character", "□"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: SquareIntersection; with a semi-colon" do
    input = "&SquareIntersection;"
    output = [["Character", "⊓"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: SquareSubset; with a semi-colon" do
    input = "&SquareSubset;"
    output = [["Character", "⊏"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: SquareSubsetEqual; with a semi-colon" do
    input = "&SquareSubsetEqual;"
    output = [["Character", "⊑"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: SquareSuperset; with a semi-colon" do
    input = "&SquareSuperset;"
    output = [["Character", "⊐"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: SquareSupersetEqual; with a semi-colon" do
    input = "&SquareSupersetEqual;"
    output = [["Character", "⊒"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: SquareUnion; with a semi-colon" do
    input = "&SquareUnion;"
    output = [["Character", "⊔"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Sscr; with a semi-colon" do
    input = "&Sscr;"
    output = [["Character", "𝒮"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Star; with a semi-colon" do
    input = "&Star;"
    output = [["Character", "⋆"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Sub; with a semi-colon" do
    input = "&Sub;"
    output = [["Character", "⋐"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Subset; with a semi-colon" do
    input = "&Subset;"
    output = [["Character", "⋐"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: SubsetEqual; with a semi-colon" do
    input = "&SubsetEqual;"
    output = [["Character", "⊆"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Succeeds; with a semi-colon" do
    input = "&Succeeds;"
    output = [["Character", "≻"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: SucceedsEqual; with a semi-colon" do
    input = "&SucceedsEqual;"
    output = [["Character", "⪰"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: SucceedsSlantEqual; with a semi-colon" do
    input = "&SucceedsSlantEqual;"
    output = [["Character", "≽"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: SucceedsTilde; with a semi-colon" do
    input = "&SucceedsTilde;"
    output = [["Character", "≿"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: SuchThat; with a semi-colon" do
    input = "&SuchThat;"
    output = [["Character", "∋"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Sum; with a semi-colon" do
    input = "&Sum;"
    output = [["Character", "∑"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Sup; with a semi-colon" do
    input = "&Sup;"
    output = [["Character", "⋑"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end
end