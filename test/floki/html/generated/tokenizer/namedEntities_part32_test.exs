defmodule Floki.HTML.Generated.Tokenizer.NamedentitiesPart32Test do
  use ExUnit.Case, async: true

  # NOTE: This file was generated by "mix generate_tokenizer_tests namedEntities.test".
  # html5lib-tests rev: e52ff68cc7113a6ef3687747fa82691079bf9cc5

  alias Floki.HTML.Tokenizer

  test "tokenize/1 Named entity: gnE; with a semi-colon" do
    input = "&gnE;"
    output = [["Character", "â‰©"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gnap; with a semi-colon" do
    input = "&gnap;"
    output = [["Character", "âªŠ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gnapprox; with a semi-colon" do
    input = "&gnapprox;"
    output = [["Character", "âªŠ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gne; with a semi-colon" do
    input = "&gne;"
    output = [["Character", "âªˆ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gneq; with a semi-colon" do
    input = "&gneq;"
    output = [["Character", "âªˆ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gneqq; with a semi-colon" do
    input = "&gneqq;"
    output = [["Character", "â‰©"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gnsim; with a semi-colon" do
    input = "&gnsim;"
    output = [["Character", "â‹§"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gopf; with a semi-colon" do
    input = "&gopf;"
    output = [["Character", "ð•˜"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: grave; with a semi-colon" do
    input = "&grave;"
    output = [["Character", "`"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gscr; with a semi-colon" do
    input = "&gscr;"
    output = [["Character", "â„Š"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gsim; with a semi-colon" do
    input = "&gsim;"
    output = [["Character", "â‰³"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gsime; with a semi-colon" do
    input = "&gsime;"
    output = [["Character", "âªŽ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gsiml; with a semi-colon" do
    input = "&gsiml;"
    output = [["Character", "âª"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gt without a semi-colon" do
    input = "&gt"
    output = [["Character", ">"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gt; with a semi-colon" do
    input = "&gt;"
    output = [["Character", ">"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gtcc; with a semi-colon" do
    input = "&gtcc;"
    output = [["Character", "âª§"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gtcir; with a semi-colon" do
    input = "&gtcir;"
    output = [["Character", "â©º"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gtdot; with a semi-colon" do
    input = "&gtdot;"
    output = [["Character", "â‹—"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gtlPar; with a semi-colon" do
    input = "&gtlPar;"
    output = [["Character", "â¦•"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gtquest; with a semi-colon" do
    input = "&gtquest;"
    output = [["Character", "â©¼"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gtrapprox; with a semi-colon" do
    input = "&gtrapprox;"
    output = [["Character", "âª†"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gtrarr; with a semi-colon" do
    input = "&gtrarr;"
    output = [["Character", "â¥¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gtrdot; with a semi-colon" do
    input = "&gtrdot;"
    output = [["Character", "â‹—"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gtreqless; with a semi-colon" do
    input = "&gtreqless;"
    output = [["Character", "â‹›"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gtreqqless; with a semi-colon" do
    input = "&gtreqqless;"
    output = [["Character", "âªŒ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gtrless; with a semi-colon" do
    input = "&gtrless;"
    output = [["Character", "â‰·"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gtrsim; with a semi-colon" do
    input = "&gtrsim;"
    output = [["Character", "â‰³"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gvertneqq; with a semi-colon" do
    input = "&gvertneqq;"
    output = [["Character", "â‰©ï¸€"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gvnE; with a semi-colon" do
    input = "&gvnE;"
    output = [["Character", "â‰©ï¸€"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: hArr; with a semi-colon" do
    input = "&hArr;"
    output = [["Character", "â‡”"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: hairsp; with a semi-colon" do
    input = "&hairsp;"
    output = [["Character", "â€Š"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: half; with a semi-colon" do
    input = "&half;"
    output = [["Character", "Â½"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: hamilt; with a semi-colon" do
    input = "&hamilt;"
    output = [["Character", "â„‹"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: hardcy; with a semi-colon" do
    input = "&hardcy;"
    output = [["Character", "ÑŠ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: harr; with a semi-colon" do
    input = "&harr;"
    output = [["Character", "â†”"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: harrcir; with a semi-colon" do
    input = "&harrcir;"
    output = [["Character", "â¥ˆ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: harrw; with a semi-colon" do
    input = "&harrw;"
    output = [["Character", "â†­"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: hbar; with a semi-colon" do
    input = "&hbar;"
    output = [["Character", "â„"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: hcirc; with a semi-colon" do
    input = "&hcirc;"
    output = [["Character", "Ä¥"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: hearts; with a semi-colon" do
    input = "&hearts;"
    output = [["Character", "â™¥"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: heartsuit; with a semi-colon" do
    input = "&heartsuit;"
    output = [["Character", "â™¥"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: hellip; with a semi-colon" do
    input = "&hellip;"
    output = [["Character", "â€¦"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: hercon; with a semi-colon" do
    input = "&hercon;"
    output = [["Character", "âŠ¹"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: hfr; with a semi-colon" do
    input = "&hfr;"
    output = [["Character", "ð”¥"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: hksearow; with a semi-colon" do
    input = "&hksearow;"
    output = [["Character", "â¤¥"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: hkswarow; with a semi-colon" do
    input = "&hkswarow;"
    output = [["Character", "â¤¦"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: hoarr; with a semi-colon" do
    input = "&hoarr;"
    output = [["Character", "â‡¿"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: homtht; with a semi-colon" do
    input = "&homtht;"
    output = [["Character", "âˆ»"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: hookleftarrow; with a semi-colon" do
    input = "&hookleftarrow;"
    output = [["Character", "â†©"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: hookrightarrow; with a semi-colon" do
    input = "&hookrightarrow;"
    output = [["Character", "â†ª"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: hopf; with a semi-colon" do
    input = "&hopf;"
    output = [["Character", "ð•™"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: horbar; with a semi-colon" do
    input = "&horbar;"
    output = [["Character", "â€•"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: hscr; with a semi-colon" do
    input = "&hscr;"
    output = [["Character", "ð’½"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: hslash; with a semi-colon" do
    input = "&hslash;"
    output = [["Character", "â„"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: hstrok; with a semi-colon" do
    input = "&hstrok;"
    output = [["Character", "Ä§"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: hybull; with a semi-colon" do
    input = "&hybull;"
    output = [["Character", "âƒ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: hyphen; with a semi-colon" do
    input = "&hyphen;"
    output = [["Character", "â€"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: iacute without a semi-colon" do
    input = "&iacute"
    output = [["Character", "Ã­"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: iacute; with a semi-colon" do
    input = "&iacute;"
    output = [["Character", "Ã­"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ic; with a semi-colon" do
    input = "&ic;"
    output = [["Character", "â£"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: icirc without a semi-colon" do
    input = "&icirc"
    output = [["Character", "Ã®"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: icirc; with a semi-colon" do
    input = "&icirc;"
    output = [["Character", "Ã®"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: icy; with a semi-colon" do
    input = "&icy;"
    output = [["Character", "Ð¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: iecy; with a semi-colon" do
    input = "&iecy;"
    output = [["Character", "Ðµ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: iexcl without a semi-colon" do
    input = "&iexcl"
    output = [["Character", "Â¡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: iexcl; with a semi-colon" do
    input = "&iexcl;"
    output = [["Character", "Â¡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: iff; with a semi-colon" do
    input = "&iff;"
    output = [["Character", "â‡”"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ifr; with a semi-colon" do
    input = "&ifr;"
    output = [["Character", "ð”¦"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: igrave without a semi-colon" do
    input = "&igrave"
    output = [["Character", "Ã¬"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: igrave; with a semi-colon" do
    input = "&igrave;"
    output = [["Character", "Ã¬"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ii; with a semi-colon" do
    input = "&ii;"
    output = [["Character", "â…ˆ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: iiiint; with a semi-colon" do
    input = "&iiiint;"
    output = [["Character", "â¨Œ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: iiint; with a semi-colon" do
    input = "&iiint;"
    output = [["Character", "âˆ­"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: iinfin; with a semi-colon" do
    input = "&iinfin;"
    output = [["Character", "â§œ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: iiota; with a semi-colon" do
    input = "&iiota;"
    output = [["Character", "â„©"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ijlig; with a semi-colon" do
    input = "&ijlig;"
    output = [["Character", "Ä³"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: imacr; with a semi-colon" do
    input = "&imacr;"
    output = [["Character", "Ä«"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: image; with a semi-colon" do
    input = "&image;"
    output = [["Character", "â„‘"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: imagline; with a semi-colon" do
    input = "&imagline;"
    output = [["Character", "â„"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: imagpart; with a semi-colon" do
    input = "&imagpart;"
    output = [["Character", "â„‘"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: imath; with a semi-colon" do
    input = "&imath;"
    output = [["Character", "Ä±"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: imof; with a semi-colon" do
    input = "&imof;"
    output = [["Character", "âŠ·"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: imped; with a semi-colon" do
    input = "&imped;"
    output = [["Character", "Æµ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: in; with a semi-colon" do
    input = "&in;"
    output = [["Character", "âˆˆ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: incare; with a semi-colon" do
    input = "&incare;"
    output = [["Character", "â„…"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: infin; with a semi-colon" do
    input = "&infin;"
    output = [["Character", "âˆž"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: infintie; with a semi-colon" do
    input = "&infintie;"
    output = [["Character", "â§"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: inodot; with a semi-colon" do
    input = "&inodot;"
    output = [["Character", "Ä±"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: int; with a semi-colon" do
    input = "&int;"
    output = [["Character", "âˆ«"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: intcal; with a semi-colon" do
    input = "&intcal;"
    output = [["Character", "âŠº"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: integers; with a semi-colon" do
    input = "&integers;"
    output = [["Character", "â„¤"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: intercal; with a semi-colon" do
    input = "&intercal;"
    output = [["Character", "âŠº"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: intlarhk; with a semi-colon" do
    input = "&intlarhk;"
    output = [["Character", "â¨—"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: intprod; with a semi-colon" do
    input = "&intprod;"
    output = [["Character", "â¨¼"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: iocy; with a semi-colon" do
    input = "&iocy;"
    output = [["Character", "Ñ‘"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: iogon; with a semi-colon" do
    input = "&iogon;"
    output = [["Character", "Ä¯"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: iopf; with a semi-colon" do
    input = "&iopf;"
    output = [["Character", "ð•š"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: iota; with a semi-colon" do
    input = "&iota;"
    output = [["Character", "Î¹"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: iprod; with a semi-colon" do
    input = "&iprod;"
    output = [["Character", "â¨¼"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: iquest without a semi-colon" do
    input = "&iquest"
    output = [["Character", "Â¿"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end
end