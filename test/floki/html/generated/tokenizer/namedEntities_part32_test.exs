defmodule Floki.HTML.Generated.Tokenizer.NamedentitiesPart32Test do
  use ExUnit.Case, async: true

  # NOTE: This file was generated by "mix generate_tokenizer_tests namedEntities.test".
  # html5lib-tests rev: e52ff68cc7113a6ef3687747fa82691079bf9cc5

  alias Floki.HTML.Tokenizer

  test "tokenize/1 Named entity: gnE; with a semi-colon" do
    input = "&gnE;"
    output = [["Character", "≩"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gnap; with a semi-colon" do
    input = "&gnap;"
    output = [["Character", "⪊"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gnapprox; with a semi-colon" do
    input = "&gnapprox;"
    output = [["Character", "⪊"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gne; with a semi-colon" do
    input = "&gne;"
    output = [["Character", "⪈"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gneq; with a semi-colon" do
    input = "&gneq;"
    output = [["Character", "⪈"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gneqq; with a semi-colon" do
    input = "&gneqq;"
    output = [["Character", "≩"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gnsim; with a semi-colon" do
    input = "&gnsim;"
    output = [["Character", "⋧"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gopf; with a semi-colon" do
    input = "&gopf;"
    output = [["Character", "𝕘"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: grave; with a semi-colon" do
    input = "&grave;"
    output = [["Character", "`"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gscr; with a semi-colon" do
    input = "&gscr;"
    output = [["Character", "ℊ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gsim; with a semi-colon" do
    input = "&gsim;"
    output = [["Character", "≳"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gsime; with a semi-colon" do
    input = "&gsime;"
    output = [["Character", "⪎"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gsiml; with a semi-colon" do
    input = "&gsiml;"
    output = [["Character", "⪐"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gt without a semi-colon" do
    input = "&gt"
    output = [["Character", ">"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gt; with a semi-colon" do
    input = "&gt;"
    output = [["Character", ">"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gtcc; with a semi-colon" do
    input = "&gtcc;"
    output = [["Character", "⪧"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gtcir; with a semi-colon" do
    input = "&gtcir;"
    output = [["Character", "⩺"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gtdot; with a semi-colon" do
    input = "&gtdot;"
    output = [["Character", "⋗"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gtlPar; with a semi-colon" do
    input = "&gtlPar;"
    output = [["Character", "⦕"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gtquest; with a semi-colon" do
    input = "&gtquest;"
    output = [["Character", "⩼"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gtrapprox; with a semi-colon" do
    input = "&gtrapprox;"
    output = [["Character", "⪆"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gtrarr; with a semi-colon" do
    input = "&gtrarr;"
    output = [["Character", "⥸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gtrdot; with a semi-colon" do
    input = "&gtrdot;"
    output = [["Character", "⋗"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gtreqless; with a semi-colon" do
    input = "&gtreqless;"
    output = [["Character", "⋛"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gtreqqless; with a semi-colon" do
    input = "&gtreqqless;"
    output = [["Character", "⪌"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gtrless; with a semi-colon" do
    input = "&gtrless;"
    output = [["Character", "≷"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gtrsim; with a semi-colon" do
    input = "&gtrsim;"
    output = [["Character", "≳"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gvertneqq; with a semi-colon" do
    input = "&gvertneqq;"
    output = [["Character", "≩︀"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gvnE; with a semi-colon" do
    input = "&gvnE;"
    output = [["Character", "≩︀"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: hArr; with a semi-colon" do
    input = "&hArr;"
    output = [["Character", "⇔"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: hairsp; with a semi-colon" do
    input = "&hairsp;"
    output = [["Character", " "]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: half; with a semi-colon" do
    input = "&half;"
    output = [["Character", "½"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: hamilt; with a semi-colon" do
    input = "&hamilt;"
    output = [["Character", "ℋ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: hardcy; with a semi-colon" do
    input = "&hardcy;"
    output = [["Character", "ъ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: harr; with a semi-colon" do
    input = "&harr;"
    output = [["Character", "↔"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: harrcir; with a semi-colon" do
    input = "&harrcir;"
    output = [["Character", "⥈"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: harrw; with a semi-colon" do
    input = "&harrw;"
    output = [["Character", "↭"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: hbar; with a semi-colon" do
    input = "&hbar;"
    output = [["Character", "ℏ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: hcirc; with a semi-colon" do
    input = "&hcirc;"
    output = [["Character", "ĥ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: hearts; with a semi-colon" do
    input = "&hearts;"
    output = [["Character", "♥"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: heartsuit; with a semi-colon" do
    input = "&heartsuit;"
    output = [["Character", "♥"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: hellip; with a semi-colon" do
    input = "&hellip;"
    output = [["Character", "…"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: hercon; with a semi-colon" do
    input = "&hercon;"
    output = [["Character", "⊹"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: hfr; with a semi-colon" do
    input = "&hfr;"
    output = [["Character", "𝔥"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: hksearow; with a semi-colon" do
    input = "&hksearow;"
    output = [["Character", "⤥"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: hkswarow; with a semi-colon" do
    input = "&hkswarow;"
    output = [["Character", "⤦"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: hoarr; with a semi-colon" do
    input = "&hoarr;"
    output = [["Character", "⇿"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: homtht; with a semi-colon" do
    input = "&homtht;"
    output = [["Character", "∻"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: hookleftarrow; with a semi-colon" do
    input = "&hookleftarrow;"
    output = [["Character", "↩"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: hookrightarrow; with a semi-colon" do
    input = "&hookrightarrow;"
    output = [["Character", "↪"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: hopf; with a semi-colon" do
    input = "&hopf;"
    output = [["Character", "𝕙"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: horbar; with a semi-colon" do
    input = "&horbar;"
    output = [["Character", "―"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: hscr; with a semi-colon" do
    input = "&hscr;"
    output = [["Character", "𝒽"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: hslash; with a semi-colon" do
    input = "&hslash;"
    output = [["Character", "ℏ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: hstrok; with a semi-colon" do
    input = "&hstrok;"
    output = [["Character", "ħ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: hybull; with a semi-colon" do
    input = "&hybull;"
    output = [["Character", "⁃"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: hyphen; with a semi-colon" do
    input = "&hyphen;"
    output = [["Character", "‐"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: iacute without a semi-colon" do
    input = "&iacute"
    output = [["Character", "í"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: iacute; with a semi-colon" do
    input = "&iacute;"
    output = [["Character", "í"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ic; with a semi-colon" do
    input = "&ic;"
    output = [["Character", "⁣"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: icirc without a semi-colon" do
    input = "&icirc"
    output = [["Character", "î"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: icirc; with a semi-colon" do
    input = "&icirc;"
    output = [["Character", "î"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: icy; with a semi-colon" do
    input = "&icy;"
    output = [["Character", "и"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: iecy; with a semi-colon" do
    input = "&iecy;"
    output = [["Character", "е"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: iexcl without a semi-colon" do
    input = "&iexcl"
    output = [["Character", "¡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: iexcl; with a semi-colon" do
    input = "&iexcl;"
    output = [["Character", "¡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: iff; with a semi-colon" do
    input = "&iff;"
    output = [["Character", "⇔"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ifr; with a semi-colon" do
    input = "&ifr;"
    output = [["Character", "𝔦"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: igrave without a semi-colon" do
    input = "&igrave"
    output = [["Character", "ì"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: igrave; with a semi-colon" do
    input = "&igrave;"
    output = [["Character", "ì"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ii; with a semi-colon" do
    input = "&ii;"
    output = [["Character", "ⅈ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: iiiint; with a semi-colon" do
    input = "&iiiint;"
    output = [["Character", "⨌"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: iiint; with a semi-colon" do
    input = "&iiint;"
    output = [["Character", "∭"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: iinfin; with a semi-colon" do
    input = "&iinfin;"
    output = [["Character", "⧜"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: iiota; with a semi-colon" do
    input = "&iiota;"
    output = [["Character", "℩"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ijlig; with a semi-colon" do
    input = "&ijlig;"
    output = [["Character", "ĳ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: imacr; with a semi-colon" do
    input = "&imacr;"
    output = [["Character", "ī"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: image; with a semi-colon" do
    input = "&image;"
    output = [["Character", "ℑ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: imagline; with a semi-colon" do
    input = "&imagline;"
    output = [["Character", "ℐ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: imagpart; with a semi-colon" do
    input = "&imagpart;"
    output = [["Character", "ℑ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: imath; with a semi-colon" do
    input = "&imath;"
    output = [["Character", "ı"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: imof; with a semi-colon" do
    input = "&imof;"
    output = [["Character", "⊷"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: imped; with a semi-colon" do
    input = "&imped;"
    output = [["Character", "Ƶ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: in; with a semi-colon" do
    input = "&in;"
    output = [["Character", "∈"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: incare; with a semi-colon" do
    input = "&incare;"
    output = [["Character", "℅"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: infin; with a semi-colon" do
    input = "&infin;"
    output = [["Character", "∞"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: infintie; with a semi-colon" do
    input = "&infintie;"
    output = [["Character", "⧝"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: inodot; with a semi-colon" do
    input = "&inodot;"
    output = [["Character", "ı"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: int; with a semi-colon" do
    input = "&int;"
    output = [["Character", "∫"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: intcal; with a semi-colon" do
    input = "&intcal;"
    output = [["Character", "⊺"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: integers; with a semi-colon" do
    input = "&integers;"
    output = [["Character", "ℤ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: intercal; with a semi-colon" do
    input = "&intercal;"
    output = [["Character", "⊺"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: intlarhk; with a semi-colon" do
    input = "&intlarhk;"
    output = [["Character", "⨗"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: intprod; with a semi-colon" do
    input = "&intprod;"
    output = [["Character", "⨼"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: iocy; with a semi-colon" do
    input = "&iocy;"
    output = [["Character", "ё"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: iogon; with a semi-colon" do
    input = "&iogon;"
    output = [["Character", "į"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: iopf; with a semi-colon" do
    input = "&iopf;"
    output = [["Character", "𝕚"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: iota; with a semi-colon" do
    input = "&iota;"
    output = [["Character", "ι"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: iprod; with a semi-colon" do
    input = "&iprod;"
    output = [["Character", "⨼"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: iquest without a semi-colon" do
    input = "&iquest"
    output = [["Character", "¿"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end
end