defmodule Floki.HTML.Generated.Tokenizer.NamedentitiesPart36Test do
  use ExUnit.Case, async: true

  # NOTE: This file was generated by "mix generate_tokenizer_tests namedEntities.test".
  # html5lib-tests rev: e52ff68cc7113a6ef3687747fa82691079bf9cc5

  alias Floki.HTML.Tokenizer

  test "tokenize/1 Named entity: nlsim; with a semi-colon" do
    input = "&nlsim;"
    output = [["Character", "â‰´"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nlt; with a semi-colon" do
    input = "&nlt;"
    output = [["Character", "â‰®"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nltri; with a semi-colon" do
    input = "&nltri;"
    output = [["Character", "â‹ª"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nltrie; with a semi-colon" do
    input = "&nltrie;"
    output = [["Character", "â‹¬"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nmid; with a semi-colon" do
    input = "&nmid;"
    output = [["Character", "âˆ¤"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nopf; with a semi-colon" do
    input = "&nopf;"
    output = [["Character", "ð•Ÿ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: not without a semi-colon" do
    input = "&not"
    output = [["Character", "Â¬"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: not; with a semi-colon" do
    input = "&not;"
    output = [["Character", "Â¬"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: notin; with a semi-colon" do
    input = "&notin;"
    output = [["Character", "âˆ‰"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: notinE; with a semi-colon" do
    input = "&notinE;"
    output = [["Character", "â‹¹Ì¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: notindot; with a semi-colon" do
    input = "&notindot;"
    output = [["Character", "â‹µÌ¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: notinva; with a semi-colon" do
    input = "&notinva;"
    output = [["Character", "âˆ‰"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: notinvb; with a semi-colon" do
    input = "&notinvb;"
    output = [["Character", "â‹·"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: notinvc; with a semi-colon" do
    input = "&notinvc;"
    output = [["Character", "â‹¶"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: notni; with a semi-colon" do
    input = "&notni;"
    output = [["Character", "âˆŒ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: notniva; with a semi-colon" do
    input = "&notniva;"
    output = [["Character", "âˆŒ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: notnivb; with a semi-colon" do
    input = "&notnivb;"
    output = [["Character", "â‹¾"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: notnivc; with a semi-colon" do
    input = "&notnivc;"
    output = [["Character", "â‹½"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: npar; with a semi-colon" do
    input = "&npar;"
    output = [["Character", "âˆ¦"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nparallel; with a semi-colon" do
    input = "&nparallel;"
    output = [["Character", "âˆ¦"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nparsl; with a semi-colon" do
    input = "&nparsl;"
    output = [["Character", "â«½âƒ¥"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: npart; with a semi-colon" do
    input = "&npart;"
    output = [["Character", "âˆ‚Ì¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: npolint; with a semi-colon" do
    input = "&npolint;"
    output = [["Character", "â¨”"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: npr; with a semi-colon" do
    input = "&npr;"
    output = [["Character", "âŠ€"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nprcue; with a semi-colon" do
    input = "&nprcue;"
    output = [["Character", "â‹ "]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: npre; with a semi-colon" do
    input = "&npre;"
    output = [["Character", "âª¯Ì¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nprec; with a semi-colon" do
    input = "&nprec;"
    output = [["Character", "âŠ€"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: npreceq; with a semi-colon" do
    input = "&npreceq;"
    output = [["Character", "âª¯Ì¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nrArr; with a semi-colon" do
    input = "&nrArr;"
    output = [["Character", "â‡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nrarr; with a semi-colon" do
    input = "&nrarr;"
    output = [["Character", "â†›"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nrarrc; with a semi-colon" do
    input = "&nrarrc;"
    output = [["Character", "â¤³Ì¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nrarrw; with a semi-colon" do
    input = "&nrarrw;"
    output = [["Character", "â†Ì¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nrightarrow; with a semi-colon" do
    input = "&nrightarrow;"
    output = [["Character", "â†›"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nrtri; with a semi-colon" do
    input = "&nrtri;"
    output = [["Character", "â‹«"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nrtrie; with a semi-colon" do
    input = "&nrtrie;"
    output = [["Character", "â‹­"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nsc; with a semi-colon" do
    input = "&nsc;"
    output = [["Character", "âŠ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nsccue; with a semi-colon" do
    input = "&nsccue;"
    output = [["Character", "â‹¡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nsce; with a semi-colon" do
    input = "&nsce;"
    output = [["Character", "âª°Ì¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nscr; with a semi-colon" do
    input = "&nscr;"
    output = [["Character", "ð“ƒ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nshortmid; with a semi-colon" do
    input = "&nshortmid;"
    output = [["Character", "âˆ¤"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nshortparallel; with a semi-colon" do
    input = "&nshortparallel;"
    output = [["Character", "âˆ¦"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nsim; with a semi-colon" do
    input = "&nsim;"
    output = [["Character", "â‰"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nsime; with a semi-colon" do
    input = "&nsime;"
    output = [["Character", "â‰„"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nsimeq; with a semi-colon" do
    input = "&nsimeq;"
    output = [["Character", "â‰„"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nsmid; with a semi-colon" do
    input = "&nsmid;"
    output = [["Character", "âˆ¤"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nspar; with a semi-colon" do
    input = "&nspar;"
    output = [["Character", "âˆ¦"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nsqsube; with a semi-colon" do
    input = "&nsqsube;"
    output = [["Character", "â‹¢"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nsqsupe; with a semi-colon" do
    input = "&nsqsupe;"
    output = [["Character", "â‹£"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nsub; with a semi-colon" do
    input = "&nsub;"
    output = [["Character", "âŠ„"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nsubE; with a semi-colon" do
    input = "&nsubE;"
    output = [["Character", "â«…Ì¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nsube; with a semi-colon" do
    input = "&nsube;"
    output = [["Character", "âŠˆ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nsubset; with a semi-colon" do
    input = "&nsubset;"
    output = [["Character", "âŠ‚âƒ’"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nsubseteq; with a semi-colon" do
    input = "&nsubseteq;"
    output = [["Character", "âŠˆ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nsubseteqq; with a semi-colon" do
    input = "&nsubseteqq;"
    output = [["Character", "â«…Ì¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nsucc; with a semi-colon" do
    input = "&nsucc;"
    output = [["Character", "âŠ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nsucceq; with a semi-colon" do
    input = "&nsucceq;"
    output = [["Character", "âª°Ì¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nsup; with a semi-colon" do
    input = "&nsup;"
    output = [["Character", "âŠ…"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nsupE; with a semi-colon" do
    input = "&nsupE;"
    output = [["Character", "â«†Ì¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nsupe; with a semi-colon" do
    input = "&nsupe;"
    output = [["Character", "âŠ‰"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nsupset; with a semi-colon" do
    input = "&nsupset;"
    output = [["Character", "âŠƒâƒ’"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nsupseteq; with a semi-colon" do
    input = "&nsupseteq;"
    output = [["Character", "âŠ‰"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nsupseteqq; with a semi-colon" do
    input = "&nsupseteqq;"
    output = [["Character", "â«†Ì¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ntgl; with a semi-colon" do
    input = "&ntgl;"
    output = [["Character", "â‰¹"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ntilde without a semi-colon" do
    input = "&ntilde"
    output = [["Character", "Ã±"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ntilde; with a semi-colon" do
    input = "&ntilde;"
    output = [["Character", "Ã±"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ntlg; with a semi-colon" do
    input = "&ntlg;"
    output = [["Character", "â‰¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ntriangleleft; with a semi-colon" do
    input = "&ntriangleleft;"
    output = [["Character", "â‹ª"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ntrianglelefteq; with a semi-colon" do
    input = "&ntrianglelefteq;"
    output = [["Character", "â‹¬"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ntriangleright; with a semi-colon" do
    input = "&ntriangleright;"
    output = [["Character", "â‹«"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ntrianglerighteq; with a semi-colon" do
    input = "&ntrianglerighteq;"
    output = [["Character", "â‹­"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nu; with a semi-colon" do
    input = "&nu;"
    output = [["Character", "Î½"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: num; with a semi-colon" do
    input = "&num;"
    output = [["Character", "#"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: numero; with a semi-colon" do
    input = "&numero;"
    output = [["Character", "â„–"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: numsp; with a semi-colon" do
    input = "&numsp;"
    output = [["Character", "â€‡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nvDash; with a semi-colon" do
    input = "&nvDash;"
    output = [["Character", "âŠ­"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nvHarr; with a semi-colon" do
    input = "&nvHarr;"
    output = [["Character", "â¤„"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nvap; with a semi-colon" do
    input = "&nvap;"
    output = [["Character", "â‰âƒ’"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nvdash; with a semi-colon" do
    input = "&nvdash;"
    output = [["Character", "âŠ¬"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nvge; with a semi-colon" do
    input = "&nvge;"
    output = [["Character", "â‰¥âƒ’"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nvgt; with a semi-colon" do
    input = "&nvgt;"
    output = [["Character", ">âƒ’"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nvinfin; with a semi-colon" do
    input = "&nvinfin;"
    output = [["Character", "â§ž"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nvlArr; with a semi-colon" do
    input = "&nvlArr;"
    output = [["Character", "â¤‚"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nvle; with a semi-colon" do
    input = "&nvle;"
    output = [["Character", "â‰¤âƒ’"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nvlt; with a semi-colon" do
    input = "&nvlt;"
    output = [["Character", "<âƒ’"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nvltrie; with a semi-colon" do
    input = "&nvltrie;"
    output = [["Character", "âŠ´âƒ’"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nvrArr; with a semi-colon" do
    input = "&nvrArr;"
    output = [["Character", "â¤ƒ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nvrtrie; with a semi-colon" do
    input = "&nvrtrie;"
    output = [["Character", "âŠµâƒ’"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nvsim; with a semi-colon" do
    input = "&nvsim;"
    output = [["Character", "âˆ¼âƒ’"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nwArr; with a semi-colon" do
    input = "&nwArr;"
    output = [["Character", "â‡–"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nwarhk; with a semi-colon" do
    input = "&nwarhk;"
    output = [["Character", "â¤£"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nwarr; with a semi-colon" do
    input = "&nwarr;"
    output = [["Character", "â†–"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nwarrow; with a semi-colon" do
    input = "&nwarrow;"
    output = [["Character", "â†–"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: nwnear; with a semi-colon" do
    input = "&nwnear;"
    output = [["Character", "â¤§"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: oS; with a semi-colon" do
    input = "&oS;"
    output = [["Character", "â“ˆ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: oacute without a semi-colon" do
    input = "&oacute"
    output = [["Character", "Ã³"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: oacute; with a semi-colon" do
    input = "&oacute;"
    output = [["Character", "Ã³"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: oast; with a semi-colon" do
    input = "&oast;"
    output = [["Character", "âŠ›"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ocir; with a semi-colon" do
    input = "&ocir;"
    output = [["Character", "âŠš"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ocirc without a semi-colon" do
    input = "&ocirc"
    output = [["Character", "Ã´"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ocirc; with a semi-colon" do
    input = "&ocirc;"
    output = [["Character", "Ã´"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end
end