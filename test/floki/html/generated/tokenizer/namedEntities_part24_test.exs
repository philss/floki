defmodule Floki.HTML.Generated.Tokenizer.NamedentitiesPart24Test do
  use ExUnit.Case, async: true

  # NOTE: This file was generated by "mix generate_tokenizer_tests namedEntities.test".
  # html5lib-tests rev: e52ff68cc7113a6ef3687747fa82691079bf9cc5

  alias Floki.HTML.Tokenizer

  test "tokenize/1 Named entity: NegativeThinSpace; with a semi-colon" do
    input = "&NegativeThinSpace;"
    output = [["Character", "â€‹"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NegativeVeryThinSpace; with a semi-colon" do
    input = "&NegativeVeryThinSpace;"
    output = [["Character", "â€‹"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NestedGreaterGreater; with a semi-colon" do
    input = "&NestedGreaterGreater;"
    output = [["Character", "â‰«"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NestedLessLess; with a semi-colon" do
    input = "&NestedLessLess;"
    output = [["Character", "â‰ª"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NewLine; with a semi-colon" do
    input = "&NewLine;"
    output = [["Character", "\n"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Nfr; with a semi-colon" do
    input = "&Nfr;"
    output = [["Character", "ð”‘"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NoBreak; with a semi-colon" do
    input = "&NoBreak;"
    output = [["Character", "â "]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NonBreakingSpace; with a semi-colon" do
    input = "&NonBreakingSpace;"
    output = [["Character", "Â "]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Nopf; with a semi-colon" do
    input = "&Nopf;"
    output = [["Character", "â„•"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Not; with a semi-colon" do
    input = "&Not;"
    output = [["Character", "â«¬"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotCongruent; with a semi-colon" do
    input = "&NotCongruent;"
    output = [["Character", "â‰¢"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotCupCap; with a semi-colon" do
    input = "&NotCupCap;"
    output = [["Character", "â‰­"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotDoubleVerticalBar; with a semi-colon" do
    input = "&NotDoubleVerticalBar;"
    output = [["Character", "âˆ¦"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotElement; with a semi-colon" do
    input = "&NotElement;"
    output = [["Character", "âˆ‰"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotEqual; with a semi-colon" do
    input = "&NotEqual;"
    output = [["Character", "â‰ "]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotEqualTilde; with a semi-colon" do
    input = "&NotEqualTilde;"
    output = [["Character", "â‰‚Ì¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotExists; with a semi-colon" do
    input = "&NotExists;"
    output = [["Character", "âˆ„"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotGreater; with a semi-colon" do
    input = "&NotGreater;"
    output = [["Character", "â‰¯"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotGreaterEqual; with a semi-colon" do
    input = "&NotGreaterEqual;"
    output = [["Character", "â‰±"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotGreaterFullEqual; with a semi-colon" do
    input = "&NotGreaterFullEqual;"
    output = [["Character", "â‰§Ì¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotGreaterGreater; with a semi-colon" do
    input = "&NotGreaterGreater;"
    output = [["Character", "â‰«Ì¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotGreaterLess; with a semi-colon" do
    input = "&NotGreaterLess;"
    output = [["Character", "â‰¹"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotGreaterSlantEqual; with a semi-colon" do
    input = "&NotGreaterSlantEqual;"
    output = [["Character", "â©¾Ì¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotGreaterTilde; with a semi-colon" do
    input = "&NotGreaterTilde;"
    output = [["Character", "â‰µ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotHumpDownHump; with a semi-colon" do
    input = "&NotHumpDownHump;"
    output = [["Character", "â‰ŽÌ¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotHumpEqual; with a semi-colon" do
    input = "&NotHumpEqual;"
    output = [["Character", "â‰Ì¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotLeftTriangle; with a semi-colon" do
    input = "&NotLeftTriangle;"
    output = [["Character", "â‹ª"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotLeftTriangleBar; with a semi-colon" do
    input = "&NotLeftTriangleBar;"
    output = [["Character", "â§Ì¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotLeftTriangleEqual; with a semi-colon" do
    input = "&NotLeftTriangleEqual;"
    output = [["Character", "â‹¬"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotLess; with a semi-colon" do
    input = "&NotLess;"
    output = [["Character", "â‰®"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotLessEqual; with a semi-colon" do
    input = "&NotLessEqual;"
    output = [["Character", "â‰°"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotLessGreater; with a semi-colon" do
    input = "&NotLessGreater;"
    output = [["Character", "â‰¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotLessLess; with a semi-colon" do
    input = "&NotLessLess;"
    output = [["Character", "â‰ªÌ¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotLessSlantEqual; with a semi-colon" do
    input = "&NotLessSlantEqual;"
    output = [["Character", "â©½Ì¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotLessTilde; with a semi-colon" do
    input = "&NotLessTilde;"
    output = [["Character", "â‰´"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotNestedGreaterGreater; with a semi-colon" do
    input = "&NotNestedGreaterGreater;"
    output = [["Character", "âª¢Ì¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotNestedLessLess; with a semi-colon" do
    input = "&NotNestedLessLess;"
    output = [["Character", "âª¡Ì¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotPrecedes; with a semi-colon" do
    input = "&NotPrecedes;"
    output = [["Character", "âŠ€"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotPrecedesEqual; with a semi-colon" do
    input = "&NotPrecedesEqual;"
    output = [["Character", "âª¯Ì¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotPrecedesSlantEqual; with a semi-colon" do
    input = "&NotPrecedesSlantEqual;"
    output = [["Character", "â‹ "]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotReverseElement; with a semi-colon" do
    input = "&NotReverseElement;"
    output = [["Character", "âˆŒ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotRightTriangle; with a semi-colon" do
    input = "&NotRightTriangle;"
    output = [["Character", "â‹«"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotRightTriangleBar; with a semi-colon" do
    input = "&NotRightTriangleBar;"
    output = [["Character", "â§Ì¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotRightTriangleEqual; with a semi-colon" do
    input = "&NotRightTriangleEqual;"
    output = [["Character", "â‹­"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotSquareSubset; with a semi-colon" do
    input = "&NotSquareSubset;"
    output = [["Character", "âŠÌ¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotSquareSubsetEqual; with a semi-colon" do
    input = "&NotSquareSubsetEqual;"
    output = [["Character", "â‹¢"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotSquareSuperset; with a semi-colon" do
    input = "&NotSquareSuperset;"
    output = [["Character", "âŠÌ¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotSquareSupersetEqual; with a semi-colon" do
    input = "&NotSquareSupersetEqual;"
    output = [["Character", "â‹£"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotSubset; with a semi-colon" do
    input = "&NotSubset;"
    output = [["Character", "âŠ‚âƒ’"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotSubsetEqual; with a semi-colon" do
    input = "&NotSubsetEqual;"
    output = [["Character", "âŠˆ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotSucceeds; with a semi-colon" do
    input = "&NotSucceeds;"
    output = [["Character", "âŠ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotSucceedsEqual; with a semi-colon" do
    input = "&NotSucceedsEqual;"
    output = [["Character", "âª°Ì¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotSucceedsSlantEqual; with a semi-colon" do
    input = "&NotSucceedsSlantEqual;"
    output = [["Character", "â‹¡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotSucceedsTilde; with a semi-colon" do
    input = "&NotSucceedsTilde;"
    output = [["Character", "â‰¿Ì¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotSuperset; with a semi-colon" do
    input = "&NotSuperset;"
    output = [["Character", "âŠƒâƒ’"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotSupersetEqual; with a semi-colon" do
    input = "&NotSupersetEqual;"
    output = [["Character", "âŠ‰"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotTilde; with a semi-colon" do
    input = "&NotTilde;"
    output = [["Character", "â‰"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotTildeEqual; with a semi-colon" do
    input = "&NotTildeEqual;"
    output = [["Character", "â‰„"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotTildeFullEqual; with a semi-colon" do
    input = "&NotTildeFullEqual;"
    output = [["Character", "â‰‡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotTildeTilde; with a semi-colon" do
    input = "&NotTildeTilde;"
    output = [["Character", "â‰‰"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotVerticalBar; with a semi-colon" do
    input = "&NotVerticalBar;"
    output = [["Character", "âˆ¤"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Nscr; with a semi-colon" do
    input = "&Nscr;"
    output = [["Character", "ð’©"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ntilde without a semi-colon" do
    input = "&Ntilde"
    output = [["Character", "Ã‘"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ntilde; with a semi-colon" do
    input = "&Ntilde;"
    output = [["Character", "Ã‘"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Nu; with a semi-colon" do
    input = "&Nu;"
    output = [["Character", "Î"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: OElig; with a semi-colon" do
    input = "&OElig;"
    output = [["Character", "Å’"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Oacute without a semi-colon" do
    input = "&Oacute"
    output = [["Character", "Ã“"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Oacute; with a semi-colon" do
    input = "&Oacute;"
    output = [["Character", "Ã“"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ocirc without a semi-colon" do
    input = "&Ocirc"
    output = [["Character", "Ã”"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ocirc; with a semi-colon" do
    input = "&Ocirc;"
    output = [["Character", "Ã”"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ocy; with a semi-colon" do
    input = "&Ocy;"
    output = [["Character", "Ðž"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Odblac; with a semi-colon" do
    input = "&Odblac;"
    output = [["Character", "Å"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ofr; with a semi-colon" do
    input = "&Ofr;"
    output = [["Character", "ð”’"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ograve without a semi-colon" do
    input = "&Ograve"
    output = [["Character", "Ã’"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ograve; with a semi-colon" do
    input = "&Ograve;"
    output = [["Character", "Ã’"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Omacr; with a semi-colon" do
    input = "&Omacr;"
    output = [["Character", "ÅŒ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Omega; with a semi-colon" do
    input = "&Omega;"
    output = [["Character", "Î©"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Omicron; with a semi-colon" do
    input = "&Omicron;"
    output = [["Character", "ÎŸ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Oopf; with a semi-colon" do
    input = "&Oopf;"
    output = [["Character", "ð•†"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: OpenCurlyDoubleQuote; with a semi-colon" do
    input = "&OpenCurlyDoubleQuote;"
    output = [["Character", "â€œ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: OpenCurlyQuote; with a semi-colon" do
    input = "&OpenCurlyQuote;"
    output = [["Character", "â€˜"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Or; with a semi-colon" do
    input = "&Or;"
    output = [["Character", "â©”"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Oscr; with a semi-colon" do
    input = "&Oscr;"
    output = [["Character", "ð’ª"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Oslash without a semi-colon" do
    input = "&Oslash"
    output = [["Character", "Ã˜"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Oslash; with a semi-colon" do
    input = "&Oslash;"
    output = [["Character", "Ã˜"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Otilde without a semi-colon" do
    input = "&Otilde"
    output = [["Character", "Ã•"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Otilde; with a semi-colon" do
    input = "&Otilde;"
    output = [["Character", "Ã•"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Otimes; with a semi-colon" do
    input = "&Otimes;"
    output = [["Character", "â¨·"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ouml without a semi-colon" do
    input = "&Ouml"
    output = [["Character", "Ã–"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ouml; with a semi-colon" do
    input = "&Ouml;"
    output = [["Character", "Ã–"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: OverBar; with a semi-colon" do
    input = "&OverBar;"
    output = [["Character", "â€¾"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: OverBrace; with a semi-colon" do
    input = "&OverBrace;"
    output = [["Character", "âž"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: OverBracket; with a semi-colon" do
    input = "&OverBracket;"
    output = [["Character", "âŽ´"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: OverParenthesis; with a semi-colon" do
    input = "&OverParenthesis;"
    output = [["Character", "âœ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: PartialD; with a semi-colon" do
    input = "&PartialD;"
    output = [["Character", "âˆ‚"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Pcy; with a semi-colon" do
    input = "&Pcy;"
    output = [["Character", "ÐŸ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Pfr; with a semi-colon" do
    input = "&Pfr;"
    output = [["Character", "ð”“"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Phi; with a semi-colon" do
    input = "&Phi;"
    output = [["Character", "Î¦"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Pi; with a semi-colon" do
    input = "&Pi;"
    output = [["Character", "Î "]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: PlusMinus; with a semi-colon" do
    input = "&PlusMinus;"
    output = [["Character", "Â±"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end
end