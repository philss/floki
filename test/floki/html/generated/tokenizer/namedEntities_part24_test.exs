defmodule Floki.HTML.Generated.Tokenizer.NamedentitiesPart24Test do
  use ExUnit.Case, async: true

  # NOTE: This file was generated by "mix generate_tokenizer_tests namedEntities.test".
  # html5lib-tests rev: e52ff68cc7113a6ef3687747fa82691079bf9cc5

  alias Floki.HTML.Tokenizer

  test "tokenize/1 Named entity: NegativeThinSpace; with a semi-colon" do
    input = "&NegativeThinSpace;"
    output = [["Character", "​"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NegativeVeryThinSpace; with a semi-colon" do
    input = "&NegativeVeryThinSpace;"
    output = [["Character", "​"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NestedGreaterGreater; with a semi-colon" do
    input = "&NestedGreaterGreater;"
    output = [["Character", "≫"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NestedLessLess; with a semi-colon" do
    input = "&NestedLessLess;"
    output = [["Character", "≪"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NewLine; with a semi-colon" do
    input = "&NewLine;"
    output = [["Character", "\n"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Nfr; with a semi-colon" do
    input = "&Nfr;"
    output = [["Character", "𝔑"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NoBreak; with a semi-colon" do
    input = "&NoBreak;"
    output = [["Character", "⁠"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NonBreakingSpace; with a semi-colon" do
    input = "&NonBreakingSpace;"
    output = [["Character", " "]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Nopf; with a semi-colon" do
    input = "&Nopf;"
    output = [["Character", "ℕ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Not; with a semi-colon" do
    input = "&Not;"
    output = [["Character", "⫬"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotCongruent; with a semi-colon" do
    input = "&NotCongruent;"
    output = [["Character", "≢"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotCupCap; with a semi-colon" do
    input = "&NotCupCap;"
    output = [["Character", "≭"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotDoubleVerticalBar; with a semi-colon" do
    input = "&NotDoubleVerticalBar;"
    output = [["Character", "∦"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotElement; with a semi-colon" do
    input = "&NotElement;"
    output = [["Character", "∉"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotEqual; with a semi-colon" do
    input = "&NotEqual;"
    output = [["Character", "≠"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotEqualTilde; with a semi-colon" do
    input = "&NotEqualTilde;"
    output = [["Character", "≂̸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotExists; with a semi-colon" do
    input = "&NotExists;"
    output = [["Character", "∄"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotGreater; with a semi-colon" do
    input = "&NotGreater;"
    output = [["Character", "≯"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotGreaterEqual; with a semi-colon" do
    input = "&NotGreaterEqual;"
    output = [["Character", "≱"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotGreaterFullEqual; with a semi-colon" do
    input = "&NotGreaterFullEqual;"
    output = [["Character", "≧̸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotGreaterGreater; with a semi-colon" do
    input = "&NotGreaterGreater;"
    output = [["Character", "≫̸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotGreaterLess; with a semi-colon" do
    input = "&NotGreaterLess;"
    output = [["Character", "≹"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotGreaterSlantEqual; with a semi-colon" do
    input = "&NotGreaterSlantEqual;"
    output = [["Character", "⩾̸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotGreaterTilde; with a semi-colon" do
    input = "&NotGreaterTilde;"
    output = [["Character", "≵"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotHumpDownHump; with a semi-colon" do
    input = "&NotHumpDownHump;"
    output = [["Character", "≎̸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotHumpEqual; with a semi-colon" do
    input = "&NotHumpEqual;"
    output = [["Character", "≏̸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotLeftTriangle; with a semi-colon" do
    input = "&NotLeftTriangle;"
    output = [["Character", "⋪"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotLeftTriangleBar; with a semi-colon" do
    input = "&NotLeftTriangleBar;"
    output = [["Character", "⧏̸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotLeftTriangleEqual; with a semi-colon" do
    input = "&NotLeftTriangleEqual;"
    output = [["Character", "⋬"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotLess; with a semi-colon" do
    input = "&NotLess;"
    output = [["Character", "≮"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotLessEqual; with a semi-colon" do
    input = "&NotLessEqual;"
    output = [["Character", "≰"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotLessGreater; with a semi-colon" do
    input = "&NotLessGreater;"
    output = [["Character", "≸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotLessLess; with a semi-colon" do
    input = "&NotLessLess;"
    output = [["Character", "≪̸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotLessSlantEqual; with a semi-colon" do
    input = "&NotLessSlantEqual;"
    output = [["Character", "⩽̸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotLessTilde; with a semi-colon" do
    input = "&NotLessTilde;"
    output = [["Character", "≴"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotNestedGreaterGreater; with a semi-colon" do
    input = "&NotNestedGreaterGreater;"
    output = [["Character", "⪢̸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotNestedLessLess; with a semi-colon" do
    input = "&NotNestedLessLess;"
    output = [["Character", "⪡̸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotPrecedes; with a semi-colon" do
    input = "&NotPrecedes;"
    output = [["Character", "⊀"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotPrecedesEqual; with a semi-colon" do
    input = "&NotPrecedesEqual;"
    output = [["Character", "⪯̸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotPrecedesSlantEqual; with a semi-colon" do
    input = "&NotPrecedesSlantEqual;"
    output = [["Character", "⋠"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotReverseElement; with a semi-colon" do
    input = "&NotReverseElement;"
    output = [["Character", "∌"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotRightTriangle; with a semi-colon" do
    input = "&NotRightTriangle;"
    output = [["Character", "⋫"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotRightTriangleBar; with a semi-colon" do
    input = "&NotRightTriangleBar;"
    output = [["Character", "⧐̸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotRightTriangleEqual; with a semi-colon" do
    input = "&NotRightTriangleEqual;"
    output = [["Character", "⋭"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotSquareSubset; with a semi-colon" do
    input = "&NotSquareSubset;"
    output = [["Character", "⊏̸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotSquareSubsetEqual; with a semi-colon" do
    input = "&NotSquareSubsetEqual;"
    output = [["Character", "⋢"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotSquareSuperset; with a semi-colon" do
    input = "&NotSquareSuperset;"
    output = [["Character", "⊐̸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotSquareSupersetEqual; with a semi-colon" do
    input = "&NotSquareSupersetEqual;"
    output = [["Character", "⋣"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotSubset; with a semi-colon" do
    input = "&NotSubset;"
    output = [["Character", "⊂⃒"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotSubsetEqual; with a semi-colon" do
    input = "&NotSubsetEqual;"
    output = [["Character", "⊈"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotSucceeds; with a semi-colon" do
    input = "&NotSucceeds;"
    output = [["Character", "⊁"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotSucceedsEqual; with a semi-colon" do
    input = "&NotSucceedsEqual;"
    output = [["Character", "⪰̸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotSucceedsSlantEqual; with a semi-colon" do
    input = "&NotSucceedsSlantEqual;"
    output = [["Character", "⋡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotSucceedsTilde; with a semi-colon" do
    input = "&NotSucceedsTilde;"
    output = [["Character", "≿̸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotSuperset; with a semi-colon" do
    input = "&NotSuperset;"
    output = [["Character", "⊃⃒"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotSupersetEqual; with a semi-colon" do
    input = "&NotSupersetEqual;"
    output = [["Character", "⊉"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotTilde; with a semi-colon" do
    input = "&NotTilde;"
    output = [["Character", "≁"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotTildeEqual; with a semi-colon" do
    input = "&NotTildeEqual;"
    output = [["Character", "≄"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotTildeFullEqual; with a semi-colon" do
    input = "&NotTildeFullEqual;"
    output = [["Character", "≇"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotTildeTilde; with a semi-colon" do
    input = "&NotTildeTilde;"
    output = [["Character", "≉"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: NotVerticalBar; with a semi-colon" do
    input = "&NotVerticalBar;"
    output = [["Character", "∤"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Nscr; with a semi-colon" do
    input = "&Nscr;"
    output = [["Character", "𝒩"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ntilde without a semi-colon" do
    input = "&Ntilde"
    output = [["Character", "Ñ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ntilde; with a semi-colon" do
    input = "&Ntilde;"
    output = [["Character", "Ñ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Nu; with a semi-colon" do
    input = "&Nu;"
    output = [["Character", "Ν"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: OElig; with a semi-colon" do
    input = "&OElig;"
    output = [["Character", "Œ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Oacute without a semi-colon" do
    input = "&Oacute"
    output = [["Character", "Ó"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Oacute; with a semi-colon" do
    input = "&Oacute;"
    output = [["Character", "Ó"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ocirc without a semi-colon" do
    input = "&Ocirc"
    output = [["Character", "Ô"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ocirc; with a semi-colon" do
    input = "&Ocirc;"
    output = [["Character", "Ô"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ocy; with a semi-colon" do
    input = "&Ocy;"
    output = [["Character", "О"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Odblac; with a semi-colon" do
    input = "&Odblac;"
    output = [["Character", "Ő"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ofr; with a semi-colon" do
    input = "&Ofr;"
    output = [["Character", "𝔒"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ograve without a semi-colon" do
    input = "&Ograve"
    output = [["Character", "Ò"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ograve; with a semi-colon" do
    input = "&Ograve;"
    output = [["Character", "Ò"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Omacr; with a semi-colon" do
    input = "&Omacr;"
    output = [["Character", "Ō"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Omega; with a semi-colon" do
    input = "&Omega;"
    output = [["Character", "Ω"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Omicron; with a semi-colon" do
    input = "&Omicron;"
    output = [["Character", "Ο"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Oopf; with a semi-colon" do
    input = "&Oopf;"
    output = [["Character", "𝕆"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: OpenCurlyDoubleQuote; with a semi-colon" do
    input = "&OpenCurlyDoubleQuote;"
    output = [["Character", "“"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: OpenCurlyQuote; with a semi-colon" do
    input = "&OpenCurlyQuote;"
    output = [["Character", "‘"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Or; with a semi-colon" do
    input = "&Or;"
    output = [["Character", "⩔"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Oscr; with a semi-colon" do
    input = "&Oscr;"
    output = [["Character", "𝒪"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Oslash without a semi-colon" do
    input = "&Oslash"
    output = [["Character", "Ø"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Oslash; with a semi-colon" do
    input = "&Oslash;"
    output = [["Character", "Ø"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Otilde without a semi-colon" do
    input = "&Otilde"
    output = [["Character", "Õ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Otilde; with a semi-colon" do
    input = "&Otilde;"
    output = [["Character", "Õ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Otimes; with a semi-colon" do
    input = "&Otimes;"
    output = [["Character", "⨷"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ouml without a semi-colon" do
    input = "&Ouml"
    output = [["Character", "Ö"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ouml; with a semi-colon" do
    input = "&Ouml;"
    output = [["Character", "Ö"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: OverBar; with a semi-colon" do
    input = "&OverBar;"
    output = [["Character", "‾"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: OverBrace; with a semi-colon" do
    input = "&OverBrace;"
    output = [["Character", "⏞"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: OverBracket; with a semi-colon" do
    input = "&OverBracket;"
    output = [["Character", "⎴"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: OverParenthesis; with a semi-colon" do
    input = "&OverParenthesis;"
    output = [["Character", "⏜"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: PartialD; with a semi-colon" do
    input = "&PartialD;"
    output = [["Character", "∂"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Pcy; with a semi-colon" do
    input = "&Pcy;"
    output = [["Character", "П"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Pfr; with a semi-colon" do
    input = "&Pfr;"
    output = [["Character", "𝔓"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Phi; with a semi-colon" do
    input = "&Phi;"
    output = [["Character", "Φ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Pi; with a semi-colon" do
    input = "&Pi;"
    output = [["Character", "Π"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: PlusMinus; with a semi-colon" do
    input = "&PlusMinus;"
    output = [["Character", "±"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end
end