defmodule Floki.HTML.Generated.Tokenizer.NamedentitiesPart43Test do
  use ExUnit.Case, async: true

  # NOTE: This file was generated by "mix generate_tokenizer_tests namedEntities.test".
  # html5lib-tests rev: e52ff68cc7113a6ef3687747fa82691079bf9cc5

  alias Floki.HTML.Tokenizer

  test "tokenize/1 Named entity: zdot; with a semi-colon" do
    input = "&zdot;"
    output = [["Character", "ż"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: zeetrf; with a semi-colon" do
    input = "&zeetrf;"
    output = [["Character", "ℨ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: zeta; with a semi-colon" do
    input = "&zeta;"
    output = [["Character", "ζ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: zfr; with a semi-colon" do
    input = "&zfr;"
    output = [["Character", "𝔷"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: zhcy; with a semi-colon" do
    input = "&zhcy;"
    output = [["Character", "ж"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: zigrarr; with a semi-colon" do
    input = "&zigrarr;"
    output = [["Character", "⇝"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: zopf; with a semi-colon" do
    input = "&zopf;"
    output = [["Character", "𝕫"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: zscr; with a semi-colon" do
    input = "&zscr;"
    output = [["Character", "𝓏"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: zwj; with a semi-colon" do
    input = "&zwj;"
    output = [["Character", "‍"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: zwnj; with a semi-colon" do
    input = "&zwnj;"
    output = [["Character", "‌"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end
end