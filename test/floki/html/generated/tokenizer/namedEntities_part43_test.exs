defmodule Floki.HTML.Generated.Tokenizer.NamedentitiesPart43Test do
  use ExUnit.Case, async: true

  # NOTE: This file was generated by "mix generate_tokenizer_tests namedEntities.test".
  # html5lib-tests rev: e52ff68cc7113a6ef3687747fa82691079bf9cc5

  alias Floki.HTML.Tokenizer

  test "tokenize/1 Named entity: zdot; with a semi-colon" do
    input = "&zdot;"
    output = [["Character", "Å¼"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: zeetrf; with a semi-colon" do
    input = "&zeetrf;"
    output = [["Character", "â„¨"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: zeta; with a semi-colon" do
    input = "&zeta;"
    output = [["Character", "Î¶"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: zfr; with a semi-colon" do
    input = "&zfr;"
    output = [["Character", "ð”·"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: zhcy; with a semi-colon" do
    input = "&zhcy;"
    output = [["Character", "Ð¶"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: zigrarr; with a semi-colon" do
    input = "&zigrarr;"
    output = [["Character", "â‡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: zopf; with a semi-colon" do
    input = "&zopf;"
    output = [["Character", "ð•«"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: zscr; with a semi-colon" do
    input = "&zscr;"
    output = [["Character", "ð“"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: zwj; with a semi-colon" do
    input = "&zwj;"
    output = [["Character", "â€"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: zwnj; with a semi-colon" do
    input = "&zwnj;"
    output = [["Character", "â€Œ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end
end