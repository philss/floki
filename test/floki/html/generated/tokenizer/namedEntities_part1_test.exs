defmodule Floki.HTML.Generated.Tokenizer.NamedentitiesPart1Test do
  use ExUnit.Case, async: true

  # NOTE: This file was generated by "mix generate_tokenizer_tests namedEntities.test".
  # html5lib-tests rev: e52ff68cc7113a6ef3687747fa82691079bf9cc5

  alias Floki.HTML.Tokenizer

  test "tokenize/1 Bad named entity: Abreve without a semi-colon" do
    input = "&Abreve"
    output = [["Character", "&Abreve"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Acy without a semi-colon" do
    input = "&Acy"
    output = [["Character", "&Acy"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Afr without a semi-colon" do
    input = "&Afr"
    output = [["Character", "&Afr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Alpha without a semi-colon" do
    input = "&Alpha"
    output = [["Character", "&Alpha"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Amacr without a semi-colon" do
    input = "&Amacr"
    output = [["Character", "&Amacr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: And without a semi-colon" do
    input = "&And"
    output = [["Character", "&And"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Aogon without a semi-colon" do
    input = "&Aogon"
    output = [["Character", "&Aogon"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Aopf without a semi-colon" do
    input = "&Aopf"
    output = [["Character", "&Aopf"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: ApplyFunction without a semi-colon" do
    input = "&ApplyFunction"
    output = [["Character", "&ApplyFunction"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Ascr without a semi-colon" do
    input = "&Ascr"
    output = [["Character", "&Ascr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Assign without a semi-colon" do
    input = "&Assign"
    output = [["Character", "&Assign"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Backslash without a semi-colon" do
    input = "&Backslash"
    output = [["Character", "&Backslash"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Barv without a semi-colon" do
    input = "&Barv"
    output = [["Character", "&Barv"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Barwed without a semi-colon" do
    input = "&Barwed"
    output = [["Character", "&Barwed"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Bcy without a semi-colon" do
    input = "&Bcy"
    output = [["Character", "&Bcy"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Because without a semi-colon" do
    input = "&Because"
    output = [["Character", "&Because"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Bernoullis without a semi-colon" do
    input = "&Bernoullis"
    output = [["Character", "&Bernoullis"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Beta without a semi-colon" do
    input = "&Beta"
    output = [["Character", "&Beta"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Bfr without a semi-colon" do
    input = "&Bfr"
    output = [["Character", "&Bfr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Bopf without a semi-colon" do
    input = "&Bopf"
    output = [["Character", "&Bopf"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Breve without a semi-colon" do
    input = "&Breve"
    output = [["Character", "&Breve"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Bscr without a semi-colon" do
    input = "&Bscr"
    output = [["Character", "&Bscr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Bumpeq without a semi-colon" do
    input = "&Bumpeq"
    output = [["Character", "&Bumpeq"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: CHcy without a semi-colon" do
    input = "&CHcy"
    output = [["Character", "&CHcy"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Cacute without a semi-colon" do
    input = "&Cacute"
    output = [["Character", "&Cacute"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Cap without a semi-colon" do
    input = "&Cap"
    output = [["Character", "&Cap"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: CapitalDifferentialD without a semi-colon" do
    input = "&CapitalDifferentialD"
    output = [["Character", "&CapitalDifferentialD"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Cayleys without a semi-colon" do
    input = "&Cayleys"
    output = [["Character", "&Cayleys"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Ccaron without a semi-colon" do
    input = "&Ccaron"
    output = [["Character", "&Ccaron"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Ccirc without a semi-colon" do
    input = "&Ccirc"
    output = [["Character", "&Ccirc"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Cconint without a semi-colon" do
    input = "&Cconint"
    output = [["Character", "&Cconint"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Cdot without a semi-colon" do
    input = "&Cdot"
    output = [["Character", "&Cdot"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Cedilla without a semi-colon" do
    input = "&Cedilla"
    output = [["Character", "&Cedilla"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: CenterDot without a semi-colon" do
    input = "&CenterDot"
    output = [["Character", "&CenterDot"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Cfr without a semi-colon" do
    input = "&Cfr"
    output = [["Character", "&Cfr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Chi without a semi-colon" do
    input = "&Chi"
    output = [["Character", "&Chi"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: CircleDot without a semi-colon" do
    input = "&CircleDot"
    output = [["Character", "&CircleDot"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: CircleMinus without a semi-colon" do
    input = "&CircleMinus"
    output = [["Character", "&CircleMinus"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: CirclePlus without a semi-colon" do
    input = "&CirclePlus"
    output = [["Character", "&CirclePlus"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: CircleTimes without a semi-colon" do
    input = "&CircleTimes"
    output = [["Character", "&CircleTimes"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: ClockwiseContourIntegral without a semi-colon" do
    input = "&ClockwiseContourIntegral"
    output = [["Character", "&ClockwiseContourIntegral"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: CloseCurlyDoubleQuote without a semi-colon" do
    input = "&CloseCurlyDoubleQuote"
    output = [["Character", "&CloseCurlyDoubleQuote"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: CloseCurlyQuote without a semi-colon" do
    input = "&CloseCurlyQuote"
    output = [["Character", "&CloseCurlyQuote"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Colon without a semi-colon" do
    input = "&Colon"
    output = [["Character", "&Colon"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Colone without a semi-colon" do
    input = "&Colone"
    output = [["Character", "&Colone"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Congruent without a semi-colon" do
    input = "&Congruent"
    output = [["Character", "&Congruent"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Conint without a semi-colon" do
    input = "&Conint"
    output = [["Character", "&Conint"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: ContourIntegral without a semi-colon" do
    input = "&ContourIntegral"
    output = [["Character", "&ContourIntegral"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Copf without a semi-colon" do
    input = "&Copf"
    output = [["Character", "&Copf"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Coproduct without a semi-colon" do
    input = "&Coproduct"
    output = [["Character", "&Coproduct"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: CounterClockwiseContourIntegral without a semi-colon" do
    input = "&CounterClockwiseContourIntegral"
    output = [["Character", "&CounterClockwiseContourIntegral"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Cross without a semi-colon" do
    input = "&Cross"
    output = [["Character", "&Cross"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Cscr without a semi-colon" do
    input = "&Cscr"
    output = [["Character", "&Cscr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Cup without a semi-colon" do
    input = "&Cup"
    output = [["Character", "&Cup"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: CupCap without a semi-colon" do
    input = "&CupCap"
    output = [["Character", "&CupCap"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: DD without a semi-colon" do
    input = "&DD"
    output = [["Character", "&DD"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: DDotrahd without a semi-colon" do
    input = "&DDotrahd"
    output = [["Character", "&DDotrahd"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: DJcy without a semi-colon" do
    input = "&DJcy"
    output = [["Character", "&DJcy"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: DScy without a semi-colon" do
    input = "&DScy"
    output = [["Character", "&DScy"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: DZcy without a semi-colon" do
    input = "&DZcy"
    output = [["Character", "&DZcy"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Dagger without a semi-colon" do
    input = "&Dagger"
    output = [["Character", "&Dagger"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Darr without a semi-colon" do
    input = "&Darr"
    output = [["Character", "&Darr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Dashv without a semi-colon" do
    input = "&Dashv"
    output = [["Character", "&Dashv"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Dcaron without a semi-colon" do
    input = "&Dcaron"
    output = [["Character", "&Dcaron"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Dcy without a semi-colon" do
    input = "&Dcy"
    output = [["Character", "&Dcy"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Del without a semi-colon" do
    input = "&Del"
    output = [["Character", "&Del"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Delta without a semi-colon" do
    input = "&Delta"
    output = [["Character", "&Delta"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Dfr without a semi-colon" do
    input = "&Dfr"
    output = [["Character", "&Dfr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: DiacriticalAcute without a semi-colon" do
    input = "&DiacriticalAcute"
    output = [["Character", "&DiacriticalAcute"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: DiacriticalDot without a semi-colon" do
    input = "&DiacriticalDot"
    output = [["Character", "&DiacriticalDot"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: DiacriticalDoubleAcute without a semi-colon" do
    input = "&DiacriticalDoubleAcute"
    output = [["Character", "&DiacriticalDoubleAcute"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: DiacriticalGrave without a semi-colon" do
    input = "&DiacriticalGrave"
    output = [["Character", "&DiacriticalGrave"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: DiacriticalTilde without a semi-colon" do
    input = "&DiacriticalTilde"
    output = [["Character", "&DiacriticalTilde"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Diamond without a semi-colon" do
    input = "&Diamond"
    output = [["Character", "&Diamond"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: DifferentialD without a semi-colon" do
    input = "&DifferentialD"
    output = [["Character", "&DifferentialD"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Dopf without a semi-colon" do
    input = "&Dopf"
    output = [["Character", "&Dopf"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Dot without a semi-colon" do
    input = "&Dot"
    output = [["Character", "&Dot"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: DotDot without a semi-colon" do
    input = "&DotDot"
    output = [["Character", "&DotDot"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: DotEqual without a semi-colon" do
    input = "&DotEqual"
    output = [["Character", "&DotEqual"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: DoubleContourIntegral without a semi-colon" do
    input = "&DoubleContourIntegral"
    output = [["Character", "&DoubleContourIntegral"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: DoubleDot without a semi-colon" do
    input = "&DoubleDot"
    output = [["Character", "&DoubleDot"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: DoubleDownArrow without a semi-colon" do
    input = "&DoubleDownArrow"
    output = [["Character", "&DoubleDownArrow"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: DoubleLeftArrow without a semi-colon" do
    input = "&DoubleLeftArrow"
    output = [["Character", "&DoubleLeftArrow"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: DoubleLeftRightArrow without a semi-colon" do
    input = "&DoubleLeftRightArrow"
    output = [["Character", "&DoubleLeftRightArrow"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: DoubleLeftTee without a semi-colon" do
    input = "&DoubleLeftTee"
    output = [["Character", "&DoubleLeftTee"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: DoubleLongLeftArrow without a semi-colon" do
    input = "&DoubleLongLeftArrow"
    output = [["Character", "&DoubleLongLeftArrow"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: DoubleLongLeftRightArrow without a semi-colon" do
    input = "&DoubleLongLeftRightArrow"
    output = [["Character", "&DoubleLongLeftRightArrow"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: DoubleLongRightArrow without a semi-colon" do
    input = "&DoubleLongRightArrow"
    output = [["Character", "&DoubleLongRightArrow"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: DoubleRightArrow without a semi-colon" do
    input = "&DoubleRightArrow"
    output = [["Character", "&DoubleRightArrow"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: DoubleRightTee without a semi-colon" do
    input = "&DoubleRightTee"
    output = [["Character", "&DoubleRightTee"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: DoubleUpArrow without a semi-colon" do
    input = "&DoubleUpArrow"
    output = [["Character", "&DoubleUpArrow"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: DoubleUpDownArrow without a semi-colon" do
    input = "&DoubleUpDownArrow"
    output = [["Character", "&DoubleUpDownArrow"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: DoubleVerticalBar without a semi-colon" do
    input = "&DoubleVerticalBar"
    output = [["Character", "&DoubleVerticalBar"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: DownArrow without a semi-colon" do
    input = "&DownArrow"
    output = [["Character", "&DownArrow"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: DownArrowBar without a semi-colon" do
    input = "&DownArrowBar"
    output = [["Character", "&DownArrowBar"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: DownArrowUpArrow without a semi-colon" do
    input = "&DownArrowUpArrow"
    output = [["Character", "&DownArrowUpArrow"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: DownBreve without a semi-colon" do
    input = "&DownBreve"
    output = [["Character", "&DownBreve"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: DownLeftRightVector without a semi-colon" do
    input = "&DownLeftRightVector"
    output = [["Character", "&DownLeftRightVector"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: DownLeftTeeVector without a semi-colon" do
    input = "&DownLeftTeeVector"
    output = [["Character", "&DownLeftTeeVector"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: DownLeftVector without a semi-colon" do
    input = "&DownLeftVector"
    output = [["Character", "&DownLeftVector"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end
end