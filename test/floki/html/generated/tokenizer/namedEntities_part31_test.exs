defmodule Floki.HTML.Generated.Tokenizer.NamedentitiesPart31Test do
  use ExUnit.Case, async: true

  # NOTE: This file was generated by "mix generate_tokenizer_tests namedEntities.test".
  # html5lib-tests rev: e52ff68cc7113a6ef3687747fa82691079bf9cc5

  alias Floki.HTML.Tokenizer

  test "tokenize/1 Named entity: eparsl; with a semi-colon" do
    input = "&eparsl;"
    output = [["Character", "⧣"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: eplus; with a semi-colon" do
    input = "&eplus;"
    output = [["Character", "⩱"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: epsi; with a semi-colon" do
    input = "&epsi;"
    output = [["Character", "ε"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: epsilon; with a semi-colon" do
    input = "&epsilon;"
    output = [["Character", "ε"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: epsiv; with a semi-colon" do
    input = "&epsiv;"
    output = [["Character", "ϵ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: eqcirc; with a semi-colon" do
    input = "&eqcirc;"
    output = [["Character", "≖"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: eqcolon; with a semi-colon" do
    input = "&eqcolon;"
    output = [["Character", "≕"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: eqsim; with a semi-colon" do
    input = "&eqsim;"
    output = [["Character", "≂"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: eqslantgtr; with a semi-colon" do
    input = "&eqslantgtr;"
    output = [["Character", "⪖"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: eqslantless; with a semi-colon" do
    input = "&eqslantless;"
    output = [["Character", "⪕"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: equals; with a semi-colon" do
    input = "&equals;"
    output = [["Character", "="]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: equest; with a semi-colon" do
    input = "&equest;"
    output = [["Character", "≟"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: equiv; with a semi-colon" do
    input = "&equiv;"
    output = [["Character", "≡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: equivDD; with a semi-colon" do
    input = "&equivDD;"
    output = [["Character", "⩸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: eqvparsl; with a semi-colon" do
    input = "&eqvparsl;"
    output = [["Character", "⧥"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: erDot; with a semi-colon" do
    input = "&erDot;"
    output = [["Character", "≓"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: erarr; with a semi-colon" do
    input = "&erarr;"
    output = [["Character", "⥱"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: escr; with a semi-colon" do
    input = "&escr;"
    output = [["Character", "ℯ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: esdot; with a semi-colon" do
    input = "&esdot;"
    output = [["Character", "≐"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: esim; with a semi-colon" do
    input = "&esim;"
    output = [["Character", "≂"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: eta; with a semi-colon" do
    input = "&eta;"
    output = [["Character", "η"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: eth without a semi-colon" do
    input = "&eth"
    output = [["Character", "ð"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: eth; with a semi-colon" do
    input = "&eth;"
    output = [["Character", "ð"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: euml without a semi-colon" do
    input = "&euml"
    output = [["Character", "ë"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: euml; with a semi-colon" do
    input = "&euml;"
    output = [["Character", "ë"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: euro; with a semi-colon" do
    input = "&euro;"
    output = [["Character", "€"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: excl; with a semi-colon" do
    input = "&excl;"
    output = [["Character", "!"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: exist; with a semi-colon" do
    input = "&exist;"
    output = [["Character", "∃"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: expectation; with a semi-colon" do
    input = "&expectation;"
    output = [["Character", "ℰ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: exponentiale; with a semi-colon" do
    input = "&exponentiale;"
    output = [["Character", "ⅇ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: fallingdotseq; with a semi-colon" do
    input = "&fallingdotseq;"
    output = [["Character", "≒"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: fcy; with a semi-colon" do
    input = "&fcy;"
    output = [["Character", "ф"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: female; with a semi-colon" do
    input = "&female;"
    output = [["Character", "♀"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ffilig; with a semi-colon" do
    input = "&ffilig;"
    output = [["Character", "ﬃ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: fflig; with a semi-colon" do
    input = "&fflig;"
    output = [["Character", "ﬀ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ffllig; with a semi-colon" do
    input = "&ffllig;"
    output = [["Character", "ﬄ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ffr; with a semi-colon" do
    input = "&ffr;"
    output = [["Character", "𝔣"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: filig; with a semi-colon" do
    input = "&filig;"
    output = [["Character", "ﬁ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: fjlig; with a semi-colon" do
    input = "&fjlig;"
    output = [["Character", "fj"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: flat; with a semi-colon" do
    input = "&flat;"
    output = [["Character", "♭"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: fllig; with a semi-colon" do
    input = "&fllig;"
    output = [["Character", "ﬂ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: fltns; with a semi-colon" do
    input = "&fltns;"
    output = [["Character", "▱"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: fnof; with a semi-colon" do
    input = "&fnof;"
    output = [["Character", "ƒ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: fopf; with a semi-colon" do
    input = "&fopf;"
    output = [["Character", "𝕗"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: forall; with a semi-colon" do
    input = "&forall;"
    output = [["Character", "∀"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: fork; with a semi-colon" do
    input = "&fork;"
    output = [["Character", "⋔"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: forkv; with a semi-colon" do
    input = "&forkv;"
    output = [["Character", "⫙"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: fpartint; with a semi-colon" do
    input = "&fpartint;"
    output = [["Character", "⨍"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: frac12 without a semi-colon" do
    input = "&frac12"
    output = [["Character", "½"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: frac12; with a semi-colon" do
    input = "&frac12;"
    output = [["Character", "½"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: frac13; with a semi-colon" do
    input = "&frac13;"
    output = [["Character", "⅓"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: frac14 without a semi-colon" do
    input = "&frac14"
    output = [["Character", "¼"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: frac14; with a semi-colon" do
    input = "&frac14;"
    output = [["Character", "¼"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: frac15; with a semi-colon" do
    input = "&frac15;"
    output = [["Character", "⅕"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: frac16; with a semi-colon" do
    input = "&frac16;"
    output = [["Character", "⅙"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: frac18; with a semi-colon" do
    input = "&frac18;"
    output = [["Character", "⅛"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: frac23; with a semi-colon" do
    input = "&frac23;"
    output = [["Character", "⅔"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: frac25; with a semi-colon" do
    input = "&frac25;"
    output = [["Character", "⅖"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: frac34 without a semi-colon" do
    input = "&frac34"
    output = [["Character", "¾"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: frac34; with a semi-colon" do
    input = "&frac34;"
    output = [["Character", "¾"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: frac35; with a semi-colon" do
    input = "&frac35;"
    output = [["Character", "⅗"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: frac38; with a semi-colon" do
    input = "&frac38;"
    output = [["Character", "⅜"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: frac45; with a semi-colon" do
    input = "&frac45;"
    output = [["Character", "⅘"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: frac56; with a semi-colon" do
    input = "&frac56;"
    output = [["Character", "⅚"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: frac58; with a semi-colon" do
    input = "&frac58;"
    output = [["Character", "⅝"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: frac78; with a semi-colon" do
    input = "&frac78;"
    output = [["Character", "⅞"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: frasl; with a semi-colon" do
    input = "&frasl;"
    output = [["Character", "⁄"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: frown; with a semi-colon" do
    input = "&frown;"
    output = [["Character", "⌢"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: fscr; with a semi-colon" do
    input = "&fscr;"
    output = [["Character", "𝒻"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gE; with a semi-colon" do
    input = "&gE;"
    output = [["Character", "≧"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gEl; with a semi-colon" do
    input = "&gEl;"
    output = [["Character", "⪌"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gacute; with a semi-colon" do
    input = "&gacute;"
    output = [["Character", "ǵ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gamma; with a semi-colon" do
    input = "&gamma;"
    output = [["Character", "γ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gammad; with a semi-colon" do
    input = "&gammad;"
    output = [["Character", "ϝ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gap; with a semi-colon" do
    input = "&gap;"
    output = [["Character", "⪆"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gbreve; with a semi-colon" do
    input = "&gbreve;"
    output = [["Character", "ğ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gcirc; with a semi-colon" do
    input = "&gcirc;"
    output = [["Character", "ĝ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gcy; with a semi-colon" do
    input = "&gcy;"
    output = [["Character", "г"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gdot; with a semi-colon" do
    input = "&gdot;"
    output = [["Character", "ġ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ge; with a semi-colon" do
    input = "&ge;"
    output = [["Character", "≥"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gel; with a semi-colon" do
    input = "&gel;"
    output = [["Character", "⋛"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: geq; with a semi-colon" do
    input = "&geq;"
    output = [["Character", "≥"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: geqq; with a semi-colon" do
    input = "&geqq;"
    output = [["Character", "≧"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: geqslant; with a semi-colon" do
    input = "&geqslant;"
    output = [["Character", "⩾"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ges; with a semi-colon" do
    input = "&ges;"
    output = [["Character", "⩾"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gescc; with a semi-colon" do
    input = "&gescc;"
    output = [["Character", "⪩"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gesdot; with a semi-colon" do
    input = "&gesdot;"
    output = [["Character", "⪀"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gesdoto; with a semi-colon" do
    input = "&gesdoto;"
    output = [["Character", "⪂"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gesdotol; with a semi-colon" do
    input = "&gesdotol;"
    output = [["Character", "⪄"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gesl; with a semi-colon" do
    input = "&gesl;"
    output = [["Character", "⋛︀"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gesles; with a semi-colon" do
    input = "&gesles;"
    output = [["Character", "⪔"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gfr; with a semi-colon" do
    input = "&gfr;"
    output = [["Character", "𝔤"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gg; with a semi-colon" do
    input = "&gg;"
    output = [["Character", "≫"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ggg; with a semi-colon" do
    input = "&ggg;"
    output = [["Character", "⋙"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gimel; with a semi-colon" do
    input = "&gimel;"
    output = [["Character", "ℷ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gjcy; with a semi-colon" do
    input = "&gjcy;"
    output = [["Character", "ѓ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gl; with a semi-colon" do
    input = "&gl;"
    output = [["Character", "≷"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: glE; with a semi-colon" do
    input = "&glE;"
    output = [["Character", "⪒"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: gla; with a semi-colon" do
    input = "&gla;"
    output = [["Character", "⪥"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: glj; with a semi-colon" do
    input = "&glj;"
    output = [["Character", "⪤"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end
end
