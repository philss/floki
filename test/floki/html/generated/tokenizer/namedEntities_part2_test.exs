defmodule Floki.HTML.Generated.Tokenizer.NamedentitiesPart2Test do
  use ExUnit.Case, async: true

  # NOTE: This file was generated by "mix generate_tokenizer_tests namedEntities.test".
  # html5lib-tests rev: e52ff68cc7113a6ef3687747fa82691079bf9cc5

  alias Floki.HTML.Tokenizer

  test "tokenize/1 Bad named entity: DownLeftVectorBar without a semi-colon" do
    input = "&DownLeftVectorBar"
    output = [["Character", "&DownLeftVectorBar"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: DownRightTeeVector without a semi-colon" do
    input = "&DownRightTeeVector"
    output = [["Character", "&DownRightTeeVector"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: DownRightVector without a semi-colon" do
    input = "&DownRightVector"
    output = [["Character", "&DownRightVector"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: DownRightVectorBar without a semi-colon" do
    input = "&DownRightVectorBar"
    output = [["Character", "&DownRightVectorBar"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: DownTee without a semi-colon" do
    input = "&DownTee"
    output = [["Character", "&DownTee"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: DownTeeArrow without a semi-colon" do
    input = "&DownTeeArrow"
    output = [["Character", "&DownTeeArrow"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Downarrow without a semi-colon" do
    input = "&Downarrow"
    output = [["Character", "&Downarrow"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Dscr without a semi-colon" do
    input = "&Dscr"
    output = [["Character", "&Dscr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Dstrok without a semi-colon" do
    input = "&Dstrok"
    output = [["Character", "&Dstrok"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: ENG without a semi-colon" do
    input = "&ENG"
    output = [["Character", "&ENG"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Ecaron without a semi-colon" do
    input = "&Ecaron"
    output = [["Character", "&Ecaron"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Ecy without a semi-colon" do
    input = "&Ecy"
    output = [["Character", "&Ecy"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Edot without a semi-colon" do
    input = "&Edot"
    output = [["Character", "&Edot"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Efr without a semi-colon" do
    input = "&Efr"
    output = [["Character", "&Efr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Element without a semi-colon" do
    input = "&Element"
    output = [["Character", "&Element"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Emacr without a semi-colon" do
    input = "&Emacr"
    output = [["Character", "&Emacr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: EmptySmallSquare without a semi-colon" do
    input = "&EmptySmallSquare"
    output = [["Character", "&EmptySmallSquare"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: EmptyVerySmallSquare without a semi-colon" do
    input = "&EmptyVerySmallSquare"
    output = [["Character", "&EmptyVerySmallSquare"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Eogon without a semi-colon" do
    input = "&Eogon"
    output = [["Character", "&Eogon"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Eopf without a semi-colon" do
    input = "&Eopf"
    output = [["Character", "&Eopf"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Epsilon without a semi-colon" do
    input = "&Epsilon"
    output = [["Character", "&Epsilon"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Equal without a semi-colon" do
    input = "&Equal"
    output = [["Character", "&Equal"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: EqualTilde without a semi-colon" do
    input = "&EqualTilde"
    output = [["Character", "&EqualTilde"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Equilibrium without a semi-colon" do
    input = "&Equilibrium"
    output = [["Character", "&Equilibrium"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Escr without a semi-colon" do
    input = "&Escr"
    output = [["Character", "&Escr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Esim without a semi-colon" do
    input = "&Esim"
    output = [["Character", "&Esim"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Eta without a semi-colon" do
    input = "&Eta"
    output = [["Character", "&Eta"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Exists without a semi-colon" do
    input = "&Exists"
    output = [["Character", "&Exists"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: ExponentialE without a semi-colon" do
    input = "&ExponentialE"
    output = [["Character", "&ExponentialE"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Fcy without a semi-colon" do
    input = "&Fcy"
    output = [["Character", "&Fcy"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Ffr without a semi-colon" do
    input = "&Ffr"
    output = [["Character", "&Ffr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: FilledSmallSquare without a semi-colon" do
    input = "&FilledSmallSquare"
    output = [["Character", "&FilledSmallSquare"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: FilledVerySmallSquare without a semi-colon" do
    input = "&FilledVerySmallSquare"
    output = [["Character", "&FilledVerySmallSquare"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Fopf without a semi-colon" do
    input = "&Fopf"
    output = [["Character", "&Fopf"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: ForAll without a semi-colon" do
    input = "&ForAll"
    output = [["Character", "&ForAll"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Fouriertrf without a semi-colon" do
    input = "&Fouriertrf"
    output = [["Character", "&Fouriertrf"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Fscr without a semi-colon" do
    input = "&Fscr"
    output = [["Character", "&Fscr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: GJcy without a semi-colon" do
    input = "&GJcy"
    output = [["Character", "&GJcy"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Gamma without a semi-colon" do
    input = "&Gamma"
    output = [["Character", "&Gamma"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Gammad without a semi-colon" do
    input = "&Gammad"
    output = [["Character", "&Gammad"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Gbreve without a semi-colon" do
    input = "&Gbreve"
    output = [["Character", "&Gbreve"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Gcedil without a semi-colon" do
    input = "&Gcedil"
    output = [["Character", "&Gcedil"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Gcirc without a semi-colon" do
    input = "&Gcirc"
    output = [["Character", "&Gcirc"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Gcy without a semi-colon" do
    input = "&Gcy"
    output = [["Character", "&Gcy"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Gdot without a semi-colon" do
    input = "&Gdot"
    output = [["Character", "&Gdot"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Gfr without a semi-colon" do
    input = "&Gfr"
    output = [["Character", "&Gfr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Gg without a semi-colon" do
    input = "&Gg"
    output = [["Character", "&Gg"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Gopf without a semi-colon" do
    input = "&Gopf"
    output = [["Character", "&Gopf"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: GreaterEqual without a semi-colon" do
    input = "&GreaterEqual"
    output = [["Character", "&GreaterEqual"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: GreaterEqualLess without a semi-colon" do
    input = "&GreaterEqualLess"
    output = [["Character", "&GreaterEqualLess"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: GreaterFullEqual without a semi-colon" do
    input = "&GreaterFullEqual"
    output = [["Character", "&GreaterFullEqual"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: GreaterGreater without a semi-colon" do
    input = "&GreaterGreater"
    output = [["Character", "&GreaterGreater"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: GreaterLess without a semi-colon" do
    input = "&GreaterLess"
    output = [["Character", "&GreaterLess"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: GreaterSlantEqual without a semi-colon" do
    input = "&GreaterSlantEqual"
    output = [["Character", "&GreaterSlantEqual"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: GreaterTilde without a semi-colon" do
    input = "&GreaterTilde"
    output = [["Character", "&GreaterTilde"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Gscr without a semi-colon" do
    input = "&Gscr"
    output = [["Character", "&Gscr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Gt without a semi-colon" do
    input = "&Gt"
    output = [["Character", "&Gt"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: HARDcy without a semi-colon" do
    input = "&HARDcy"
    output = [["Character", "&HARDcy"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Hacek without a semi-colon" do
    input = "&Hacek"
    output = [["Character", "&Hacek"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Hat without a semi-colon" do
    input = "&Hat"
    output = [["Character", "&Hat"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Hcirc without a semi-colon" do
    input = "&Hcirc"
    output = [["Character", "&Hcirc"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Hfr without a semi-colon" do
    input = "&Hfr"
    output = [["Character", "&Hfr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: HilbertSpace without a semi-colon" do
    input = "&HilbertSpace"
    output = [["Character", "&HilbertSpace"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Hopf without a semi-colon" do
    input = "&Hopf"
    output = [["Character", "&Hopf"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: HorizontalLine without a semi-colon" do
    input = "&HorizontalLine"
    output = [["Character", "&HorizontalLine"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Hscr without a semi-colon" do
    input = "&Hscr"
    output = [["Character", "&Hscr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Hstrok without a semi-colon" do
    input = "&Hstrok"
    output = [["Character", "&Hstrok"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: HumpDownHump without a semi-colon" do
    input = "&HumpDownHump"
    output = [["Character", "&HumpDownHump"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: HumpEqual without a semi-colon" do
    input = "&HumpEqual"
    output = [["Character", "&HumpEqual"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: IEcy without a semi-colon" do
    input = "&IEcy"
    output = [["Character", "&IEcy"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: IJlig without a semi-colon" do
    input = "&IJlig"
    output = [["Character", "&IJlig"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: IOcy without a semi-colon" do
    input = "&IOcy"
    output = [["Character", "&IOcy"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Icy without a semi-colon" do
    input = "&Icy"
    output = [["Character", "&Icy"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Idot without a semi-colon" do
    input = "&Idot"
    output = [["Character", "&Idot"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Ifr without a semi-colon" do
    input = "&Ifr"
    output = [["Character", "&Ifr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Im without a semi-colon" do
    input = "&Im"
    output = [["Character", "&Im"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Imacr without a semi-colon" do
    input = "&Imacr"
    output = [["Character", "&Imacr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: ImaginaryI without a semi-colon" do
    input = "&ImaginaryI"
    output = [["Character", "&ImaginaryI"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Implies without a semi-colon" do
    input = "&Implies"
    output = [["Character", "&Implies"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Int without a semi-colon" do
    input = "&Int"
    output = [["Character", "&Int"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Integral without a semi-colon" do
    input = "&Integral"
    output = [["Character", "&Integral"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Intersection without a semi-colon" do
    input = "&Intersection"
    output = [["Character", "&Intersection"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: InvisibleComma without a semi-colon" do
    input = "&InvisibleComma"
    output = [["Character", "&InvisibleComma"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: InvisibleTimes without a semi-colon" do
    input = "&InvisibleTimes"
    output = [["Character", "&InvisibleTimes"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Iogon without a semi-colon" do
    input = "&Iogon"
    output = [["Character", "&Iogon"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Iopf without a semi-colon" do
    input = "&Iopf"
    output = [["Character", "&Iopf"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Iota without a semi-colon" do
    input = "&Iota"
    output = [["Character", "&Iota"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Iscr without a semi-colon" do
    input = "&Iscr"
    output = [["Character", "&Iscr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Itilde without a semi-colon" do
    input = "&Itilde"
    output = [["Character", "&Itilde"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Iukcy without a semi-colon" do
    input = "&Iukcy"
    output = [["Character", "&Iukcy"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Jcirc without a semi-colon" do
    input = "&Jcirc"
    output = [["Character", "&Jcirc"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Jcy without a semi-colon" do
    input = "&Jcy"
    output = [["Character", "&Jcy"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Jfr without a semi-colon" do
    input = "&Jfr"
    output = [["Character", "&Jfr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Jopf without a semi-colon" do
    input = "&Jopf"
    output = [["Character", "&Jopf"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Jscr without a semi-colon" do
    input = "&Jscr"
    output = [["Character", "&Jscr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Jsercy without a semi-colon" do
    input = "&Jsercy"
    output = [["Character", "&Jsercy"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Jukcy without a semi-colon" do
    input = "&Jukcy"
    output = [["Character", "&Jukcy"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: KHcy without a semi-colon" do
    input = "&KHcy"
    output = [["Character", "&KHcy"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: KJcy without a semi-colon" do
    input = "&KJcy"
    output = [["Character", "&KJcy"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: Kappa without a semi-colon" do
    input = "&Kappa"
    output = [["Character", "&Kappa"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end
end