defmodule Floki.HTML.Generated.Tokenizer.NamedentitiesPart21Test do
  use ExUnit.Case, async: true

  # NOTE: This file was generated by "mix generate_tokenizer_tests namedEntities.test".
  # html5lib-tests rev: e52ff68cc7113a6ef3687747fa82691079bf9cc5

  alias Floki.HTML.Tokenizer

  test "tokenize/1 Named entity: Ascr; with a semi-colon" do
    input = "&Ascr;"
    output = [["Character", "𝒜"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Assign; with a semi-colon" do
    input = "&Assign;"
    output = [["Character", "≔"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Atilde without a semi-colon" do
    input = "&Atilde"
    output = [["Character", "Ã"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Atilde; with a semi-colon" do
    input = "&Atilde;"
    output = [["Character", "Ã"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Auml without a semi-colon" do
    input = "&Auml"
    output = [["Character", "Ä"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Auml; with a semi-colon" do
    input = "&Auml;"
    output = [["Character", "Ä"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Backslash; with a semi-colon" do
    input = "&Backslash;"
    output = [["Character", "∖"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Barv; with a semi-colon" do
    input = "&Barv;"
    output = [["Character", "⫧"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Barwed; with a semi-colon" do
    input = "&Barwed;"
    output = [["Character", "⌆"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Bcy; with a semi-colon" do
    input = "&Bcy;"
    output = [["Character", "Б"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Because; with a semi-colon" do
    input = "&Because;"
    output = [["Character", "∵"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Bernoullis; with a semi-colon" do
    input = "&Bernoullis;"
    output = [["Character", "ℬ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Beta; with a semi-colon" do
    input = "&Beta;"
    output = [["Character", "Β"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Bfr; with a semi-colon" do
    input = "&Bfr;"
    output = [["Character", "𝔅"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Bopf; with a semi-colon" do
    input = "&Bopf;"
    output = [["Character", "𝔹"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Breve; with a semi-colon" do
    input = "&Breve;"
    output = [["Character", "˘"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Bscr; with a semi-colon" do
    input = "&Bscr;"
    output = [["Character", "ℬ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Bumpeq; with a semi-colon" do
    input = "&Bumpeq;"
    output = [["Character", "≎"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: CHcy; with a semi-colon" do
    input = "&CHcy;"
    output = [["Character", "Ч"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: COPY without a semi-colon" do
    input = "&COPY"
    output = [["Character", "©"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: COPY; with a semi-colon" do
    input = "&COPY;"
    output = [["Character", "©"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Cacute; with a semi-colon" do
    input = "&Cacute;"
    output = [["Character", "Ć"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Cap; with a semi-colon" do
    input = "&Cap;"
    output = [["Character", "⋒"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: CapitalDifferentialD; with a semi-colon" do
    input = "&CapitalDifferentialD;"
    output = [["Character", "ⅅ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Cayleys; with a semi-colon" do
    input = "&Cayleys;"
    output = [["Character", "ℭ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ccaron; with a semi-colon" do
    input = "&Ccaron;"
    output = [["Character", "Č"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ccedil without a semi-colon" do
    input = "&Ccedil"
    output = [["Character", "Ç"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ccedil; with a semi-colon" do
    input = "&Ccedil;"
    output = [["Character", "Ç"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ccirc; with a semi-colon" do
    input = "&Ccirc;"
    output = [["Character", "Ĉ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Cconint; with a semi-colon" do
    input = "&Cconint;"
    output = [["Character", "∰"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Cdot; with a semi-colon" do
    input = "&Cdot;"
    output = [["Character", "Ċ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Cedilla; with a semi-colon" do
    input = "&Cedilla;"
    output = [["Character", "¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: CenterDot; with a semi-colon" do
    input = "&CenterDot;"
    output = [["Character", "·"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Cfr; with a semi-colon" do
    input = "&Cfr;"
    output = [["Character", "ℭ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Chi; with a semi-colon" do
    input = "&Chi;"
    output = [["Character", "Χ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: CircleDot; with a semi-colon" do
    input = "&CircleDot;"
    output = [["Character", "⊙"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: CircleMinus; with a semi-colon" do
    input = "&CircleMinus;"
    output = [["Character", "⊖"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: CirclePlus; with a semi-colon" do
    input = "&CirclePlus;"
    output = [["Character", "⊕"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: CircleTimes; with a semi-colon" do
    input = "&CircleTimes;"
    output = [["Character", "⊗"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ClockwiseContourIntegral; with a semi-colon" do
    input = "&ClockwiseContourIntegral;"
    output = [["Character", "∲"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: CloseCurlyDoubleQuote; with a semi-colon" do
    input = "&CloseCurlyDoubleQuote;"
    output = [["Character", "”"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: CloseCurlyQuote; with a semi-colon" do
    input = "&CloseCurlyQuote;"
    output = [["Character", "’"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Colon; with a semi-colon" do
    input = "&Colon;"
    output = [["Character", "∷"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Colone; with a semi-colon" do
    input = "&Colone;"
    output = [["Character", "⩴"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Congruent; with a semi-colon" do
    input = "&Congruent;"
    output = [["Character", "≡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Conint; with a semi-colon" do
    input = "&Conint;"
    output = [["Character", "∯"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ContourIntegral; with a semi-colon" do
    input = "&ContourIntegral;"
    output = [["Character", "∮"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Copf; with a semi-colon" do
    input = "&Copf;"
    output = [["Character", "ℂ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Coproduct; with a semi-colon" do
    input = "&Coproduct;"
    output = [["Character", "∐"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: CounterClockwiseContourIntegral; with a semi-colon" do
    input = "&CounterClockwiseContourIntegral;"
    output = [["Character", "∳"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Cross; with a semi-colon" do
    input = "&Cross;"
    output = [["Character", "⨯"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Cscr; with a semi-colon" do
    input = "&Cscr;"
    output = [["Character", "𝒞"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Cup; with a semi-colon" do
    input = "&Cup;"
    output = [["Character", "⋓"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: CupCap; with a semi-colon" do
    input = "&CupCap;"
    output = [["Character", "≍"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: DD; with a semi-colon" do
    input = "&DD;"
    output = [["Character", "ⅅ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: DDotrahd; with a semi-colon" do
    input = "&DDotrahd;"
    output = [["Character", "⤑"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: DJcy; with a semi-colon" do
    input = "&DJcy;"
    output = [["Character", "Ђ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: DScy; with a semi-colon" do
    input = "&DScy;"
    output = [["Character", "Ѕ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: DZcy; with a semi-colon" do
    input = "&DZcy;"
    output = [["Character", "Џ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Dagger; with a semi-colon" do
    input = "&Dagger;"
    output = [["Character", "‡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Darr; with a semi-colon" do
    input = "&Darr;"
    output = [["Character", "↡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Dashv; with a semi-colon" do
    input = "&Dashv;"
    output = [["Character", "⫤"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Dcaron; with a semi-colon" do
    input = "&Dcaron;"
    output = [["Character", "Ď"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Dcy; with a semi-colon" do
    input = "&Dcy;"
    output = [["Character", "Д"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Del; with a semi-colon" do
    input = "&Del;"
    output = [["Character", "∇"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Delta; with a semi-colon" do
    input = "&Delta;"
    output = [["Character", "Δ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Dfr; with a semi-colon" do
    input = "&Dfr;"
    output = [["Character", "𝔇"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: DiacriticalAcute; with a semi-colon" do
    input = "&DiacriticalAcute;"
    output = [["Character", "´"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: DiacriticalDot; with a semi-colon" do
    input = "&DiacriticalDot;"
    output = [["Character", "˙"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: DiacriticalDoubleAcute; with a semi-colon" do
    input = "&DiacriticalDoubleAcute;"
    output = [["Character", "˝"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: DiacriticalGrave; with a semi-colon" do
    input = "&DiacriticalGrave;"
    output = [["Character", "`"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: DiacriticalTilde; with a semi-colon" do
    input = "&DiacriticalTilde;"
    output = [["Character", "˜"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Diamond; with a semi-colon" do
    input = "&Diamond;"
    output = [["Character", "⋄"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: DifferentialD; with a semi-colon" do
    input = "&DifferentialD;"
    output = [["Character", "ⅆ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Dopf; with a semi-colon" do
    input = "&Dopf;"
    output = [["Character", "𝔻"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Dot; with a semi-colon" do
    input = "&Dot;"
    output = [["Character", "¨"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: DotDot; with a semi-colon" do
    input = "&DotDot;"
    output = [["Character", "⃜"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: DotEqual; with a semi-colon" do
    input = "&DotEqual;"
    output = [["Character", "≐"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: DoubleContourIntegral; with a semi-colon" do
    input = "&DoubleContourIntegral;"
    output = [["Character", "∯"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: DoubleDot; with a semi-colon" do
    input = "&DoubleDot;"
    output = [["Character", "¨"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: DoubleDownArrow; with a semi-colon" do
    input = "&DoubleDownArrow;"
    output = [["Character", "⇓"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: DoubleLeftArrow; with a semi-colon" do
    input = "&DoubleLeftArrow;"
    output = [["Character", "⇐"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: DoubleLeftRightArrow; with a semi-colon" do
    input = "&DoubleLeftRightArrow;"
    output = [["Character", "⇔"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: DoubleLeftTee; with a semi-colon" do
    input = "&DoubleLeftTee;"
    output = [["Character", "⫤"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: DoubleLongLeftArrow; with a semi-colon" do
    input = "&DoubleLongLeftArrow;"
    output = [["Character", "⟸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: DoubleLongLeftRightArrow; with a semi-colon" do
    input = "&DoubleLongLeftRightArrow;"
    output = [["Character", "⟺"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: DoubleLongRightArrow; with a semi-colon" do
    input = "&DoubleLongRightArrow;"
    output = [["Character", "⟹"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: DoubleRightArrow; with a semi-colon" do
    input = "&DoubleRightArrow;"
    output = [["Character", "⇒"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: DoubleRightTee; with a semi-colon" do
    input = "&DoubleRightTee;"
    output = [["Character", "⊨"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: DoubleUpArrow; with a semi-colon" do
    input = "&DoubleUpArrow;"
    output = [["Character", "⇑"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: DoubleUpDownArrow; with a semi-colon" do
    input = "&DoubleUpDownArrow;"
    output = [["Character", "⇕"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: DoubleVerticalBar; with a semi-colon" do
    input = "&DoubleVerticalBar;"
    output = [["Character", "∥"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: DownArrow; with a semi-colon" do
    input = "&DownArrow;"
    output = [["Character", "↓"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: DownArrowBar; with a semi-colon" do
    input = "&DownArrowBar;"
    output = [["Character", "⤓"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: DownArrowUpArrow; with a semi-colon" do
    input = "&DownArrowUpArrow;"
    output = [["Character", "⇵"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: DownBreve; with a semi-colon" do
    input = "&DownBreve;"
    output = [["Character", "̑"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: DownLeftRightVector; with a semi-colon" do
    input = "&DownLeftRightVector;"
    output = [["Character", "⥐"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: DownLeftTeeVector; with a semi-colon" do
    input = "&DownLeftTeeVector;"
    output = [["Character", "⥞"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: DownLeftVector; with a semi-colon" do
    input = "&DownLeftVector;"
    output = [["Character", "↽"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: DownLeftVectorBar; with a semi-colon" do
    input = "&DownLeftVectorBar;"
    output = [["Character", "⥖"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end
end