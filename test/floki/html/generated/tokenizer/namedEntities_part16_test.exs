defmodule Floki.HTML.Generated.Tokenizer.NamedentitiesPart16Test do
  use ExUnit.Case, async: true

  # NOTE: This file was generated by "mix generate_tokenizer_tests namedEntities.test".
  # html5lib-tests rev: e52ff68cc7113a6ef3687747fa82691079bf9cc5

  alias Floki.HTML.Tokenizer

  test "tokenize/1 Bad named entity: plustwo without a semi-colon" do
    input = "&plustwo"
    output = [["Character", "&plustwo"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: pm without a semi-colon" do
    input = "&pm"
    output = [["Character", "&pm"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: pointint without a semi-colon" do
    input = "&pointint"
    output = [["Character", "&pointint"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: popf without a semi-colon" do
    input = "&popf"
    output = [["Character", "&popf"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: pr without a semi-colon" do
    input = "&pr"
    output = [["Character", "&pr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: prE without a semi-colon" do
    input = "&prE"
    output = [["Character", "&prE"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: prap without a semi-colon" do
    input = "&prap"
    output = [["Character", "&prap"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: prcue without a semi-colon" do
    input = "&prcue"
    output = [["Character", "&prcue"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: pre without a semi-colon" do
    input = "&pre"
    output = [["Character", "&pre"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: prec without a semi-colon" do
    input = "&prec"
    output = [["Character", "&prec"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: precapprox without a semi-colon" do
    input = "&precapprox"
    output = [["Character", "&precapprox"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: preccurlyeq without a semi-colon" do
    input = "&preccurlyeq"
    output = [["Character", "&preccurlyeq"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: preceq without a semi-colon" do
    input = "&preceq"
    output = [["Character", "&preceq"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: precnapprox without a semi-colon" do
    input = "&precnapprox"
    output = [["Character", "&precnapprox"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: precneqq without a semi-colon" do
    input = "&precneqq"
    output = [["Character", "&precneqq"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: precnsim without a semi-colon" do
    input = "&precnsim"
    output = [["Character", "&precnsim"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: precsim without a semi-colon" do
    input = "&precsim"
    output = [["Character", "&precsim"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: prime without a semi-colon" do
    input = "&prime"
    output = [["Character", "&prime"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: primes without a semi-colon" do
    input = "&primes"
    output = [["Character", "&primes"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: prnE without a semi-colon" do
    input = "&prnE"
    output = [["Character", "&prnE"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: prnap without a semi-colon" do
    input = "&prnap"
    output = [["Character", "&prnap"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: prnsim without a semi-colon" do
    input = "&prnsim"
    output = [["Character", "&prnsim"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: prod without a semi-colon" do
    input = "&prod"
    output = [["Character", "&prod"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: profalar without a semi-colon" do
    input = "&profalar"
    output = [["Character", "&profalar"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: profline without a semi-colon" do
    input = "&profline"
    output = [["Character", "&profline"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: profsurf without a semi-colon" do
    input = "&profsurf"
    output = [["Character", "&profsurf"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: prop without a semi-colon" do
    input = "&prop"
    output = [["Character", "&prop"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: propto without a semi-colon" do
    input = "&propto"
    output = [["Character", "&propto"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: prsim without a semi-colon" do
    input = "&prsim"
    output = [["Character", "&prsim"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: prurel without a semi-colon" do
    input = "&prurel"
    output = [["Character", "&prurel"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: pscr without a semi-colon" do
    input = "&pscr"
    output = [["Character", "&pscr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: psi without a semi-colon" do
    input = "&psi"
    output = [["Character", "&psi"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: puncsp without a semi-colon" do
    input = "&puncsp"
    output = [["Character", "&puncsp"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: qfr without a semi-colon" do
    input = "&qfr"
    output = [["Character", "&qfr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: qint without a semi-colon" do
    input = "&qint"
    output = [["Character", "&qint"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: qopf without a semi-colon" do
    input = "&qopf"
    output = [["Character", "&qopf"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: qprime without a semi-colon" do
    input = "&qprime"
    output = [["Character", "&qprime"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: qscr without a semi-colon" do
    input = "&qscr"
    output = [["Character", "&qscr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: quaternions without a semi-colon" do
    input = "&quaternions"
    output = [["Character", "&quaternions"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: quatint without a semi-colon" do
    input = "&quatint"
    output = [["Character", "&quatint"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: quest without a semi-colon" do
    input = "&quest"
    output = [["Character", "&quest"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: questeq without a semi-colon" do
    input = "&questeq"
    output = [["Character", "&questeq"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rAarr without a semi-colon" do
    input = "&rAarr"
    output = [["Character", "&rAarr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rArr without a semi-colon" do
    input = "&rArr"
    output = [["Character", "&rArr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rAtail without a semi-colon" do
    input = "&rAtail"
    output = [["Character", "&rAtail"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rBarr without a semi-colon" do
    input = "&rBarr"
    output = [["Character", "&rBarr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rHar without a semi-colon" do
    input = "&rHar"
    output = [["Character", "&rHar"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: race without a semi-colon" do
    input = "&race"
    output = [["Character", "&race"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: racute without a semi-colon" do
    input = "&racute"
    output = [["Character", "&racute"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: radic without a semi-colon" do
    input = "&radic"
    output = [["Character", "&radic"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: raemptyv without a semi-colon" do
    input = "&raemptyv"
    output = [["Character", "&raemptyv"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rang without a semi-colon" do
    input = "&rang"
    output = [["Character", "&rang"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rangd without a semi-colon" do
    input = "&rangd"
    output = [["Character", "&rangd"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: range without a semi-colon" do
    input = "&range"
    output = [["Character", "&range"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rangle without a semi-colon" do
    input = "&rangle"
    output = [["Character", "&rangle"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rarr without a semi-colon" do
    input = "&rarr"
    output = [["Character", "&rarr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rarrap without a semi-colon" do
    input = "&rarrap"
    output = [["Character", "&rarrap"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rarrb without a semi-colon" do
    input = "&rarrb"
    output = [["Character", "&rarrb"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rarrbfs without a semi-colon" do
    input = "&rarrbfs"
    output = [["Character", "&rarrbfs"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rarrc without a semi-colon" do
    input = "&rarrc"
    output = [["Character", "&rarrc"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rarrfs without a semi-colon" do
    input = "&rarrfs"
    output = [["Character", "&rarrfs"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rarrhk without a semi-colon" do
    input = "&rarrhk"
    output = [["Character", "&rarrhk"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rarrlp without a semi-colon" do
    input = "&rarrlp"
    output = [["Character", "&rarrlp"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rarrpl without a semi-colon" do
    input = "&rarrpl"
    output = [["Character", "&rarrpl"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rarrsim without a semi-colon" do
    input = "&rarrsim"
    output = [["Character", "&rarrsim"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rarrtl without a semi-colon" do
    input = "&rarrtl"
    output = [["Character", "&rarrtl"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rarrw without a semi-colon" do
    input = "&rarrw"
    output = [["Character", "&rarrw"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: ratail without a semi-colon" do
    input = "&ratail"
    output = [["Character", "&ratail"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: ratio without a semi-colon" do
    input = "&ratio"
    output = [["Character", "&ratio"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rationals without a semi-colon" do
    input = "&rationals"
    output = [["Character", "&rationals"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rbarr without a semi-colon" do
    input = "&rbarr"
    output = [["Character", "&rbarr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rbbrk without a semi-colon" do
    input = "&rbbrk"
    output = [["Character", "&rbbrk"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rbrace without a semi-colon" do
    input = "&rbrace"
    output = [["Character", "&rbrace"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rbrack without a semi-colon" do
    input = "&rbrack"
    output = [["Character", "&rbrack"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rbrke without a semi-colon" do
    input = "&rbrke"
    output = [["Character", "&rbrke"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rbrksld without a semi-colon" do
    input = "&rbrksld"
    output = [["Character", "&rbrksld"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rbrkslu without a semi-colon" do
    input = "&rbrkslu"
    output = [["Character", "&rbrkslu"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rcaron without a semi-colon" do
    input = "&rcaron"
    output = [["Character", "&rcaron"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rcedil without a semi-colon" do
    input = "&rcedil"
    output = [["Character", "&rcedil"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rceil without a semi-colon" do
    input = "&rceil"
    output = [["Character", "&rceil"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rcub without a semi-colon" do
    input = "&rcub"
    output = [["Character", "&rcub"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rcy without a semi-colon" do
    input = "&rcy"
    output = [["Character", "&rcy"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rdca without a semi-colon" do
    input = "&rdca"
    output = [["Character", "&rdca"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rdldhar without a semi-colon" do
    input = "&rdldhar"
    output = [["Character", "&rdldhar"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rdquo without a semi-colon" do
    input = "&rdquo"
    output = [["Character", "&rdquo"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rdquor without a semi-colon" do
    input = "&rdquor"
    output = [["Character", "&rdquor"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rdsh without a semi-colon" do
    input = "&rdsh"
    output = [["Character", "&rdsh"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: real without a semi-colon" do
    input = "&real"
    output = [["Character", "&real"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: realine without a semi-colon" do
    input = "&realine"
    output = [["Character", "&realine"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: realpart without a semi-colon" do
    input = "&realpart"
    output = [["Character", "&realpart"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: reals without a semi-colon" do
    input = "&reals"
    output = [["Character", "&reals"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rect without a semi-colon" do
    input = "&rect"
    output = [["Character", "&rect"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rfisht without a semi-colon" do
    input = "&rfisht"
    output = [["Character", "&rfisht"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rfloor without a semi-colon" do
    input = "&rfloor"
    output = [["Character", "&rfloor"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rfr without a semi-colon" do
    input = "&rfr"
    output = [["Character", "&rfr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rhard without a semi-colon" do
    input = "&rhard"
    output = [["Character", "&rhard"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rharu without a semi-colon" do
    input = "&rharu"
    output = [["Character", "&rharu"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rharul without a semi-colon" do
    input = "&rharul"
    output = [["Character", "&rharul"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rho without a semi-colon" do
    input = "&rho"
    output = [["Character", "&rho"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rhov without a semi-colon" do
    input = "&rhov"
    output = [["Character", "&rhov"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end
end
