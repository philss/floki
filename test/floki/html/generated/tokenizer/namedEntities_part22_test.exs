defmodule Floki.HTML.Generated.Tokenizer.NamedentitiesPart22Test do
  use ExUnit.Case, async: true

  # NOTE: This file was generated by "mix generate_tokenizer_tests namedEntities.test".
  # html5lib-tests rev: e52ff68cc7113a6ef3687747fa82691079bf9cc5

  alias Floki.HTML.Tokenizer

  test "tokenize/1 Named entity: DownRightTeeVector; with a semi-colon" do
    input = "&DownRightTeeVector;"
    output = [["Character", "â¥Ÿ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: DownRightVector; with a semi-colon" do
    input = "&DownRightVector;"
    output = [["Character", "â‡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: DownRightVectorBar; with a semi-colon" do
    input = "&DownRightVectorBar;"
    output = [["Character", "â¥—"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: DownTee; with a semi-colon" do
    input = "&DownTee;"
    output = [["Character", "âŠ¤"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: DownTeeArrow; with a semi-colon" do
    input = "&DownTeeArrow;"
    output = [["Character", "â†§"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Downarrow; with a semi-colon" do
    input = "&Downarrow;"
    output = [["Character", "â‡“"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Dscr; with a semi-colon" do
    input = "&Dscr;"
    output = [["Character", "ð’Ÿ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Dstrok; with a semi-colon" do
    input = "&Dstrok;"
    output = [["Character", "Ä"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ENG; with a semi-colon" do
    input = "&ENG;"
    output = [["Character", "ÅŠ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ETH without a semi-colon" do
    input = "&ETH"
    output = [["Character", "Ã"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ETH; with a semi-colon" do
    input = "&ETH;"
    output = [["Character", "Ã"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Eacute without a semi-colon" do
    input = "&Eacute"
    output = [["Character", "Ã‰"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Eacute; with a semi-colon" do
    input = "&Eacute;"
    output = [["Character", "Ã‰"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ecaron; with a semi-colon" do
    input = "&Ecaron;"
    output = [["Character", "Äš"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ecirc without a semi-colon" do
    input = "&Ecirc"
    output = [["Character", "ÃŠ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ecirc; with a semi-colon" do
    input = "&Ecirc;"
    output = [["Character", "ÃŠ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ecy; with a semi-colon" do
    input = "&Ecy;"
    output = [["Character", "Ð­"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Edot; with a semi-colon" do
    input = "&Edot;"
    output = [["Character", "Ä–"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Efr; with a semi-colon" do
    input = "&Efr;"
    output = [["Character", "ð”ˆ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Egrave without a semi-colon" do
    input = "&Egrave"
    output = [["Character", "Ãˆ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Egrave; with a semi-colon" do
    input = "&Egrave;"
    output = [["Character", "Ãˆ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Element; with a semi-colon" do
    input = "&Element;"
    output = [["Character", "âˆˆ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Emacr; with a semi-colon" do
    input = "&Emacr;"
    output = [["Character", "Ä’"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: EmptySmallSquare; with a semi-colon" do
    input = "&EmptySmallSquare;"
    output = [["Character", "â—»"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: EmptyVerySmallSquare; with a semi-colon" do
    input = "&EmptyVerySmallSquare;"
    output = [["Character", "â–«"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Eogon; with a semi-colon" do
    input = "&Eogon;"
    output = [["Character", "Ä˜"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Eopf; with a semi-colon" do
    input = "&Eopf;"
    output = [["Character", "ð”¼"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Epsilon; with a semi-colon" do
    input = "&Epsilon;"
    output = [["Character", "Î•"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Equal; with a semi-colon" do
    input = "&Equal;"
    output = [["Character", "â©µ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: EqualTilde; with a semi-colon" do
    input = "&EqualTilde;"
    output = [["Character", "â‰‚"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Equilibrium; with a semi-colon" do
    input = "&Equilibrium;"
    output = [["Character", "â‡Œ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Escr; with a semi-colon" do
    input = "&Escr;"
    output = [["Character", "â„°"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Esim; with a semi-colon" do
    input = "&Esim;"
    output = [["Character", "â©³"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Eta; with a semi-colon" do
    input = "&Eta;"
    output = [["Character", "Î—"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Euml without a semi-colon" do
    input = "&Euml"
    output = [["Character", "Ã‹"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Euml; with a semi-colon" do
    input = "&Euml;"
    output = [["Character", "Ã‹"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Exists; with a semi-colon" do
    input = "&Exists;"
    output = [["Character", "âˆƒ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ExponentialE; with a semi-colon" do
    input = "&ExponentialE;"
    output = [["Character", "â…‡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Fcy; with a semi-colon" do
    input = "&Fcy;"
    output = [["Character", "Ð¤"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ffr; with a semi-colon" do
    input = "&Ffr;"
    output = [["Character", "ð”‰"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: FilledSmallSquare; with a semi-colon" do
    input = "&FilledSmallSquare;"
    output = [["Character", "â—¼"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: FilledVerySmallSquare; with a semi-colon" do
    input = "&FilledVerySmallSquare;"
    output = [["Character", "â–ª"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Fopf; with a semi-colon" do
    input = "&Fopf;"
    output = [["Character", "ð”½"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ForAll; with a semi-colon" do
    input = "&ForAll;"
    output = [["Character", "âˆ€"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Fouriertrf; with a semi-colon" do
    input = "&Fouriertrf;"
    output = [["Character", "â„±"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Fscr; with a semi-colon" do
    input = "&Fscr;"
    output = [["Character", "â„±"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: GJcy; with a semi-colon" do
    input = "&GJcy;"
    output = [["Character", "Ðƒ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: GT without a semi-colon" do
    input = "&GT"
    output = [["Character", ">"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: GT; with a semi-colon" do
    input = "&GT;"
    output = [["Character", ">"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Gamma; with a semi-colon" do
    input = "&Gamma;"
    output = [["Character", "Î“"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Gammad; with a semi-colon" do
    input = "&Gammad;"
    output = [["Character", "Ïœ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Gbreve; with a semi-colon" do
    input = "&Gbreve;"
    output = [["Character", "Äž"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Gcedil; with a semi-colon" do
    input = "&Gcedil;"
    output = [["Character", "Ä¢"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Gcirc; with a semi-colon" do
    input = "&Gcirc;"
    output = [["Character", "Äœ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Gcy; with a semi-colon" do
    input = "&Gcy;"
    output = [["Character", "Ð“"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Gdot; with a semi-colon" do
    input = "&Gdot;"
    output = [["Character", "Ä "]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Gfr; with a semi-colon" do
    input = "&Gfr;"
    output = [["Character", "ð”Š"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Gg; with a semi-colon" do
    input = "&Gg;"
    output = [["Character", "â‹™"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Gopf; with a semi-colon" do
    input = "&Gopf;"
    output = [["Character", "ð”¾"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: GreaterEqual; with a semi-colon" do
    input = "&GreaterEqual;"
    output = [["Character", "â‰¥"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: GreaterEqualLess; with a semi-colon" do
    input = "&GreaterEqualLess;"
    output = [["Character", "â‹›"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: GreaterFullEqual; with a semi-colon" do
    input = "&GreaterFullEqual;"
    output = [["Character", "â‰§"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: GreaterGreater; with a semi-colon" do
    input = "&GreaterGreater;"
    output = [["Character", "âª¢"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: GreaterLess; with a semi-colon" do
    input = "&GreaterLess;"
    output = [["Character", "â‰·"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: GreaterSlantEqual; with a semi-colon" do
    input = "&GreaterSlantEqual;"
    output = [["Character", "â©¾"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: GreaterTilde; with a semi-colon" do
    input = "&GreaterTilde;"
    output = [["Character", "â‰³"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Gscr; with a semi-colon" do
    input = "&Gscr;"
    output = [["Character", "ð’¢"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Gt; with a semi-colon" do
    input = "&Gt;"
    output = [["Character", "â‰«"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: HARDcy; with a semi-colon" do
    input = "&HARDcy;"
    output = [["Character", "Ðª"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Hacek; with a semi-colon" do
    input = "&Hacek;"
    output = [["Character", "Ë‡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Hat; with a semi-colon" do
    input = "&Hat;"
    output = [["Character", "^"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Hcirc; with a semi-colon" do
    input = "&Hcirc;"
    output = [["Character", "Ä¤"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Hfr; with a semi-colon" do
    input = "&Hfr;"
    output = [["Character", "â„Œ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: HilbertSpace; with a semi-colon" do
    input = "&HilbertSpace;"
    output = [["Character", "â„‹"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Hopf; with a semi-colon" do
    input = "&Hopf;"
    output = [["Character", "â„"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: HorizontalLine; with a semi-colon" do
    input = "&HorizontalLine;"
    output = [["Character", "â”€"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Hscr; with a semi-colon" do
    input = "&Hscr;"
    output = [["Character", "â„‹"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Hstrok; with a semi-colon" do
    input = "&Hstrok;"
    output = [["Character", "Ä¦"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: HumpDownHump; with a semi-colon" do
    input = "&HumpDownHump;"
    output = [["Character", "â‰Ž"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: HumpEqual; with a semi-colon" do
    input = "&HumpEqual;"
    output = [["Character", "â‰"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: IEcy; with a semi-colon" do
    input = "&IEcy;"
    output = [["Character", "Ð•"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: IJlig; with a semi-colon" do
    input = "&IJlig;"
    output = [["Character", "Ä²"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: IOcy; with a semi-colon" do
    input = "&IOcy;"
    output = [["Character", "Ð"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Iacute without a semi-colon" do
    input = "&Iacute"
    output = [["Character", "Ã"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Iacute; with a semi-colon" do
    input = "&Iacute;"
    output = [["Character", "Ã"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Icirc without a semi-colon" do
    input = "&Icirc"
    output = [["Character", "ÃŽ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Icirc; with a semi-colon" do
    input = "&Icirc;"
    output = [["Character", "ÃŽ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Icy; with a semi-colon" do
    input = "&Icy;"
    output = [["Character", "Ð˜"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Idot; with a semi-colon" do
    input = "&Idot;"
    output = [["Character", "Ä°"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ifr; with a semi-colon" do
    input = "&Ifr;"
    output = [["Character", "â„‘"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Igrave without a semi-colon" do
    input = "&Igrave"
    output = [["Character", "ÃŒ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Igrave; with a semi-colon" do
    input = "&Igrave;"
    output = [["Character", "ÃŒ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Im; with a semi-colon" do
    input = "&Im;"
    output = [["Character", "â„‘"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Imacr; with a semi-colon" do
    input = "&Imacr;"
    output = [["Character", "Äª"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ImaginaryI; with a semi-colon" do
    input = "&ImaginaryI;"
    output = [["Character", "â…ˆ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Implies; with a semi-colon" do
    input = "&Implies;"
    output = [["Character", "â‡’"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Int; with a semi-colon" do
    input = "&Int;"
    output = [["Character", "âˆ¬"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Integral; with a semi-colon" do
    input = "&Integral;"
    output = [["Character", "âˆ«"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Intersection; with a semi-colon" do
    input = "&Intersection;"
    output = [["Character", "â‹‚"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: InvisibleComma; with a semi-colon" do
    input = "&InvisibleComma;"
    output = [["Character", "â£"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end
end
