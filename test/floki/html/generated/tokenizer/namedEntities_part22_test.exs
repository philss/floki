defmodule Floki.HTML.Generated.Tokenizer.NamedentitiesPart22Test do
  use ExUnit.Case, async: true

  # NOTE: This file was generated by "mix generate_tokenizer_tests namedEntities.test".
  # html5lib-tests rev: e52ff68cc7113a6ef3687747fa82691079bf9cc5

  alias Floki.HTML.Tokenizer

  test "tokenize/1 Named entity: DownRightTeeVector; with a semi-colon" do
    input = "&DownRightTeeVector;"
    output = [["Character", "⥟"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: DownRightVector; with a semi-colon" do
    input = "&DownRightVector;"
    output = [["Character", "⇁"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: DownRightVectorBar; with a semi-colon" do
    input = "&DownRightVectorBar;"
    output = [["Character", "⥗"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: DownTee; with a semi-colon" do
    input = "&DownTee;"
    output = [["Character", "⊤"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: DownTeeArrow; with a semi-colon" do
    input = "&DownTeeArrow;"
    output = [["Character", "↧"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Downarrow; with a semi-colon" do
    input = "&Downarrow;"
    output = [["Character", "⇓"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Dscr; with a semi-colon" do
    input = "&Dscr;"
    output = [["Character", "𝒟"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Dstrok; with a semi-colon" do
    input = "&Dstrok;"
    output = [["Character", "Đ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ENG; with a semi-colon" do
    input = "&ENG;"
    output = [["Character", "Ŋ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ETH without a semi-colon" do
    input = "&ETH"
    output = [["Character", "Ð"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ETH; with a semi-colon" do
    input = "&ETH;"
    output = [["Character", "Ð"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Eacute without a semi-colon" do
    input = "&Eacute"
    output = [["Character", "É"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Eacute; with a semi-colon" do
    input = "&Eacute;"
    output = [["Character", "É"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ecaron; with a semi-colon" do
    input = "&Ecaron;"
    output = [["Character", "Ě"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ecirc without a semi-colon" do
    input = "&Ecirc"
    output = [["Character", "Ê"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ecirc; with a semi-colon" do
    input = "&Ecirc;"
    output = [["Character", "Ê"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ecy; with a semi-colon" do
    input = "&Ecy;"
    output = [["Character", "Э"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Edot; with a semi-colon" do
    input = "&Edot;"
    output = [["Character", "Ė"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Efr; with a semi-colon" do
    input = "&Efr;"
    output = [["Character", "𝔈"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Egrave without a semi-colon" do
    input = "&Egrave"
    output = [["Character", "È"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Egrave; with a semi-colon" do
    input = "&Egrave;"
    output = [["Character", "È"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Element; with a semi-colon" do
    input = "&Element;"
    output = [["Character", "∈"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Emacr; with a semi-colon" do
    input = "&Emacr;"
    output = [["Character", "Ē"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: EmptySmallSquare; with a semi-colon" do
    input = "&EmptySmallSquare;"
    output = [["Character", "◻"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: EmptyVerySmallSquare; with a semi-colon" do
    input = "&EmptyVerySmallSquare;"
    output = [["Character", "▫"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Eogon; with a semi-colon" do
    input = "&Eogon;"
    output = [["Character", "Ę"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Eopf; with a semi-colon" do
    input = "&Eopf;"
    output = [["Character", "𝔼"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Epsilon; with a semi-colon" do
    input = "&Epsilon;"
    output = [["Character", "Ε"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Equal; with a semi-colon" do
    input = "&Equal;"
    output = [["Character", "⩵"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: EqualTilde; with a semi-colon" do
    input = "&EqualTilde;"
    output = [["Character", "≂"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Equilibrium; with a semi-colon" do
    input = "&Equilibrium;"
    output = [["Character", "⇌"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Escr; with a semi-colon" do
    input = "&Escr;"
    output = [["Character", "ℰ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Esim; with a semi-colon" do
    input = "&Esim;"
    output = [["Character", "⩳"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Eta; with a semi-colon" do
    input = "&Eta;"
    output = [["Character", "Η"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Euml without a semi-colon" do
    input = "&Euml"
    output = [["Character", "Ë"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Euml; with a semi-colon" do
    input = "&Euml;"
    output = [["Character", "Ë"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Exists; with a semi-colon" do
    input = "&Exists;"
    output = [["Character", "∃"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ExponentialE; with a semi-colon" do
    input = "&ExponentialE;"
    output = [["Character", "ⅇ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Fcy; with a semi-colon" do
    input = "&Fcy;"
    output = [["Character", "Ф"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ffr; with a semi-colon" do
    input = "&Ffr;"
    output = [["Character", "𝔉"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: FilledSmallSquare; with a semi-colon" do
    input = "&FilledSmallSquare;"
    output = [["Character", "◼"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: FilledVerySmallSquare; with a semi-colon" do
    input = "&FilledVerySmallSquare;"
    output = [["Character", "▪"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Fopf; with a semi-colon" do
    input = "&Fopf;"
    output = [["Character", "𝔽"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ForAll; with a semi-colon" do
    input = "&ForAll;"
    output = [["Character", "∀"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Fouriertrf; with a semi-colon" do
    input = "&Fouriertrf;"
    output = [["Character", "ℱ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Fscr; with a semi-colon" do
    input = "&Fscr;"
    output = [["Character", "ℱ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: GJcy; with a semi-colon" do
    input = "&GJcy;"
    output = [["Character", "Ѓ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: GT without a semi-colon" do
    input = "&GT"
    output = [["Character", ">"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: GT; with a semi-colon" do
    input = "&GT;"
    output = [["Character", ">"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Gamma; with a semi-colon" do
    input = "&Gamma;"
    output = [["Character", "Γ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Gammad; with a semi-colon" do
    input = "&Gammad;"
    output = [["Character", "Ϝ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Gbreve; with a semi-colon" do
    input = "&Gbreve;"
    output = [["Character", "Ğ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Gcedil; with a semi-colon" do
    input = "&Gcedil;"
    output = [["Character", "Ģ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Gcirc; with a semi-colon" do
    input = "&Gcirc;"
    output = [["Character", "Ĝ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Gcy; with a semi-colon" do
    input = "&Gcy;"
    output = [["Character", "Г"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Gdot; with a semi-colon" do
    input = "&Gdot;"
    output = [["Character", "Ġ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Gfr; with a semi-colon" do
    input = "&Gfr;"
    output = [["Character", "𝔊"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Gg; with a semi-colon" do
    input = "&Gg;"
    output = [["Character", "⋙"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Gopf; with a semi-colon" do
    input = "&Gopf;"
    output = [["Character", "𝔾"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: GreaterEqual; with a semi-colon" do
    input = "&GreaterEqual;"
    output = [["Character", "≥"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: GreaterEqualLess; with a semi-colon" do
    input = "&GreaterEqualLess;"
    output = [["Character", "⋛"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: GreaterFullEqual; with a semi-colon" do
    input = "&GreaterFullEqual;"
    output = [["Character", "≧"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: GreaterGreater; with a semi-colon" do
    input = "&GreaterGreater;"
    output = [["Character", "⪢"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: GreaterLess; with a semi-colon" do
    input = "&GreaterLess;"
    output = [["Character", "≷"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: GreaterSlantEqual; with a semi-colon" do
    input = "&GreaterSlantEqual;"
    output = [["Character", "⩾"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: GreaterTilde; with a semi-colon" do
    input = "&GreaterTilde;"
    output = [["Character", "≳"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Gscr; with a semi-colon" do
    input = "&Gscr;"
    output = [["Character", "𝒢"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Gt; with a semi-colon" do
    input = "&Gt;"
    output = [["Character", "≫"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: HARDcy; with a semi-colon" do
    input = "&HARDcy;"
    output = [["Character", "Ъ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Hacek; with a semi-colon" do
    input = "&Hacek;"
    output = [["Character", "ˇ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Hat; with a semi-colon" do
    input = "&Hat;"
    output = [["Character", "^"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Hcirc; with a semi-colon" do
    input = "&Hcirc;"
    output = [["Character", "Ĥ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Hfr; with a semi-colon" do
    input = "&Hfr;"
    output = [["Character", "ℌ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: HilbertSpace; with a semi-colon" do
    input = "&HilbertSpace;"
    output = [["Character", "ℋ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Hopf; with a semi-colon" do
    input = "&Hopf;"
    output = [["Character", "ℍ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: HorizontalLine; with a semi-colon" do
    input = "&HorizontalLine;"
    output = [["Character", "─"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Hscr; with a semi-colon" do
    input = "&Hscr;"
    output = [["Character", "ℋ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Hstrok; with a semi-colon" do
    input = "&Hstrok;"
    output = [["Character", "Ħ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: HumpDownHump; with a semi-colon" do
    input = "&HumpDownHump;"
    output = [["Character", "≎"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: HumpEqual; with a semi-colon" do
    input = "&HumpEqual;"
    output = [["Character", "≏"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: IEcy; with a semi-colon" do
    input = "&IEcy;"
    output = [["Character", "Е"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: IJlig; with a semi-colon" do
    input = "&IJlig;"
    output = [["Character", "Ĳ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: IOcy; with a semi-colon" do
    input = "&IOcy;"
    output = [["Character", "Ё"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Iacute without a semi-colon" do
    input = "&Iacute"
    output = [["Character", "Í"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Iacute; with a semi-colon" do
    input = "&Iacute;"
    output = [["Character", "Í"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Icirc without a semi-colon" do
    input = "&Icirc"
    output = [["Character", "Î"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Icirc; with a semi-colon" do
    input = "&Icirc;"
    output = [["Character", "Î"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Icy; with a semi-colon" do
    input = "&Icy;"
    output = [["Character", "И"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Idot; with a semi-colon" do
    input = "&Idot;"
    output = [["Character", "İ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Ifr; with a semi-colon" do
    input = "&Ifr;"
    output = [["Character", "ℑ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Igrave without a semi-colon" do
    input = "&Igrave"
    output = [["Character", "Ì"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Igrave; with a semi-colon" do
    input = "&Igrave;"
    output = [["Character", "Ì"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Im; with a semi-colon" do
    input = "&Im;"
    output = [["Character", "ℑ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Imacr; with a semi-colon" do
    input = "&Imacr;"
    output = [["Character", "Ī"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ImaginaryI; with a semi-colon" do
    input = "&ImaginaryI;"
    output = [["Character", "ⅈ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Implies; with a semi-colon" do
    input = "&Implies;"
    output = [["Character", "⇒"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Int; with a semi-colon" do
    input = "&Int;"
    output = [["Character", "∬"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Integral; with a semi-colon" do
    input = "&Integral;"
    output = [["Character", "∫"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Intersection; with a semi-colon" do
    input = "&Intersection;"
    output = [["Character", "⋂"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: InvisibleComma; with a semi-colon" do
    input = "&InvisibleComma;"
    output = [["Character", "⁣"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end
end
