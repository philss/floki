defmodule Floki.HTML.Generated.Tokenizer.NamedentitiesPart17Test do
  use ExUnit.Case, async: true

  # NOTE: This file was generated by "mix generate_tokenizer_tests namedEntities.test".
  # html5lib-tests rev: e52ff68cc7113a6ef3687747fa82691079bf9cc5

  alias Floki.HTML.Tokenizer

  test "tokenize/1 Bad named entity: rightarrow without a semi-colon" do
    input = "&rightarrow"
    output = [["Character", "&rightarrow"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rightarrowtail without a semi-colon" do
    input = "&rightarrowtail"
    output = [["Character", "&rightarrowtail"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rightharpoondown without a semi-colon" do
    input = "&rightharpoondown"
    output = [["Character", "&rightharpoondown"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rightharpoonup without a semi-colon" do
    input = "&rightharpoonup"
    output = [["Character", "&rightharpoonup"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rightleftarrows without a semi-colon" do
    input = "&rightleftarrows"
    output = [["Character", "&rightleftarrows"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rightleftharpoons without a semi-colon" do
    input = "&rightleftharpoons"
    output = [["Character", "&rightleftharpoons"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rightrightarrows without a semi-colon" do
    input = "&rightrightarrows"
    output = [["Character", "&rightrightarrows"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rightsquigarrow without a semi-colon" do
    input = "&rightsquigarrow"
    output = [["Character", "&rightsquigarrow"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rightthreetimes without a semi-colon" do
    input = "&rightthreetimes"
    output = [["Character", "&rightthreetimes"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: ring without a semi-colon" do
    input = "&ring"
    output = [["Character", "&ring"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: risingdotseq without a semi-colon" do
    input = "&risingdotseq"
    output = [["Character", "&risingdotseq"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rlarr without a semi-colon" do
    input = "&rlarr"
    output = [["Character", "&rlarr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rlhar without a semi-colon" do
    input = "&rlhar"
    output = [["Character", "&rlhar"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rlm without a semi-colon" do
    input = "&rlm"
    output = [["Character", "&rlm"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rmoust without a semi-colon" do
    input = "&rmoust"
    output = [["Character", "&rmoust"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rmoustache without a semi-colon" do
    input = "&rmoustache"
    output = [["Character", "&rmoustache"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rnmid without a semi-colon" do
    input = "&rnmid"
    output = [["Character", "&rnmid"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: roang without a semi-colon" do
    input = "&roang"
    output = [["Character", "&roang"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: roarr without a semi-colon" do
    input = "&roarr"
    output = [["Character", "&roarr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: robrk without a semi-colon" do
    input = "&robrk"
    output = [["Character", "&robrk"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: ropar without a semi-colon" do
    input = "&ropar"
    output = [["Character", "&ropar"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: ropf without a semi-colon" do
    input = "&ropf"
    output = [["Character", "&ropf"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: roplus without a semi-colon" do
    input = "&roplus"
    output = [["Character", "&roplus"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rotimes without a semi-colon" do
    input = "&rotimes"
    output = [["Character", "&rotimes"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rpar without a semi-colon" do
    input = "&rpar"
    output = [["Character", "&rpar"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rpargt without a semi-colon" do
    input = "&rpargt"
    output = [["Character", "&rpargt"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rppolint without a semi-colon" do
    input = "&rppolint"
    output = [["Character", "&rppolint"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rrarr without a semi-colon" do
    input = "&rrarr"
    output = [["Character", "&rrarr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rsaquo without a semi-colon" do
    input = "&rsaquo"
    output = [["Character", "&rsaquo"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rscr without a semi-colon" do
    input = "&rscr"
    output = [["Character", "&rscr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rsh without a semi-colon" do
    input = "&rsh"
    output = [["Character", "&rsh"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rsqb without a semi-colon" do
    input = "&rsqb"
    output = [["Character", "&rsqb"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rsquo without a semi-colon" do
    input = "&rsquo"
    output = [["Character", "&rsquo"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rsquor without a semi-colon" do
    input = "&rsquor"
    output = [["Character", "&rsquor"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rthree without a semi-colon" do
    input = "&rthree"
    output = [["Character", "&rthree"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rtimes without a semi-colon" do
    input = "&rtimes"
    output = [["Character", "&rtimes"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rtri without a semi-colon" do
    input = "&rtri"
    output = [["Character", "&rtri"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rtrie without a semi-colon" do
    input = "&rtrie"
    output = [["Character", "&rtrie"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rtrif without a semi-colon" do
    input = "&rtrif"
    output = [["Character", "&rtrif"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rtriltri without a semi-colon" do
    input = "&rtriltri"
    output = [["Character", "&rtriltri"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: ruluhar without a semi-colon" do
    input = "&ruluhar"
    output = [["Character", "&ruluhar"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: rx without a semi-colon" do
    input = "&rx"
    output = [["Character", "&rx"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: sacute without a semi-colon" do
    input = "&sacute"
    output = [["Character", "&sacute"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: sbquo without a semi-colon" do
    input = "&sbquo"
    output = [["Character", "&sbquo"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: sc without a semi-colon" do
    input = "&sc"
    output = [["Character", "&sc"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: scE without a semi-colon" do
    input = "&scE"
    output = [["Character", "&scE"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: scap without a semi-colon" do
    input = "&scap"
    output = [["Character", "&scap"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: scaron without a semi-colon" do
    input = "&scaron"
    output = [["Character", "&scaron"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: sccue without a semi-colon" do
    input = "&sccue"
    output = [["Character", "&sccue"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: sce without a semi-colon" do
    input = "&sce"
    output = [["Character", "&sce"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: scedil without a semi-colon" do
    input = "&scedil"
    output = [["Character", "&scedil"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: scirc without a semi-colon" do
    input = "&scirc"
    output = [["Character", "&scirc"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: scnE without a semi-colon" do
    input = "&scnE"
    output = [["Character", "&scnE"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: scnap without a semi-colon" do
    input = "&scnap"
    output = [["Character", "&scnap"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: scnsim without a semi-colon" do
    input = "&scnsim"
    output = [["Character", "&scnsim"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: scpolint without a semi-colon" do
    input = "&scpolint"
    output = [["Character", "&scpolint"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: scsim without a semi-colon" do
    input = "&scsim"
    output = [["Character", "&scsim"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: scy without a semi-colon" do
    input = "&scy"
    output = [["Character", "&scy"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: sdot without a semi-colon" do
    input = "&sdot"
    output = [["Character", "&sdot"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: sdotb without a semi-colon" do
    input = "&sdotb"
    output = [["Character", "&sdotb"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: sdote without a semi-colon" do
    input = "&sdote"
    output = [["Character", "&sdote"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: seArr without a semi-colon" do
    input = "&seArr"
    output = [["Character", "&seArr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: searhk without a semi-colon" do
    input = "&searhk"
    output = [["Character", "&searhk"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: searr without a semi-colon" do
    input = "&searr"
    output = [["Character", "&searr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: searrow without a semi-colon" do
    input = "&searrow"
    output = [["Character", "&searrow"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: semi without a semi-colon" do
    input = "&semi"
    output = [["Character", "&semi"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: seswar without a semi-colon" do
    input = "&seswar"
    output = [["Character", "&seswar"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: setminus without a semi-colon" do
    input = "&setminus"
    output = [["Character", "&setminus"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: setmn without a semi-colon" do
    input = "&setmn"
    output = [["Character", "&setmn"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: sext without a semi-colon" do
    input = "&sext"
    output = [["Character", "&sext"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: sfr without a semi-colon" do
    input = "&sfr"
    output = [["Character", "&sfr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: sfrown without a semi-colon" do
    input = "&sfrown"
    output = [["Character", "&sfrown"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: sharp without a semi-colon" do
    input = "&sharp"
    output = [["Character", "&sharp"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: shchcy without a semi-colon" do
    input = "&shchcy"
    output = [["Character", "&shchcy"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: shcy without a semi-colon" do
    input = "&shcy"
    output = [["Character", "&shcy"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: shortmid without a semi-colon" do
    input = "&shortmid"
    output = [["Character", "&shortmid"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: shortparallel without a semi-colon" do
    input = "&shortparallel"
    output = [["Character", "&shortparallel"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: sigma without a semi-colon" do
    input = "&sigma"
    output = [["Character", "&sigma"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: sigmaf without a semi-colon" do
    input = "&sigmaf"
    output = [["Character", "&sigmaf"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: sigmav without a semi-colon" do
    input = "&sigmav"
    output = [["Character", "&sigmav"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: sim without a semi-colon" do
    input = "&sim"
    output = [["Character", "&sim"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: simdot without a semi-colon" do
    input = "&simdot"
    output = [["Character", "&simdot"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: sime without a semi-colon" do
    input = "&sime"
    output = [["Character", "&sime"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: simeq without a semi-colon" do
    input = "&simeq"
    output = [["Character", "&simeq"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: simg without a semi-colon" do
    input = "&simg"
    output = [["Character", "&simg"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: simgE without a semi-colon" do
    input = "&simgE"
    output = [["Character", "&simgE"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: siml without a semi-colon" do
    input = "&siml"
    output = [["Character", "&siml"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: simlE without a semi-colon" do
    input = "&simlE"
    output = [["Character", "&simlE"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: simne without a semi-colon" do
    input = "&simne"
    output = [["Character", "&simne"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: simplus without a semi-colon" do
    input = "&simplus"
    output = [["Character", "&simplus"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: simrarr without a semi-colon" do
    input = "&simrarr"
    output = [["Character", "&simrarr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: slarr without a semi-colon" do
    input = "&slarr"
    output = [["Character", "&slarr"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: smallsetminus without a semi-colon" do
    input = "&smallsetminus"
    output = [["Character", "&smallsetminus"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: smashp without a semi-colon" do
    input = "&smashp"
    output = [["Character", "&smashp"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: smeparsl without a semi-colon" do
    input = "&smeparsl"
    output = [["Character", "&smeparsl"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: smid without a semi-colon" do
    input = "&smid"
    output = [["Character", "&smid"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: smile without a semi-colon" do
    input = "&smile"
    output = [["Character", "&smile"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: smt without a semi-colon" do
    input = "&smt"
    output = [["Character", "&smt"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: smte without a semi-colon" do
    input = "&smte"
    output = [["Character", "&smte"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Bad named entity: smtes without a semi-colon" do
    input = "&smtes"
    output = [["Character", "&smtes"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end
end