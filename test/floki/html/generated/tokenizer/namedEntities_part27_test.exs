defmodule Floki.HTML.Generated.Tokenizer.NamedentitiesPart27Test do
  use ExUnit.Case, async: true

  # NOTE: This file was generated by "mix generate_tokenizer_tests namedEntities.test".
  # html5lib-tests rev: e52ff68cc7113a6ef3687747fa82691079bf9cc5

  alias Floki.HTML.Tokenizer

  test "tokenize/1 Named entity: Yopf; with a semi-colon" do
    input = "&Yopf;"
    output = [["Character", "𝕐"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Yscr; with a semi-colon" do
    input = "&Yscr;"
    output = [["Character", "𝒴"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Yuml; with a semi-colon" do
    input = "&Yuml;"
    output = [["Character", "Ÿ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ZHcy; with a semi-colon" do
    input = "&ZHcy;"
    output = [["Character", "Ж"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Zacute; with a semi-colon" do
    input = "&Zacute;"
    output = [["Character", "Ź"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Zcaron; with a semi-colon" do
    input = "&Zcaron;"
    output = [["Character", "Ž"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Zcy; with a semi-colon" do
    input = "&Zcy;"
    output = [["Character", "З"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Zdot; with a semi-colon" do
    input = "&Zdot;"
    output = [["Character", "Ż"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ZeroWidthSpace; with a semi-colon" do
    input = "&ZeroWidthSpace;"
    output = [["Character", "​"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Zeta; with a semi-colon" do
    input = "&Zeta;"
    output = [["Character", "Ζ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Zfr; with a semi-colon" do
    input = "&Zfr;"
    output = [["Character", "ℨ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Zopf; with a semi-colon" do
    input = "&Zopf;"
    output = [["Character", "ℤ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Zscr; with a semi-colon" do
    input = "&Zscr;"
    output = [["Character", "𝒵"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: aacute without a semi-colon" do
    input = "&aacute"
    output = [["Character", "á"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: aacute; with a semi-colon" do
    input = "&aacute;"
    output = [["Character", "á"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: abreve; with a semi-colon" do
    input = "&abreve;"
    output = [["Character", "ă"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ac; with a semi-colon" do
    input = "&ac;"
    output = [["Character", "∾"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: acE; with a semi-colon" do
    input = "&acE;"
    output = [["Character", "∾̳"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: acd; with a semi-colon" do
    input = "&acd;"
    output = [["Character", "∿"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: acirc without a semi-colon" do
    input = "&acirc"
    output = [["Character", "â"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: acirc; with a semi-colon" do
    input = "&acirc;"
    output = [["Character", "â"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: acute without a semi-colon" do
    input = "&acute"
    output = [["Character", "´"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: acute; with a semi-colon" do
    input = "&acute;"
    output = [["Character", "´"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: acy; with a semi-colon" do
    input = "&acy;"
    output = [["Character", "а"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: aelig without a semi-colon" do
    input = "&aelig"
    output = [["Character", "æ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: aelig; with a semi-colon" do
    input = "&aelig;"
    output = [["Character", "æ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: af; with a semi-colon" do
    input = "&af;"
    output = [["Character", "⁡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: afr; with a semi-colon" do
    input = "&afr;"
    output = [["Character", "𝔞"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: agrave without a semi-colon" do
    input = "&agrave"
    output = [["Character", "à"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: agrave; with a semi-colon" do
    input = "&agrave;"
    output = [["Character", "à"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: alefsym; with a semi-colon" do
    input = "&alefsym;"
    output = [["Character", "ℵ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: aleph; with a semi-colon" do
    input = "&aleph;"
    output = [["Character", "ℵ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: alpha; with a semi-colon" do
    input = "&alpha;"
    output = [["Character", "α"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: amacr; with a semi-colon" do
    input = "&amacr;"
    output = [["Character", "ā"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: amalg; with a semi-colon" do
    input = "&amalg;"
    output = [["Character", "⨿"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: amp without a semi-colon" do
    input = "&amp"
    output = [["Character", "&"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: amp; with a semi-colon" do
    input = "&amp;"
    output = [["Character", "&"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: and; with a semi-colon" do
    input = "&and;"
    output = [["Character", "∧"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: andand; with a semi-colon" do
    input = "&andand;"
    output = [["Character", "⩕"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: andd; with a semi-colon" do
    input = "&andd;"
    output = [["Character", "⩜"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: andslope; with a semi-colon" do
    input = "&andslope;"
    output = [["Character", "⩘"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: andv; with a semi-colon" do
    input = "&andv;"
    output = [["Character", "⩚"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ang; with a semi-colon" do
    input = "&ang;"
    output = [["Character", "∠"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ange; with a semi-colon" do
    input = "&ange;"
    output = [["Character", "⦤"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: angle; with a semi-colon" do
    input = "&angle;"
    output = [["Character", "∠"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: angmsd; with a semi-colon" do
    input = "&angmsd;"
    output = [["Character", "∡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: angmsdaa; with a semi-colon" do
    input = "&angmsdaa;"
    output = [["Character", "⦨"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: angmsdab; with a semi-colon" do
    input = "&angmsdab;"
    output = [["Character", "⦩"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: angmsdac; with a semi-colon" do
    input = "&angmsdac;"
    output = [["Character", "⦪"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: angmsdad; with a semi-colon" do
    input = "&angmsdad;"
    output = [["Character", "⦫"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: angmsdae; with a semi-colon" do
    input = "&angmsdae;"
    output = [["Character", "⦬"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: angmsdaf; with a semi-colon" do
    input = "&angmsdaf;"
    output = [["Character", "⦭"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: angmsdag; with a semi-colon" do
    input = "&angmsdag;"
    output = [["Character", "⦮"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: angmsdah; with a semi-colon" do
    input = "&angmsdah;"
    output = [["Character", "⦯"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: angrt; with a semi-colon" do
    input = "&angrt;"
    output = [["Character", "∟"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: angrtvb; with a semi-colon" do
    input = "&angrtvb;"
    output = [["Character", "⊾"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: angrtvbd; with a semi-colon" do
    input = "&angrtvbd;"
    output = [["Character", "⦝"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: angsph; with a semi-colon" do
    input = "&angsph;"
    output = [["Character", "∢"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: angst; with a semi-colon" do
    input = "&angst;"
    output = [["Character", "Å"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: angzarr; with a semi-colon" do
    input = "&angzarr;"
    output = [["Character", "⍼"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: aogon; with a semi-colon" do
    input = "&aogon;"
    output = [["Character", "ą"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: aopf; with a semi-colon" do
    input = "&aopf;"
    output = [["Character", "𝕒"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ap; with a semi-colon" do
    input = "&ap;"
    output = [["Character", "≈"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: apE; with a semi-colon" do
    input = "&apE;"
    output = [["Character", "⩰"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: apacir; with a semi-colon" do
    input = "&apacir;"
    output = [["Character", "⩯"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ape; with a semi-colon" do
    input = "&ape;"
    output = [["Character", "≊"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: apid; with a semi-colon" do
    input = "&apid;"
    output = [["Character", "≋"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: apos; with a semi-colon" do
    input = "&apos;"
    output = [["Character", "'"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: approx; with a semi-colon" do
    input = "&approx;"
    output = [["Character", "≈"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: approxeq; with a semi-colon" do
    input = "&approxeq;"
    output = [["Character", "≊"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: aring without a semi-colon" do
    input = "&aring"
    output = [["Character", "å"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: aring; with a semi-colon" do
    input = "&aring;"
    output = [["Character", "å"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ascr; with a semi-colon" do
    input = "&ascr;"
    output = [["Character", "𝒶"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ast; with a semi-colon" do
    input = "&ast;"
    output = [["Character", "*"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: asymp; with a semi-colon" do
    input = "&asymp;"
    output = [["Character", "≈"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: asympeq; with a semi-colon" do
    input = "&asympeq;"
    output = [["Character", "≍"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: atilde without a semi-colon" do
    input = "&atilde"
    output = [["Character", "ã"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: atilde; with a semi-colon" do
    input = "&atilde;"
    output = [["Character", "ã"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: auml without a semi-colon" do
    input = "&auml"
    output = [["Character", "ä"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: auml; with a semi-colon" do
    input = "&auml;"
    output = [["Character", "ä"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: awconint; with a semi-colon" do
    input = "&awconint;"
    output = [["Character", "∳"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: awint; with a semi-colon" do
    input = "&awint;"
    output = [["Character", "⨑"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bNot; with a semi-colon" do
    input = "&bNot;"
    output = [["Character", "⫭"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: backcong; with a semi-colon" do
    input = "&backcong;"
    output = [["Character", "≌"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: backepsilon; with a semi-colon" do
    input = "&backepsilon;"
    output = [["Character", "϶"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: backprime; with a semi-colon" do
    input = "&backprime;"
    output = [["Character", "‵"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: backsim; with a semi-colon" do
    input = "&backsim;"
    output = [["Character", "∽"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: backsimeq; with a semi-colon" do
    input = "&backsimeq;"
    output = [["Character", "⋍"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: barvee; with a semi-colon" do
    input = "&barvee;"
    output = [["Character", "⊽"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: barwed; with a semi-colon" do
    input = "&barwed;"
    output = [["Character", "⌅"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: barwedge; with a semi-colon" do
    input = "&barwedge;"
    output = [["Character", "⌅"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bbrk; with a semi-colon" do
    input = "&bbrk;"
    output = [["Character", "⎵"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bbrktbrk; with a semi-colon" do
    input = "&bbrktbrk;"
    output = [["Character", "⎶"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bcong; with a semi-colon" do
    input = "&bcong;"
    output = [["Character", "≌"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bcy; with a semi-colon" do
    input = "&bcy;"
    output = [["Character", "б"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bdquo; with a semi-colon" do
    input = "&bdquo;"
    output = [["Character", "„"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: becaus; with a semi-colon" do
    input = "&becaus;"
    output = [["Character", "∵"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: because; with a semi-colon" do
    input = "&because;"
    output = [["Character", "∵"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bemptyv; with a semi-colon" do
    input = "&bemptyv;"
    output = [["Character", "⦰"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bepsi; with a semi-colon" do
    input = "&bepsi;"
    output = [["Character", "϶"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end
end
