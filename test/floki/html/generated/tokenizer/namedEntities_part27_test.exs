defmodule Floki.HTML.Generated.Tokenizer.NamedentitiesPart27Test do
  use ExUnit.Case, async: true

  # NOTE: This file was generated by "mix generate_tokenizer_tests namedEntities.test".
  # html5lib-tests rev: e52ff68cc7113a6ef3687747fa82691079bf9cc5

  alias Floki.HTML.Tokenizer

  test "tokenize/1 Named entity: Yopf; with a semi-colon" do
    input = "&Yopf;"
    output = [["Character", "ð•"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Yscr; with a semi-colon" do
    input = "&Yscr;"
    output = [["Character", "ð’´"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Yuml; with a semi-colon" do
    input = "&Yuml;"
    output = [["Character", "Å¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ZHcy; with a semi-colon" do
    input = "&ZHcy;"
    output = [["Character", "Ð–"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Zacute; with a semi-colon" do
    input = "&Zacute;"
    output = [["Character", "Å¹"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Zcaron; with a semi-colon" do
    input = "&Zcaron;"
    output = [["Character", "Å½"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Zcy; with a semi-colon" do
    input = "&Zcy;"
    output = [["Character", "Ð—"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Zdot; with a semi-colon" do
    input = "&Zdot;"
    output = [["Character", "Å»"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ZeroWidthSpace; with a semi-colon" do
    input = "&ZeroWidthSpace;"
    output = [["Character", "â€‹"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Zeta; with a semi-colon" do
    input = "&Zeta;"
    output = [["Character", "Î–"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Zfr; with a semi-colon" do
    input = "&Zfr;"
    output = [["Character", "â„¨"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Zopf; with a semi-colon" do
    input = "&Zopf;"
    output = [["Character", "â„¤"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: Zscr; with a semi-colon" do
    input = "&Zscr;"
    output = [["Character", "ð’µ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: aacute without a semi-colon" do
    input = "&aacute"
    output = [["Character", "Ã¡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: aacute; with a semi-colon" do
    input = "&aacute;"
    output = [["Character", "Ã¡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: abreve; with a semi-colon" do
    input = "&abreve;"
    output = [["Character", "Äƒ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ac; with a semi-colon" do
    input = "&ac;"
    output = [["Character", "âˆ¾"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: acE; with a semi-colon" do
    input = "&acE;"
    output = [["Character", "âˆ¾Ì³"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: acd; with a semi-colon" do
    input = "&acd;"
    output = [["Character", "âˆ¿"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: acirc without a semi-colon" do
    input = "&acirc"
    output = [["Character", "Ã¢"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: acirc; with a semi-colon" do
    input = "&acirc;"
    output = [["Character", "Ã¢"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: acute without a semi-colon" do
    input = "&acute"
    output = [["Character", "Â´"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: acute; with a semi-colon" do
    input = "&acute;"
    output = [["Character", "Â´"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: acy; with a semi-colon" do
    input = "&acy;"
    output = [["Character", "Ð°"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: aelig without a semi-colon" do
    input = "&aelig"
    output = [["Character", "Ã¦"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: aelig; with a semi-colon" do
    input = "&aelig;"
    output = [["Character", "Ã¦"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: af; with a semi-colon" do
    input = "&af;"
    output = [["Character", "â¡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: afr; with a semi-colon" do
    input = "&afr;"
    output = [["Character", "ð”ž"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: agrave without a semi-colon" do
    input = "&agrave"
    output = [["Character", "Ã "]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: agrave; with a semi-colon" do
    input = "&agrave;"
    output = [["Character", "Ã "]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: alefsym; with a semi-colon" do
    input = "&alefsym;"
    output = [["Character", "â„µ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: aleph; with a semi-colon" do
    input = "&aleph;"
    output = [["Character", "â„µ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: alpha; with a semi-colon" do
    input = "&alpha;"
    output = [["Character", "Î±"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: amacr; with a semi-colon" do
    input = "&amacr;"
    output = [["Character", "Ä"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: amalg; with a semi-colon" do
    input = "&amalg;"
    output = [["Character", "â¨¿"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: amp without a semi-colon" do
    input = "&amp"
    output = [["Character", "&"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: amp; with a semi-colon" do
    input = "&amp;"
    output = [["Character", "&"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: and; with a semi-colon" do
    input = "&and;"
    output = [["Character", "âˆ§"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: andand; with a semi-colon" do
    input = "&andand;"
    output = [["Character", "â©•"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: andd; with a semi-colon" do
    input = "&andd;"
    output = [["Character", "â©œ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: andslope; with a semi-colon" do
    input = "&andslope;"
    output = [["Character", "â©˜"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: andv; with a semi-colon" do
    input = "&andv;"
    output = [["Character", "â©š"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ang; with a semi-colon" do
    input = "&ang;"
    output = [["Character", "âˆ "]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ange; with a semi-colon" do
    input = "&ange;"
    output = [["Character", "â¦¤"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: angle; with a semi-colon" do
    input = "&angle;"
    output = [["Character", "âˆ "]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: angmsd; with a semi-colon" do
    input = "&angmsd;"
    output = [["Character", "âˆ¡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: angmsdaa; with a semi-colon" do
    input = "&angmsdaa;"
    output = [["Character", "â¦¨"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: angmsdab; with a semi-colon" do
    input = "&angmsdab;"
    output = [["Character", "â¦©"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: angmsdac; with a semi-colon" do
    input = "&angmsdac;"
    output = [["Character", "â¦ª"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: angmsdad; with a semi-colon" do
    input = "&angmsdad;"
    output = [["Character", "â¦«"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: angmsdae; with a semi-colon" do
    input = "&angmsdae;"
    output = [["Character", "â¦¬"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: angmsdaf; with a semi-colon" do
    input = "&angmsdaf;"
    output = [["Character", "â¦­"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: angmsdag; with a semi-colon" do
    input = "&angmsdag;"
    output = [["Character", "â¦®"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: angmsdah; with a semi-colon" do
    input = "&angmsdah;"
    output = [["Character", "â¦¯"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: angrt; with a semi-colon" do
    input = "&angrt;"
    output = [["Character", "âˆŸ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: angrtvb; with a semi-colon" do
    input = "&angrtvb;"
    output = [["Character", "âŠ¾"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: angrtvbd; with a semi-colon" do
    input = "&angrtvbd;"
    output = [["Character", "â¦"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: angsph; with a semi-colon" do
    input = "&angsph;"
    output = [["Character", "âˆ¢"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: angst; with a semi-colon" do
    input = "&angst;"
    output = [["Character", "Ã…"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: angzarr; with a semi-colon" do
    input = "&angzarr;"
    output = [["Character", "â¼"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: aogon; with a semi-colon" do
    input = "&aogon;"
    output = [["Character", "Ä…"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: aopf; with a semi-colon" do
    input = "&aopf;"
    output = [["Character", "ð•’"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ap; with a semi-colon" do
    input = "&ap;"
    output = [["Character", "â‰ˆ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: apE; with a semi-colon" do
    input = "&apE;"
    output = [["Character", "â©°"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: apacir; with a semi-colon" do
    input = "&apacir;"
    output = [["Character", "â©¯"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ape; with a semi-colon" do
    input = "&ape;"
    output = [["Character", "â‰Š"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: apid; with a semi-colon" do
    input = "&apid;"
    output = [["Character", "â‰‹"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: apos; with a semi-colon" do
    input = "&apos;"
    output = [["Character", "'"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: approx; with a semi-colon" do
    input = "&approx;"
    output = [["Character", "â‰ˆ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: approxeq; with a semi-colon" do
    input = "&approxeq;"
    output = [["Character", "â‰Š"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: aring without a semi-colon" do
    input = "&aring"
    output = [["Character", "Ã¥"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: aring; with a semi-colon" do
    input = "&aring;"
    output = [["Character", "Ã¥"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ascr; with a semi-colon" do
    input = "&ascr;"
    output = [["Character", "ð’¶"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ast; with a semi-colon" do
    input = "&ast;"
    output = [["Character", "*"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: asymp; with a semi-colon" do
    input = "&asymp;"
    output = [["Character", "â‰ˆ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: asympeq; with a semi-colon" do
    input = "&asympeq;"
    output = [["Character", "â‰"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: atilde without a semi-colon" do
    input = "&atilde"
    output = [["Character", "Ã£"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: atilde; with a semi-colon" do
    input = "&atilde;"
    output = [["Character", "Ã£"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: auml without a semi-colon" do
    input = "&auml"
    output = [["Character", "Ã¤"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: auml; with a semi-colon" do
    input = "&auml;"
    output = [["Character", "Ã¤"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: awconint; with a semi-colon" do
    input = "&awconint;"
    output = [["Character", "âˆ³"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: awint; with a semi-colon" do
    input = "&awint;"
    output = [["Character", "â¨‘"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bNot; with a semi-colon" do
    input = "&bNot;"
    output = [["Character", "â«­"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: backcong; with a semi-colon" do
    input = "&backcong;"
    output = [["Character", "â‰Œ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: backepsilon; with a semi-colon" do
    input = "&backepsilon;"
    output = [["Character", "Ï¶"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: backprime; with a semi-colon" do
    input = "&backprime;"
    output = [["Character", "â€µ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: backsim; with a semi-colon" do
    input = "&backsim;"
    output = [["Character", "âˆ½"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: backsimeq; with a semi-colon" do
    input = "&backsimeq;"
    output = [["Character", "â‹"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: barvee; with a semi-colon" do
    input = "&barvee;"
    output = [["Character", "âŠ½"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: barwed; with a semi-colon" do
    input = "&barwed;"
    output = [["Character", "âŒ…"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: barwedge; with a semi-colon" do
    input = "&barwedge;"
    output = [["Character", "âŒ…"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bbrk; with a semi-colon" do
    input = "&bbrk;"
    output = [["Character", "âŽµ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bbrktbrk; with a semi-colon" do
    input = "&bbrktbrk;"
    output = [["Character", "âŽ¶"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bcong; with a semi-colon" do
    input = "&bcong;"
    output = [["Character", "â‰Œ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bcy; with a semi-colon" do
    input = "&bcy;"
    output = [["Character", "Ð±"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bdquo; with a semi-colon" do
    input = "&bdquo;"
    output = [["Character", "â€ž"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: becaus; with a semi-colon" do
    input = "&becaus;"
    output = [["Character", "âˆµ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: because; with a semi-colon" do
    input = "&because;"
    output = [["Character", "âˆµ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bemptyv; with a semi-colon" do
    input = "&bemptyv;"
    output = [["Character", "â¦°"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: bepsi; with a semi-colon" do
    input = "&bepsi;"
    output = [["Character", "Ï¶"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end
end
