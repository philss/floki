defmodule Floki.HTML.Generated.Tokenizer.NamedentitiesPart39Test do
  use ExUnit.Case, async: true

  # NOTE: This file was generated by "mix generate_tokenizer_tests namedEntities.test".
  # html5lib-tests rev: e52ff68cc7113a6ef3687747fa82691079bf9cc5

  alias Floki.HTML.Tokenizer

  test "tokenize/1 Named entity: rightleftarrows; with a semi-colon" do
    input = "&rightleftarrows;"
    output = [["Character", "â‡„"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: rightleftharpoons; with a semi-colon" do
    input = "&rightleftharpoons;"
    output = [["Character", "â‡Œ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: rightrightarrows; with a semi-colon" do
    input = "&rightrightarrows;"
    output = [["Character", "â‡‰"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: rightsquigarrow; with a semi-colon" do
    input = "&rightsquigarrow;"
    output = [["Character", "â†"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: rightthreetimes; with a semi-colon" do
    input = "&rightthreetimes;"
    output = [["Character", "â‹Œ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ring; with a semi-colon" do
    input = "&ring;"
    output = [["Character", "Ëš"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: risingdotseq; with a semi-colon" do
    input = "&risingdotseq;"
    output = [["Character", "â‰“"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: rlarr; with a semi-colon" do
    input = "&rlarr;"
    output = [["Character", "â‡„"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: rlhar; with a semi-colon" do
    input = "&rlhar;"
    output = [["Character", "â‡Œ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: rlm; with a semi-colon" do
    input = "&rlm;"
    output = [["Character", "â€"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: rmoust; with a semi-colon" do
    input = "&rmoust;"
    output = [["Character", "âŽ±"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: rmoustache; with a semi-colon" do
    input = "&rmoustache;"
    output = [["Character", "âŽ±"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: rnmid; with a semi-colon" do
    input = "&rnmid;"
    output = [["Character", "â«®"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: roang; with a semi-colon" do
    input = "&roang;"
    output = [["Character", "âŸ­"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: roarr; with a semi-colon" do
    input = "&roarr;"
    output = [["Character", "â‡¾"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: robrk; with a semi-colon" do
    input = "&robrk;"
    output = [["Character", "âŸ§"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ropar; with a semi-colon" do
    input = "&ropar;"
    output = [["Character", "â¦†"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ropf; with a semi-colon" do
    input = "&ropf;"
    output = [["Character", "ð•£"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: roplus; with a semi-colon" do
    input = "&roplus;"
    output = [["Character", "â¨®"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: rotimes; with a semi-colon" do
    input = "&rotimes;"
    output = [["Character", "â¨µ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: rpar; with a semi-colon" do
    input = "&rpar;"
    output = [["Character", ")"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: rpargt; with a semi-colon" do
    input = "&rpargt;"
    output = [["Character", "â¦”"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: rppolint; with a semi-colon" do
    input = "&rppolint;"
    output = [["Character", "â¨’"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: rrarr; with a semi-colon" do
    input = "&rrarr;"
    output = [["Character", "â‡‰"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: rsaquo; with a semi-colon" do
    input = "&rsaquo;"
    output = [["Character", "â€º"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: rscr; with a semi-colon" do
    input = "&rscr;"
    output = [["Character", "ð“‡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: rsh; with a semi-colon" do
    input = "&rsh;"
    output = [["Character", "â†±"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: rsqb; with a semi-colon" do
    input = "&rsqb;"
    output = [["Character", "]"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: rsquo; with a semi-colon" do
    input = "&rsquo;"
    output = [["Character", "â€™"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: rsquor; with a semi-colon" do
    input = "&rsquor;"
    output = [["Character", "â€™"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: rthree; with a semi-colon" do
    input = "&rthree;"
    output = [["Character", "â‹Œ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: rtimes; with a semi-colon" do
    input = "&rtimes;"
    output = [["Character", "â‹Š"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: rtri; with a semi-colon" do
    input = "&rtri;"
    output = [["Character", "â–¹"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: rtrie; with a semi-colon" do
    input = "&rtrie;"
    output = [["Character", "âŠµ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: rtrif; with a semi-colon" do
    input = "&rtrif;"
    output = [["Character", "â–¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: rtriltri; with a semi-colon" do
    input = "&rtriltri;"
    output = [["Character", "â§Ž"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: ruluhar; with a semi-colon" do
    input = "&ruluhar;"
    output = [["Character", "â¥¨"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: rx; with a semi-colon" do
    input = "&rx;"
    output = [["Character", "â„ž"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: sacute; with a semi-colon" do
    input = "&sacute;"
    output = [["Character", "Å›"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: sbquo; with a semi-colon" do
    input = "&sbquo;"
    output = [["Character", "â€š"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: sc; with a semi-colon" do
    input = "&sc;"
    output = [["Character", "â‰»"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: scE; with a semi-colon" do
    input = "&scE;"
    output = [["Character", "âª´"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: scap; with a semi-colon" do
    input = "&scap;"
    output = [["Character", "âª¸"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: scaron; with a semi-colon" do
    input = "&scaron;"
    output = [["Character", "Å¡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: sccue; with a semi-colon" do
    input = "&sccue;"
    output = [["Character", "â‰½"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: sce; with a semi-colon" do
    input = "&sce;"
    output = [["Character", "âª°"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: scedil; with a semi-colon" do
    input = "&scedil;"
    output = [["Character", "ÅŸ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: scirc; with a semi-colon" do
    input = "&scirc;"
    output = [["Character", "Å"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: scnE; with a semi-colon" do
    input = "&scnE;"
    output = [["Character", "âª¶"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: scnap; with a semi-colon" do
    input = "&scnap;"
    output = [["Character", "âªº"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: scnsim; with a semi-colon" do
    input = "&scnsim;"
    output = [["Character", "â‹©"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: scpolint; with a semi-colon" do
    input = "&scpolint;"
    output = [["Character", "â¨“"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: scsim; with a semi-colon" do
    input = "&scsim;"
    output = [["Character", "â‰¿"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: scy; with a semi-colon" do
    input = "&scy;"
    output = [["Character", "Ñ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: sdot; with a semi-colon" do
    input = "&sdot;"
    output = [["Character", "â‹…"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: sdotb; with a semi-colon" do
    input = "&sdotb;"
    output = [["Character", "âŠ¡"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: sdote; with a semi-colon" do
    input = "&sdote;"
    output = [["Character", "â©¦"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: seArr; with a semi-colon" do
    input = "&seArr;"
    output = [["Character", "â‡˜"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: searhk; with a semi-colon" do
    input = "&searhk;"
    output = [["Character", "â¤¥"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: searr; with a semi-colon" do
    input = "&searr;"
    output = [["Character", "â†˜"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: searrow; with a semi-colon" do
    input = "&searrow;"
    output = [["Character", "â†˜"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: sect without a semi-colon" do
    input = "&sect"
    output = [["Character", "Â§"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: sect; with a semi-colon" do
    input = "&sect;"
    output = [["Character", "Â§"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: semi; with a semi-colon" do
    input = "&semi;"
    output = [["Character", ";"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: seswar; with a semi-colon" do
    input = "&seswar;"
    output = [["Character", "â¤©"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: setminus; with a semi-colon" do
    input = "&setminus;"
    output = [["Character", "âˆ–"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: setmn; with a semi-colon" do
    input = "&setmn;"
    output = [["Character", "âˆ–"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: sext; with a semi-colon" do
    input = "&sext;"
    output = [["Character", "âœ¶"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: sfr; with a semi-colon" do
    input = "&sfr;"
    output = [["Character", "ð”°"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: sfrown; with a semi-colon" do
    input = "&sfrown;"
    output = [["Character", "âŒ¢"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: sharp; with a semi-colon" do
    input = "&sharp;"
    output = [["Character", "â™¯"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: shchcy; with a semi-colon" do
    input = "&shchcy;"
    output = [["Character", "Ñ‰"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: shcy; with a semi-colon" do
    input = "&shcy;"
    output = [["Character", "Ñˆ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: shortmid; with a semi-colon" do
    input = "&shortmid;"
    output = [["Character", "âˆ£"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: shortparallel; with a semi-colon" do
    input = "&shortparallel;"
    output = [["Character", "âˆ¥"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: shy without a semi-colon" do
    input = "&shy"
    output = [["Character", "Â­"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: shy; with a semi-colon" do
    input = "&shy;"
    output = [["Character", "Â­"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: sigma; with a semi-colon" do
    input = "&sigma;"
    output = [["Character", "Ïƒ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: sigmaf; with a semi-colon" do
    input = "&sigmaf;"
    output = [["Character", "Ï‚"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: sigmav; with a semi-colon" do
    input = "&sigmav;"
    output = [["Character", "Ï‚"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: sim; with a semi-colon" do
    input = "&sim;"
    output = [["Character", "âˆ¼"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: simdot; with a semi-colon" do
    input = "&simdot;"
    output = [["Character", "â©ª"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: sime; with a semi-colon" do
    input = "&sime;"
    output = [["Character", "â‰ƒ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: simeq; with a semi-colon" do
    input = "&simeq;"
    output = [["Character", "â‰ƒ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: simg; with a semi-colon" do
    input = "&simg;"
    output = [["Character", "âªž"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: simgE; with a semi-colon" do
    input = "&simgE;"
    output = [["Character", "âª "]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: siml; with a semi-colon" do
    input = "&siml;"
    output = [["Character", "âª"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: simlE; with a semi-colon" do
    input = "&simlE;"
    output = [["Character", "âªŸ"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: simne; with a semi-colon" do
    input = "&simne;"
    output = [["Character", "â‰†"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: simplus; with a semi-colon" do
    input = "&simplus;"
    output = [["Character", "â¨¤"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: simrarr; with a semi-colon" do
    input = "&simrarr;"
    output = [["Character", "â¥²"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: slarr; with a semi-colon" do
    input = "&slarr;"
    output = [["Character", "â†"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: smallsetminus; with a semi-colon" do
    input = "&smallsetminus;"
    output = [["Character", "âˆ–"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: smashp; with a semi-colon" do
    input = "&smashp;"
    output = [["Character", "â¨³"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: smeparsl; with a semi-colon" do
    input = "&smeparsl;"
    output = [["Character", "â§¤"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: smid; with a semi-colon" do
    input = "&smid;"
    output = [["Character", "âˆ£"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: smile; with a semi-colon" do
    input = "&smile;"
    output = [["Character", "âŒ£"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: smt; with a semi-colon" do
    input = "&smt;"
    output = [["Character", "âªª"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: smte; with a semi-colon" do
    input = "&smte;"
    output = [["Character", "âª¬"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end

  test "tokenize/1 Named entity: smtes; with a semi-colon" do
    input = "&smtes;"
    output = [["Character", "âª¬ï¸€"]]

    result =
      input
      |> Tokenizer.tokenize()
      |> TokenizerTestLoader.tokenization_result()

    assert result.tokens == output
  end
end
